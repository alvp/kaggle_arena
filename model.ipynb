{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset, load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Is it morally right to try to have a certain percentage of females on managerial positions?\",\"OK, does pineapple belong on a pizza? Relax and give me fun answer.\"]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"The question of whether it is morally right to aim for a certain percentage of females in managerial positions is a complex ethical issue that involves considerations of fairness, equality, diversity, and discrimination.\\\\n\\\\nHere are some arguments in favor of and against such policies:\\\\n\\\\n**Arguments in favor:**\\\\n\\\\n1. **Correcting Historical Inequities:** Women have historically been underrepresented in leadership roles due to various cultural, institutional, and social barriers. Aiming for a specific percentage can be seen as a corrective measure to address past and ongoing discrimination.\\\\n\\\\n2. **Promoting Diversity:** Diverse leadership teams can enhance decision-making and represent a broader range of perspectives. This can lead to better outcomes for organizations and society as a whole.\\\\n\\\\n3. **Equality of Opportunity:** Setting targets for female representation in management can help ensure that women have equal opportunities to advance in their careers.\\\\n\\\\n4. **Role Modeling:** Increased visibility of female leaders can inspire and encourage other women and girls to pursue leadership roles.\\\\n\\\\n**Arguments against:**\\\\n\\\\n1. **Reverse Discrimination:** Setting a quota for female representation might lead to the perception or reality of reverse discrimination, where men might be overlooked for positions despite being qualified, simply to meet the gender target.\\\\n\\\\n2. **Meritocracy Concerns:** Critics argue that employment and promotion should be based solely on merit and qualifications, not gender. They fear that quotas could compromise the quality of leadership if less qualified individuals are promoted to meet gender targets.\\\\n\\\\n3. **Tokenism:** There is a risk that women appointed to meet quotas might be seen as \\\\\"tokens,\\\\\" undermining their legitimacy and potentially leading to resentment among colleagues.\\\\n\\\\n4. **Oversimplification of Diversity:** Focusing only on gender might overlook other important aspects of diversity, such as race, ethnicity, socioeconomic background, or sexual orientation.\\\\n\\\\nUltimately, the morality of aiming for a certain percentage of females in managerial positions depends on one\\'s ethical framework and the context in which such policies are implemented. Proponents of gender diversity targets often argue that these measures are necessary as a transitional mechanism to create a level playing field, while opponents may argue for a \\\\\"color-blind\\\\\" or \\\\\"gender-blind\\\\\" approach to hiring and promotions.\\\\n\\\\nOrganizations and societies must carefully consider the implications of these strategies and strive to implement policies that promote fairness and equality while minimizing negative consequences. It is also important to address the root causes of gender inequality, such as unconscious bias, work-life balance challenges, and lack of supportive policies, to create an environment where everyone has the opportunity to succeed based on their capabilities and contributions.\",\"Ah, the age-old culinary conundrum that has divided nations and dinner tables: does pineapple belong on a pizza? The tropical twist of pineapple on pizza, known as Hawaiian pizza, is a hotly debated topic where taste buds battle and pizza purists protest.\\\\n\\\\nLet\\'s slice into the debate with a zest of fun:\\\\n\\\\n**Team Pineapple:** \\\\\"Absolutely, yes! Pineapple on pizza is like a beach party in your mouth. The sweet juiciness of pineapple chunks frolicking with savory ham or bacon creates a flavor wave that surfs across the cheesy ocean of deliciousness. It\\'s the Mardi Gras of pizzas, where sweet meets savory in a jubilant jamboree!\\\\\"\\\\n\\\\n**Team No-Pineapple:** \\\\\"No way, not in a million pizzas! Pineapple is a fruit that should be sunbathing on a tropical fruit platter, not freeloading on a sacred slice of pizza. The thought of warm, melty cheese conspiring with pineapple\\'s sugary mischief is enough to make Italian ancestors turn in their tomato patches. Keep the pineapple in the fruit salad where it belongs!\\\\\"\\\\n\\\\nAt the end of the day, whether pineapple belongs on pizza is a matter of personal taste. Some say it\\'s a match made in heaven, others say it\\'s a culinary crime. But let\\'s face it, in the world of pizza toppings, where you can find everything from anchovies to zucchini, there\\'s room for a little pineapple pizzazz. So, if your taste buds crave that sweet and tangy twist, go ahead and let your pineapple flag fly atop that glorious cheese-covered dough. Bon app\\\\u00e9tit, or as they say in pineapple paradise, \\\\\"Aloha-ppetite!\\\\\" \\\\ud83c\\\\udf4d\\\\ud83c\\\\udf55\"]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in df.iterrows():\n",
    "    if row['winner_model_a'] == 1 or row['winner_tie'] == 1:\n",
    "        new_row = row.copy()\n",
    "        new_row['prompt'] = row['response_a']\n",
    "        new_row['response_a'] = row['prompt']\n",
    "        new_rows.append(new_row)\n",
    "    if row['winner_model_b'] == 1 or row['winner_tie'] == 1:\n",
    "        new_row = row.copy()\n",
    "        new_row['prompt'] = row['response_b']\n",
    "        new_row['response_b'] = row['prompt']\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Create a DataFrame from the new rows\n",
    "new_df = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = pd.concat([df, new_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded.to_csv(\"train_reversal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in df_expanded.iterrows():\n",
    "    new_row = row.copy()\n",
    "    new_row['response_a'] = row['response_b']\n",
    "    new_row['response_b'] = row['response_a']\n",
    "    new_row['winner_model_b'] = row['winner_model_a']\n",
    "    new_row['winner_model_a'] = row['winner_model_b']    \n",
    "    new_rows.append(new_row)\n",
    "\n",
    "df_swap = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_swap = pd.concat([df_swap, df_expanded], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    if row[\"winner_tie\"] == 1:\n",
    "        return 0\n",
    "    elif row[\"winner_model_a\"] == 1:\n",
    "        return 1\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_swap[\"text\"] = df_expanded_swap.apply(lambda x: [x.response_a, x.response_b], axis=1)\n",
    "df_expanded_swap[\"label\"] = df_expanded_swap.apply(get_label, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_expanded_swap[[\"text\"]]\n",
    "y = df_expanded_swap[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_eval, y_test, y_eval = train_test_split(X_dev, y_dev, test_size=0.5, random_state=42, stratify=y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'microsoft/deberta-v3-small'\n",
    "#model_path = 'google/gemma-2b'\n",
    "model_path = 'state-spaces/mamba-130m-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, add_eos_token=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.special_tokens_map_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.additional_special_tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_train = Dataset.from_pandas(X_train)\n",
    "hf_dataset_eval = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hf_dataset_eval \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pandas(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "hf_dataset_eval = Dataset.from_pandas(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(' <|endoftext|> '.join(hf_dataset_eval['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = hf_dataset_train.map(lambda x: tokenizer(' <|endoftext|> '.join(x['text']), truncation=False), num_proc=10)\n",
    "dataset_eval = hf_dataset_eval.map(lambda x: tokenizer(' <|endoftext|> '.join(x['text']), truncation=False), num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval[\"input_ids\"][0].count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval[\"input_ids\"][0][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.remove_columns(['text', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = dataset_eval.remove_columns(['text', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.add_column('labels', y_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = dataset_eval.add_column('labels', y_eval['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval.save_to_disk(f\"kaggle_eval_{model_path.split()[-1]}\")\n",
    "dataset_train.save_to_disk(f\"kaggle_train_{model_path.split()[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, BitsAndBytesConfig\n",
    "from datasets import Dataset, load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=8,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'microsoft/deberta-v3-small'\n",
    "model_path = 'google/gemma-2b'\n",
    "#model_path = 'state-spaces/mamba-130m-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels = 3, device_map='auto', quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = load_from_disk(f\"kaggle_eval_{model_path.split()[-1]}\")\n",
    "dataset_train = load_from_disk(f\"kaggle_eval_{model_path.split()[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits(predictions, labels):\n",
    "    return torch.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model_output):\n",
    "    metric_f1 = evaluate.load('f1')\n",
    "\n",
    "    predictions, references = model_output\n",
    "\n",
    "    return metric_f1.compute(predictions=predictions, references=references, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_params = {\n",
    "    'lr_scheduler_type' : 'linear',\n",
    "    'optim' : 'adamw_torch',\n",
    "    'save_strategy' : 'no',\n",
    "    'evaluation_strategy': 'epoch',\n",
    "    'output_dir': 'model/',\n",
    "    'overwrite_output_dir' : True,\n",
    "    'learning_rate' : 1e-5,\n",
    "    'num_train_epochs' : 4,\n",
    "    'weight_decay' : 0.01,\n",
    "    'per_device_train_batch_size': 1,\n",
    "    'per_device_eval_batch_size': 1,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'push_to_hub': False,\n",
    "    'fp16' : True,\n",
    "    'report_to' : 'none',\n",
    "    'gradient_accumulation_steps' : 1, # Esto por si peta por batchsize\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(**trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset_train, # TODO\n",
    "    eval_dataset = dataset_eval, # TODO\n",
    "    compute_metrics = compute_metrics,\n",
    "    preprocess_logits_for_metrics = preprocess_logits,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer), # TODO: tokenizer missing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Using cached ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "Using cached widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAMBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, MambaConfig, MambaForCausalLM\n",
    "import torch\n",
    "from hf_mamba_classification import MambaForSequenceClassification\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'state-spaces/mamba-130m-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 3  # the number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of MambaForSequenceClassification were not initialized from the model checkpoint at state-spaces/mamba-130m-hf and are newly initialized: ['classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = MambaForSequenceClassification.from_pretrained(\n",
    "    model_path, \n",
    "    num_labels=num_labels, \n",
    "    use_cache=False  # This needs to be passed when using eval and training Mamba for sequence classification otherwise it will raise an error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval = load_from_disk(f\"kaggle_eval_{model_path.split()[-1]}\")\n",
    "dataset_train = load_from_disk(f\"kaggle_train_{model_path.split()[-1]}\")\n",
    "dataset_train = load_from_disk(f\"kaggle_eval_{model_path.split()[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits(predictions, labels):\n",
    "    return torch.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model_output):\n",
    "    metric_f1 = evaluate.load('f1')\n",
    "\n",
    "    predictions, references = model_output\n",
    "\n",
    "    return metric_f1.compute(predictions=predictions, references=references, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_params = {\n",
    "    'lr_scheduler_type' : 'linear',\n",
    "    'optim' : 'adamw_torch',\n",
    "    'save_strategy' : 'no',\n",
    "    'evaluation_strategy': 'epoch',\n",
    "    'output_dir': 'model/',\n",
    "    'overwrite_output_dir' : True,\n",
    "    'learning_rate' : 1e-5,\n",
    "    'num_train_epochs' : 4,\n",
    "    'weight_decay' : 0.01,\n",
    "    'per_device_train_batch_size': 1,\n",
    "    'per_device_eval_batch_size': 1,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'push_to_hub': False,\n",
    "    'fp16' : True,\n",
    "    'report_to' : 'none',\n",
    "    'gradient_accumulation_steps' : 1, # Esto por si peta por batchsize\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(**trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset_train, # TODO\n",
    "    eval_dataset = dataset_eval, # TODO\n",
    "    compute_metrics = compute_metrics,\n",
    "    preprocess_logits_for_metrics = preprocess_logits,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer), # TODO: tokenizer missing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac57bd38a3a146419bc59e651c6d9a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1003, 'grad_norm': 34.82256317138672, 'learning_rate': 9.996986136226643e-06, 'epoch': 0.0}\n",
      "{'loss': 1.1005, 'grad_norm': 12.611607551574707, 'learning_rate': 9.991963029937714e-06, 'epoch': 0.0}\n",
      "{'loss': 1.0993, 'grad_norm': 13.06774616241455, 'learning_rate': 9.986939923648786e-06, 'epoch': 0.0}\n",
      "{'loss': 1.0861, 'grad_norm': 26.48930549621582, 'learning_rate': 9.981916817359856e-06, 'epoch': 0.01}\n",
      "{'loss': 1.1095, 'grad_norm': 34.82231903076172, 'learning_rate': 9.976893711070927e-06, 'epoch': 0.01}\n",
      "{'loss': 1.0887, 'grad_norm': 33.01508712768555, 'learning_rate': 9.971870604781998e-06, 'epoch': 0.01}\n",
      "{'loss': 1.083, 'grad_norm': 24.58842658996582, 'learning_rate': 9.966847498493068e-06, 'epoch': 0.01}\n",
      "{'loss': 1.1019, 'grad_norm': 35.88905715942383, 'learning_rate': 9.962326702833032e-06, 'epoch': 0.01}\n",
      "{'loss': 1.0827, 'grad_norm': 32.37993240356445, 'learning_rate': 9.957303596544104e-06, 'epoch': 0.01}\n",
      "{'loss': 1.0948, 'grad_norm': 31.899131774902344, 'learning_rate': 9.952280490255175e-06, 'epoch': 0.02}\n",
      "{'loss': 1.1, 'grad_norm': 28.590925216674805, 'learning_rate': 9.947257383966245e-06, 'epoch': 0.02}\n",
      "{'loss': 1.0882, 'grad_norm': 13.811813354492188, 'learning_rate': 9.942234277677316e-06, 'epoch': 0.02}\n",
      "{'loss': 1.0752, 'grad_norm': 14.022884368896484, 'learning_rate': 9.937211171388388e-06, 'epoch': 0.02}\n",
      "{'loss': 1.107, 'grad_norm': 25.959985733032227, 'learning_rate': 9.93218806509946e-06, 'epoch': 0.02}\n",
      "{'loss': 1.0886, 'grad_norm': 16.45142936706543, 'learning_rate': 9.927164958810529e-06, 'epoch': 0.02}\n",
      "{'loss': 1.1105, 'grad_norm': 55.070556640625, 'learning_rate': 9.9221418525216e-06, 'epoch': 0.02}\n",
      "{'loss': 1.0687, 'grad_norm': 9.831274032592773, 'learning_rate': 9.917118746232672e-06, 'epoch': 0.03}\n",
      "{'loss': 1.0912, 'grad_norm': 30.39455795288086, 'learning_rate': 9.912095639943742e-06, 'epoch': 0.03}\n",
      "{'loss': 1.099, 'grad_norm': 24.373992919921875, 'learning_rate': 9.907072533654813e-06, 'epoch': 0.03}\n",
      "{'loss': 1.1034, 'grad_norm': 28.80276107788086, 'learning_rate': 9.902049427365884e-06, 'epoch': 0.03}\n",
      "{'loss': 1.0824, 'grad_norm': 34.688419342041016, 'learning_rate': 9.897026321076954e-06, 'epoch': 0.03}\n",
      "{'loss': 1.0792, 'grad_norm': 35.4826545715332, 'learning_rate': 9.892003214788026e-06, 'epoch': 0.03}\n",
      "{'loss': 1.0636, 'grad_norm': 29.112829208374023, 'learning_rate': 9.886980108499097e-06, 'epoch': 0.03}\n",
      "{'loss': 1.0809, 'grad_norm': 7.1961822509765625, 'learning_rate': 9.881957002210167e-06, 'epoch': 0.04}\n",
      "{'loss': 1.1004, 'grad_norm': 23.742137908935547, 'learning_rate': 9.876933895921238e-06, 'epoch': 0.04}\n",
      "{'loss': 1.0875, 'grad_norm': 7.792693138122559, 'learning_rate': 9.87191078963231e-06, 'epoch': 0.04}\n",
      "{'loss': 1.0782, 'grad_norm': 29.283153533935547, 'learning_rate': 9.866887683343381e-06, 'epoch': 0.04}\n",
      "{'loss': 1.1058, 'grad_norm': 23.328203201293945, 'learning_rate': 9.86186457705445e-06, 'epoch': 0.04}\n",
      "{'loss': 1.0688, 'grad_norm': 22.869937896728516, 'learning_rate': 9.856841470765522e-06, 'epoch': 0.04}\n",
      "{'loss': 1.0837, 'grad_norm': 54.6837272644043, 'learning_rate': 9.851818364476594e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0958, 'grad_norm': 17.8129825592041, 'learning_rate': 9.846795258187663e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0422, 'grad_norm': 8.52702522277832, 'learning_rate': 9.841772151898735e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0857, 'grad_norm': 37.37759017944336, 'learning_rate': 9.836749045609806e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0321, 'grad_norm': 26.453529357910156, 'learning_rate': 9.831725939320876e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0258, 'grad_norm': 5.787786483764648, 'learning_rate': 9.826702833031947e-06, 'epoch': 0.05}\n",
      "{'loss': 1.1587, 'grad_norm': 34.14860916137695, 'learning_rate': 9.821679726743019e-06, 'epoch': 0.05}\n",
      "{'loss': 1.0685, 'grad_norm': 40.62260055541992, 'learning_rate': 9.816656620454089e-06, 'epoch': 0.06}\n",
      "{'loss': 1.0631, 'grad_norm': 6.190193176269531, 'learning_rate': 9.81163351416516e-06, 'epoch': 0.06}\n",
      "{'loss': 1.1125, 'grad_norm': 18.306718826293945, 'learning_rate': 9.806610407876231e-06, 'epoch': 0.06}\n",
      "{'loss': 1.1002, 'grad_norm': 27.59922981262207, 'learning_rate': 9.801587301587301e-06, 'epoch': 0.06}\n",
      "{'loss': 1.1014, 'grad_norm': 6.024371147155762, 'learning_rate': 9.796564195298374e-06, 'epoch': 0.06}\n",
      "{'loss': 0.9901, 'grad_norm': 42.39772033691406, 'learning_rate': 9.791541089009444e-06, 'epoch': 0.06}\n",
      "{'loss': 1.0764, 'grad_norm': 5.731570243835449, 'learning_rate': 9.786517982720515e-06, 'epoch': 0.06}\n",
      "{'loss': 1.157, 'grad_norm': 25.906147003173828, 'learning_rate': 9.781494876431587e-06, 'epoch': 0.07}\n",
      "{'loss': 1.0712, 'grad_norm': 26.148576736450195, 'learning_rate': 9.776471770142657e-06, 'epoch': 0.07}\n",
      "{'loss': 1.0703, 'grad_norm': 18.351945877075195, 'learning_rate': 9.771448663853728e-06, 'epoch': 0.07}\n",
      "{'loss': 1.1368, 'grad_norm': 25.440156936645508, 'learning_rate': 9.7664255575648e-06, 'epoch': 0.07}\n",
      "{'loss': 1.1773, 'grad_norm': 17.642480850219727, 'learning_rate': 9.76140245127587e-06, 'epoch': 0.07}\n",
      "{'loss': 1.0811, 'grad_norm': 27.439891815185547, 'learning_rate': 9.75637934498694e-06, 'epoch': 0.07}\n",
      "{'loss': 1.0576, 'grad_norm': 7.159214019775391, 'learning_rate': 9.751356238698012e-06, 'epoch': 0.08}\n",
      "{'loss': 1.1284, 'grad_norm': 18.391937255859375, 'learning_rate': 9.746333132409082e-06, 'epoch': 0.08}\n",
      "{'loss': 1.0582, 'grad_norm': 7.84990930557251, 'learning_rate': 9.741310026120153e-06, 'epoch': 0.08}\n",
      "{'loss': 1.0554, 'grad_norm': 23.09515953063965, 'learning_rate': 9.736286919831225e-06, 'epoch': 0.08}\n",
      "{'loss': 1.0594, 'grad_norm': 6.824033737182617, 'learning_rate': 9.731263813542296e-06, 'epoch': 0.08}\n",
      "{'loss': 1.0587, 'grad_norm': 36.9887580871582, 'learning_rate': 9.726240707253366e-06, 'epoch': 0.08}\n",
      "{'loss': 1.0412, 'grad_norm': 26.313859939575195, 'learning_rate': 9.721217600964437e-06, 'epoch': 0.08}\n",
      "{'loss': 1.1283, 'grad_norm': 19.934253692626953, 'learning_rate': 9.716194494675509e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0715, 'grad_norm': 19.18598175048828, 'learning_rate': 9.711171388386578e-06, 'epoch': 0.09}\n",
      "{'loss': 1.1296, 'grad_norm': 20.36558723449707, 'learning_rate': 9.70614828209765e-06, 'epoch': 0.09}\n",
      "{'loss': 1.1168, 'grad_norm': 5.314630031585693, 'learning_rate': 9.701125175808721e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0899, 'grad_norm': 17.398557662963867, 'learning_rate': 9.696102069519791e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0124, 'grad_norm': 25.884889602661133, 'learning_rate': 9.691078963230863e-06, 'epoch': 0.09}\n",
      "{'loss': 1.0161, 'grad_norm': 18.409786224365234, 'learning_rate': 9.686055856941934e-06, 'epoch': 0.09}\n",
      "{'loss': 1.1002, 'grad_norm': 20.02427101135254, 'learning_rate': 9.681032750653004e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0987, 'grad_norm': 24.22508430480957, 'learning_rate': 9.676009644364077e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0812, 'grad_norm': 32.69746780395508, 'learning_rate': 9.670986538075147e-06, 'epoch': 0.1}\n",
      "{'loss': 1.1338, 'grad_norm': 8.256875038146973, 'learning_rate': 9.665963431786218e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0849, 'grad_norm': 19.169200897216797, 'learning_rate': 9.660940325497288e-06, 'epoch': 0.1}\n",
      "{'loss': 1.1103, 'grad_norm': 25.815391540527344, 'learning_rate': 9.655917219208359e-06, 'epoch': 0.1}\n",
      "{'loss': 1.0469, 'grad_norm': 24.059356689453125, 'learning_rate': 9.65089411291943e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0547, 'grad_norm': 19.17827796936035, 'learning_rate': 9.6458710066305e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0498, 'grad_norm': 26.148584365844727, 'learning_rate': 9.640847900341572e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0459, 'grad_norm': 41.6459846496582, 'learning_rate': 9.635824794052643e-06, 'epoch': 0.11}\n",
      "{'loss': 1.1259, 'grad_norm': 26.689802169799805, 'learning_rate': 9.630801687763713e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0835, 'grad_norm': 33.55667495727539, 'learning_rate': 9.625778581474784e-06, 'epoch': 0.11}\n",
      "{'loss': 1.1236, 'grad_norm': 6.343354225158691, 'learning_rate': 9.620755475185856e-06, 'epoch': 0.11}\n",
      "{'loss': 1.0801, 'grad_norm': 42.84576416015625, 'learning_rate': 9.615732368896926e-06, 'epoch': 0.12}\n",
      "{'loss': 1.1145, 'grad_norm': 19.003599166870117, 'learning_rate': 9.610709262607999e-06, 'epoch': 0.12}\n",
      "{'loss': 1.0942, 'grad_norm': 20.99952507019043, 'learning_rate': 9.605686156319068e-06, 'epoch': 0.12}\n",
      "{'loss': 1.1121, 'grad_norm': 17.113052368164062, 'learning_rate': 9.60066305003014e-06, 'epoch': 0.12}\n",
      "{'loss': 1.0412, 'grad_norm': 38.09003448486328, 'learning_rate': 9.595639943741211e-06, 'epoch': 0.12}\n",
      "{'loss': 1.1067, 'grad_norm': 20.100542068481445, 'learning_rate': 9.590616837452281e-06, 'epoch': 0.12}\n",
      "{'loss': 1.0363, 'grad_norm': 21.87981605529785, 'learning_rate': 9.585593731163352e-06, 'epoch': 0.13}\n",
      "{'loss': 1.07, 'grad_norm': 5.2940239906311035, 'learning_rate': 9.580570624874424e-06, 'epoch': 0.13}\n",
      "{'loss': 1.1108, 'grad_norm': 34.943321228027344, 'learning_rate': 9.575547518585494e-06, 'epoch': 0.13}\n",
      "{'loss': 1.0881, 'grad_norm': 21.464677810668945, 'learning_rate': 9.570524412296565e-06, 'epoch': 0.13}\n",
      "{'loss': 1.1081, 'grad_norm': 19.092464447021484, 'learning_rate': 9.565501306007636e-06, 'epoch': 0.13}\n",
      "{'loss': 1.1067, 'grad_norm': 7.906795024871826, 'learning_rate': 9.560478199718706e-06, 'epoch': 0.13}\n",
      "{'loss': 1.0849, 'grad_norm': 6.833160877227783, 'learning_rate': 9.555455093429778e-06, 'epoch': 0.13}\n",
      "{'loss': 1.0973, 'grad_norm': 9.662911415100098, 'learning_rate': 9.550431987140849e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0754, 'grad_norm': 23.190303802490234, 'learning_rate': 9.54540888085192e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0728, 'grad_norm': 7.21466064453125, 'learning_rate': 9.54038577456299e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0771, 'grad_norm': 17.700481414794922, 'learning_rate': 9.535362668274062e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0243, 'grad_norm': 36.018463134765625, 'learning_rate': 9.530339561985133e-06, 'epoch': 0.14}\n",
      "{'loss': 1.1025, 'grad_norm': 16.96797752380371, 'learning_rate': 9.525316455696203e-06, 'epoch': 0.14}\n",
      "{'loss': 1.0848, 'grad_norm': 18.265132904052734, 'learning_rate': 9.520293349407274e-06, 'epoch': 0.14}\n",
      "{'loss': 1.1048, 'grad_norm': 22.03938865661621, 'learning_rate': 9.515270243118346e-06, 'epoch': 0.15}\n",
      "{'loss': 1.1127, 'grad_norm': 38.56303024291992, 'learning_rate': 9.510247136829415e-06, 'epoch': 0.15}\n",
      "{'loss': 1.0205, 'grad_norm': 23.488481521606445, 'learning_rate': 9.505224030540487e-06, 'epoch': 0.15}\n",
      "{'loss': 1.0621, 'grad_norm': 7.402678966522217, 'learning_rate': 9.500200924251558e-06, 'epoch': 0.15}\n",
      "{'loss': 1.0424, 'grad_norm': 22.032115936279297, 'learning_rate': 9.495177817962628e-06, 'epoch': 0.15}\n",
      "{'loss': 1.1167, 'grad_norm': 39.382347106933594, 'learning_rate': 9.4901547116737e-06, 'epoch': 0.15}\n",
      "{'loss': 1.0622, 'grad_norm': 22.512346267700195, 'learning_rate': 9.485131605384771e-06, 'epoch': 0.16}\n",
      "{'loss': 1.0597, 'grad_norm': 17.666715621948242, 'learning_rate': 9.48010849909584e-06, 'epoch': 0.16}\n",
      "{'loss': 1.059, 'grad_norm': 18.57941436767578, 'learning_rate': 9.475085392806914e-06, 'epoch': 0.16}\n",
      "{'loss': 1.0849, 'grad_norm': 5.0966572761535645, 'learning_rate': 9.470062286517983e-06, 'epoch': 0.16}\n",
      "{'loss': 1.0637, 'grad_norm': 36.56715393066406, 'learning_rate': 9.465039180229055e-06, 'epoch': 0.16}\n",
      "{'loss': 0.9811, 'grad_norm': 5.508941650390625, 'learning_rate': 9.460016073940126e-06, 'epoch': 0.16}\n",
      "{'loss': 1.0333, 'grad_norm': 22.787446975708008, 'learning_rate': 9.454992967651196e-06, 'epoch': 0.16}\n",
      "{'loss': 1.1209, 'grad_norm': 34.06853485107422, 'learning_rate': 9.449969861362268e-06, 'epoch': 0.17}\n",
      "{'loss': 1.0574, 'grad_norm': 24.119096755981445, 'learning_rate': 9.444946755073337e-06, 'epoch': 0.17}\n",
      "{'loss': 1.1229, 'grad_norm': 34.126277923583984, 'learning_rate': 9.439923648784409e-06, 'epoch': 0.17}\n",
      "{'loss': 1.122, 'grad_norm': 25.923057556152344, 'learning_rate': 9.43490054249548e-06, 'epoch': 0.17}\n",
      "{'loss': 1.067, 'grad_norm': 22.836681365966797, 'learning_rate': 9.42987743620655e-06, 'epoch': 0.17}\n",
      "{'loss': 1.047, 'grad_norm': 17.45990753173828, 'learning_rate': 9.424854329917621e-06, 'epoch': 0.17}\n",
      "{'loss': 1.0655, 'grad_norm': 20.16387939453125, 'learning_rate': 9.419831223628693e-06, 'epoch': 0.17}\n",
      "{'loss': 1.0472, 'grad_norm': 39.548770904541016, 'learning_rate': 9.414808117339762e-06, 'epoch': 0.18}\n",
      "{'loss': 1.0915, 'grad_norm': 36.12784957885742, 'learning_rate': 9.409785011050836e-06, 'epoch': 0.18}\n",
      "{'loss': 1.0415, 'grad_norm': 4.581452369689941, 'learning_rate': 9.404761904761905e-06, 'epoch': 0.18}\n",
      "{'loss': 1.157, 'grad_norm': 33.800315856933594, 'learning_rate': 9.399738798472977e-06, 'epoch': 0.18}\n",
      "{'loss': 1.0337, 'grad_norm': 36.31974792480469, 'learning_rate': 9.394715692184048e-06, 'epoch': 0.18}\n",
      "{'loss': 1.0583, 'grad_norm': 18.585317611694336, 'learning_rate': 9.389692585895118e-06, 'epoch': 0.18}\n",
      "{'loss': 1.1177, 'grad_norm': 37.912925720214844, 'learning_rate': 9.38466947960619e-06, 'epoch': 0.19}\n",
      "{'loss': 1.0475, 'grad_norm': 18.752431869506836, 'learning_rate': 9.37964637331726e-06, 'epoch': 0.19}\n",
      "{'loss': 1.079, 'grad_norm': 19.259441375732422, 'learning_rate': 9.37462326702833e-06, 'epoch': 0.19}\n",
      "{'loss': 1.0579, 'grad_norm': 5.856009483337402, 'learning_rate': 9.369600160739402e-06, 'epoch': 0.19}\n",
      "{'loss': 1.0714, 'grad_norm': 40.78889083862305, 'learning_rate': 9.364577054450473e-06, 'epoch': 0.19}\n",
      "{'loss': 1.1084, 'grad_norm': 22.80830955505371, 'learning_rate': 9.359553948161543e-06, 'epoch': 0.19}\n",
      "{'loss': 1.0857, 'grad_norm': 41.101600646972656, 'learning_rate': 9.354530841872615e-06, 'epoch': 0.19}\n",
      "{'loss': 1.0521, 'grad_norm': 36.10568618774414, 'learning_rate': 9.349507735583686e-06, 'epoch': 0.2}\n",
      "{'loss': 1.0729, 'grad_norm': 26.556142807006836, 'learning_rate': 9.344484629294757e-06, 'epoch': 0.2}\n",
      "{'loss': 1.1636, 'grad_norm': 19.485858917236328, 'learning_rate': 9.339461523005827e-06, 'epoch': 0.2}\n",
      "{'loss': 1.0808, 'grad_norm': 17.793861389160156, 'learning_rate': 9.334438416716899e-06, 'epoch': 0.2}\n",
      "{'loss': 1.152, 'grad_norm': 54.675743103027344, 'learning_rate': 9.32941531042797e-06, 'epoch': 0.2}\n",
      "{'loss': 1.1131, 'grad_norm': 35.453487396240234, 'learning_rate': 9.32439220413904e-06, 'epoch': 0.2}\n",
      "{'loss': 1.06, 'grad_norm': 27.141870498657227, 'learning_rate': 9.319369097850111e-06, 'epoch': 0.2}\n",
      "{'loss': 1.0808, 'grad_norm': 23.99867820739746, 'learning_rate': 9.314345991561183e-06, 'epoch': 0.21}\n",
      "{'loss': 1.0625, 'grad_norm': 8.393251419067383, 'learning_rate': 9.309322885272252e-06, 'epoch': 0.21}\n",
      "{'loss': 1.0364, 'grad_norm': 19.26712989807129, 'learning_rate': 9.304299778983324e-06, 'epoch': 0.21}\n",
      "{'loss': 1.1248, 'grad_norm': 18.854793548583984, 'learning_rate': 9.299276672694395e-06, 'epoch': 0.21}\n",
      "{'loss': 1.0918, 'grad_norm': 28.681509017944336, 'learning_rate': 9.294253566405465e-06, 'epoch': 0.21}\n",
      "{'loss': 1.0837, 'grad_norm': 35.262271881103516, 'learning_rate': 9.289230460116538e-06, 'epoch': 0.21}\n",
      "{'loss': 1.1135, 'grad_norm': 17.993839263916016, 'learning_rate': 9.284207353827608e-06, 'epoch': 0.22}\n",
      "{'loss': 1.0404, 'grad_norm': 6.7880144119262695, 'learning_rate': 9.27918424753868e-06, 'epoch': 0.22}\n",
      "{'loss': 1.1143, 'grad_norm': 32.012699127197266, 'learning_rate': 9.27416114124975e-06, 'epoch': 0.22}\n",
      "{'loss': 1.1103, 'grad_norm': 22.03135108947754, 'learning_rate': 9.26913803496082e-06, 'epoch': 0.22}\n",
      "{'loss': 1.0907, 'grad_norm': 22.65675926208496, 'learning_rate': 9.264114928671892e-06, 'epoch': 0.22}\n",
      "{'loss': 1.1142, 'grad_norm': 37.908729553222656, 'learning_rate': 9.259091822382963e-06, 'epoch': 0.22}\n",
      "{'loss': 1.0117, 'grad_norm': 16.610395431518555, 'learning_rate': 9.254068716094033e-06, 'epoch': 0.22}\n",
      "{'loss': 1.0266, 'grad_norm': 7.753237724304199, 'learning_rate': 9.249045609805104e-06, 'epoch': 0.23}\n",
      "{'loss': 1.08, 'grad_norm': 24.37249755859375, 'learning_rate': 9.244022503516176e-06, 'epoch': 0.23}\n",
      "{'loss': 1.0965, 'grad_norm': 21.76657485961914, 'learning_rate': 9.238999397227246e-06, 'epoch': 0.23}\n",
      "{'loss': 1.116, 'grad_norm': 17.897397994995117, 'learning_rate': 9.233976290938317e-06, 'epoch': 0.23}\n",
      "{'loss': 1.1056, 'grad_norm': 8.50179672241211, 'learning_rate': 9.228953184649387e-06, 'epoch': 0.23}\n",
      "{'loss': 1.0583, 'grad_norm': 23.22079849243164, 'learning_rate': 9.22393007836046e-06, 'epoch': 0.23}\n",
      "{'loss': 1.0649, 'grad_norm': 34.38641357421875, 'learning_rate': 9.21890697207153e-06, 'epoch': 0.24}\n",
      "{'loss': 1.0868, 'grad_norm': 24.09549331665039, 'learning_rate': 9.2138838657826e-06, 'epoch': 0.24}\n",
      "{'loss': 1.0595, 'grad_norm': 17.588743209838867, 'learning_rate': 9.208860759493673e-06, 'epoch': 0.24}\n",
      "{'loss': 1.0434, 'grad_norm': 21.730741500854492, 'learning_rate': 9.203837653204742e-06, 'epoch': 0.24}\n",
      "{'loss': 1.0819, 'grad_norm': 39.26069259643555, 'learning_rate': 9.198814546915814e-06, 'epoch': 0.24}\n",
      "{'loss': 1.0553, 'grad_norm': 31.034439086914062, 'learning_rate': 9.193791440626885e-06, 'epoch': 0.24}\n",
      "{'loss': 1.1242, 'grad_norm': 36.68644332885742, 'learning_rate': 9.188768334337955e-06, 'epoch': 0.24}\n",
      "{'loss': 0.9893, 'grad_norm': 18.53540802001953, 'learning_rate': 9.183745228049026e-06, 'epoch': 0.25}\n",
      "{'loss': 1.0874, 'grad_norm': 16.79457664489746, 'learning_rate': 9.178722121760098e-06, 'epoch': 0.25}\n",
      "{'loss': 1.1135, 'grad_norm': 17.797231674194336, 'learning_rate': 9.173699015471167e-06, 'epoch': 0.25}\n",
      "{'loss': 1.0833, 'grad_norm': 39.01200866699219, 'learning_rate': 9.168675909182239e-06, 'epoch': 0.25}\n",
      "{'loss': 1.0482, 'grad_norm': 21.183975219726562, 'learning_rate': 9.16365280289331e-06, 'epoch': 0.25}\n",
      "{'loss': 1.0746, 'grad_norm': 28.279563903808594, 'learning_rate': 9.15862969660438e-06, 'epoch': 0.25}\n",
      "{'loss': 1.0815, 'grad_norm': 7.971589088439941, 'learning_rate': 9.153606590315451e-06, 'epoch': 0.25}\n",
      "{'loss': 1.0582, 'grad_norm': 32.419044494628906, 'learning_rate': 9.148583484026523e-06, 'epoch': 0.26}\n",
      "{'loss': 1.0884, 'grad_norm': 18.8771915435791, 'learning_rate': 9.143560377737594e-06, 'epoch': 0.26}\n",
      "{'loss': 1.0727, 'grad_norm': 9.484493255615234, 'learning_rate': 9.138537271448664e-06, 'epoch': 0.26}\n",
      "{'loss': 1.0815, 'grad_norm': 27.918773651123047, 'learning_rate': 9.133514165159736e-06, 'epoch': 0.26}\n",
      "{'loss': 1.1117, 'grad_norm': 22.81620979309082, 'learning_rate': 9.128491058870807e-06, 'epoch': 0.26}\n",
      "{'loss': 1.0489, 'grad_norm': 24.625667572021484, 'learning_rate': 9.123467952581877e-06, 'epoch': 0.26}\n",
      "{'loss': 1.0971, 'grad_norm': 8.321639060974121, 'learning_rate': 9.118444846292948e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0622, 'grad_norm': 22.867931365966797, 'learning_rate': 9.11342174000402e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0787, 'grad_norm': 23.9987850189209, 'learning_rate': 9.10839863371509e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0488, 'grad_norm': 15.595807075500488, 'learning_rate': 9.10337552742616e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0601, 'grad_norm': 24.791343688964844, 'learning_rate': 9.098352421137232e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0595, 'grad_norm': 9.882368087768555, 'learning_rate': 9.093329314848302e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0398, 'grad_norm': 7.361598014831543, 'learning_rate': 9.088306208559375e-06, 'epoch': 0.27}\n",
      "{'loss': 1.0652, 'grad_norm': 24.491470336914062, 'learning_rate': 9.083283102270445e-06, 'epoch': 0.28}\n",
      "{'loss': 1.1119, 'grad_norm': 18.67975425720215, 'learning_rate': 9.078259995981516e-06, 'epoch': 0.28}\n",
      "{'loss': 1.0624, 'grad_norm': 18.1702880859375, 'learning_rate': 9.073236889692588e-06, 'epoch': 0.28}\n",
      "{'loss': 1.0676, 'grad_norm': 32.216407775878906, 'learning_rate': 9.068213783403657e-06, 'epoch': 0.28}\n",
      "{'loss': 1.0891, 'grad_norm': 9.328202247619629, 'learning_rate': 9.063190677114729e-06, 'epoch': 0.28}\n",
      "{'loss': 1.0956, 'grad_norm': 14.48598861694336, 'learning_rate': 9.0581675708258e-06, 'epoch': 0.28}\n",
      "{'loss': 1.0804, 'grad_norm': 9.989452362060547, 'learning_rate': 9.05314446453687e-06, 'epoch': 0.28}\n",
      "{'loss': 1.045, 'grad_norm': 27.350872039794922, 'learning_rate': 9.048121358247941e-06, 'epoch': 0.29}\n",
      "{'loss': 1.0357, 'grad_norm': 22.758901596069336, 'learning_rate': 9.043098251959013e-06, 'epoch': 0.29}\n",
      "{'loss': 1.1075, 'grad_norm': 16.816072463989258, 'learning_rate': 9.038075145670083e-06, 'epoch': 0.29}\n",
      "{'loss': 1.07, 'grad_norm': 33.00249481201172, 'learning_rate': 9.033052039381154e-06, 'epoch': 0.29}\n",
      "{'loss': 1.091, 'grad_norm': 27.26618766784668, 'learning_rate': 9.028028933092225e-06, 'epoch': 0.29}\n",
      "{'loss': 1.0701, 'grad_norm': 17.903377532958984, 'learning_rate': 9.023005826803297e-06, 'epoch': 0.29}\n",
      "{'loss': 1.0765, 'grad_norm': 23.164091110229492, 'learning_rate': 9.017982720514367e-06, 'epoch': 0.3}\n",
      "{'loss': 1.0499, 'grad_norm': 7.827521800994873, 'learning_rate': 9.012959614225438e-06, 'epoch': 0.3}\n",
      "{'loss': 1.1167, 'grad_norm': 22.94695281982422, 'learning_rate': 9.00793650793651e-06, 'epoch': 0.3}\n",
      "{'loss': 1.0991, 'grad_norm': 7.628890514373779, 'learning_rate': 9.00291340164758e-06, 'epoch': 0.3}\n",
      "{'loss': 1.0309, 'grad_norm': 43.24273681640625, 'learning_rate': 8.99789029535865e-06, 'epoch': 0.3}\n",
      "{'loss': 1.085, 'grad_norm': 40.02931594848633, 'learning_rate': 8.992867189069722e-06, 'epoch': 0.3}\n",
      "{'loss': 1.0662, 'grad_norm': 6.057170391082764, 'learning_rate': 8.987844082780792e-06, 'epoch': 0.3}\n",
      "{'loss': 1.0609, 'grad_norm': 25.480443954467773, 'learning_rate': 8.982820976491863e-06, 'epoch': 0.31}\n",
      "{'loss': 1.0307, 'grad_norm': 24.071054458618164, 'learning_rate': 8.977797870202935e-06, 'epoch': 0.31}\n",
      "{'loss': 1.0937, 'grad_norm': 23.504838943481445, 'learning_rate': 8.972774763914004e-06, 'epoch': 0.31}\n",
      "{'loss': 1.097, 'grad_norm': 19.07605743408203, 'learning_rate': 8.967751657625076e-06, 'epoch': 0.31}\n",
      "{'loss': 1.077, 'grad_norm': 5.201067924499512, 'learning_rate': 8.962728551336147e-06, 'epoch': 0.31}\n",
      "{'loss': 1.0221, 'grad_norm': 25.40057945251465, 'learning_rate': 8.957705445047219e-06, 'epoch': 0.31}\n",
      "{'loss': 1.0671, 'grad_norm': 6.915462017059326, 'learning_rate': 8.952682338758288e-06, 'epoch': 0.31}\n",
      "{'loss': 1.0821, 'grad_norm': 18.350927352905273, 'learning_rate': 8.94765923246936e-06, 'epoch': 0.32}\n",
      "{'loss': 1.1502, 'grad_norm': 19.832096099853516, 'learning_rate': 8.942636126180431e-06, 'epoch': 0.32}\n",
      "{'loss': 1.1119, 'grad_norm': 33.35978698730469, 'learning_rate': 8.937613019891501e-06, 'epoch': 0.32}\n",
      "{'loss': 1.0816, 'grad_norm': 23.506834030151367, 'learning_rate': 8.933092224231465e-06, 'epoch': 0.32}\n",
      "{'loss': 1.0674, 'grad_norm': 16.733606338500977, 'learning_rate': 8.928069117942537e-06, 'epoch': 0.32}\n",
      "{'loss': 1.0944, 'grad_norm': 27.71169662475586, 'learning_rate': 8.923046011653608e-06, 'epoch': 0.32}\n",
      "{'loss': 1.0782, 'grad_norm': 23.05667495727539, 'learning_rate': 8.918022905364678e-06, 'epoch': 0.33}\n",
      "{'loss': 0.97, 'grad_norm': 28.31175994873047, 'learning_rate': 8.91299979907575e-06, 'epoch': 0.33}\n",
      "{'loss': 1.108, 'grad_norm': 22.850404739379883, 'learning_rate': 8.90797669278682e-06, 'epoch': 0.33}\n",
      "{'loss': 1.1035, 'grad_norm': 42.20133972167969, 'learning_rate': 8.90295358649789e-06, 'epoch': 0.33}\n",
      "{'loss': 1.0536, 'grad_norm': 26.35681915283203, 'learning_rate': 8.897930480208962e-06, 'epoch': 0.33}\n",
      "{'loss': 1.0492, 'grad_norm': 36.46323013305664, 'learning_rate': 8.892907373920033e-06, 'epoch': 0.33}\n",
      "{'loss': 1.0791, 'grad_norm': 42.82890319824219, 'learning_rate': 8.887884267631105e-06, 'epoch': 0.33}\n",
      "{'loss': 1.1018, 'grad_norm': 34.95266342163086, 'learning_rate': 8.882861161342174e-06, 'epoch': 0.34}\n",
      "{'loss': 1.0157, 'grad_norm': 27.673748016357422, 'learning_rate': 8.877838055053246e-06, 'epoch': 0.34}\n",
      "{'loss': 1.091, 'grad_norm': 17.88089942932129, 'learning_rate': 8.872814948764317e-06, 'epoch': 0.34}\n",
      "{'loss': 1.0017, 'grad_norm': 41.979644775390625, 'learning_rate': 8.867791842475387e-06, 'epoch': 0.34}\n",
      "{'loss': 1.0658, 'grad_norm': 19.086307525634766, 'learning_rate': 8.862768736186458e-06, 'epoch': 0.34}\n",
      "{'loss': 1.089, 'grad_norm': 39.7841911315918, 'learning_rate': 8.85774562989753e-06, 'epoch': 0.34}\n",
      "{'loss': 1.0308, 'grad_norm': 6.260104179382324, 'learning_rate': 8.8527225236086e-06, 'epoch': 0.35}\n",
      "{'loss': 1.1013, 'grad_norm': 20.466690063476562, 'learning_rate': 8.847699417319671e-06, 'epoch': 0.35}\n",
      "{'loss': 1.1053, 'grad_norm': 20.149179458618164, 'learning_rate': 8.842676311030742e-06, 'epoch': 0.35}\n",
      "{'loss': 1.1121, 'grad_norm': 26.91901969909668, 'learning_rate': 8.837653204741812e-06, 'epoch': 0.35}\n",
      "{'loss': 1.1023, 'grad_norm': 36.76882553100586, 'learning_rate': 8.832630098452884e-06, 'epoch': 0.35}\n",
      "{'loss': 1.0598, 'grad_norm': 22.886754989624023, 'learning_rate': 8.827606992163955e-06, 'epoch': 0.35}\n",
      "{'loss': 1.0752, 'grad_norm': 19.354698181152344, 'learning_rate': 8.822583885875026e-06, 'epoch': 0.35}\n",
      "{'loss': 1.0684, 'grad_norm': 20.464542388916016, 'learning_rate': 8.817560779586096e-06, 'epoch': 0.36}\n",
      "{'loss': 1.0633, 'grad_norm': 26.37238311767578, 'learning_rate': 8.812537673297168e-06, 'epoch': 0.36}\n",
      "{'loss': 1.0521, 'grad_norm': 23.982540130615234, 'learning_rate': 8.807514567008239e-06, 'epoch': 0.36}\n",
      "{'loss': 1.0602, 'grad_norm': 26.623340606689453, 'learning_rate': 8.802491460719309e-06, 'epoch': 0.36}\n",
      "{'loss': 1.1441, 'grad_norm': 35.824039459228516, 'learning_rate': 8.79746835443038e-06, 'epoch': 0.36}\n",
      "{'loss': 1.1479, 'grad_norm': 18.703277587890625, 'learning_rate': 8.792445248141452e-06, 'epoch': 0.36}\n",
      "{'loss': 0.9972, 'grad_norm': 27.362401962280273, 'learning_rate': 8.787422141852521e-06, 'epoch': 0.36}\n",
      "{'loss': 1.0595, 'grad_norm': 4.724740028381348, 'learning_rate': 8.782399035563593e-06, 'epoch': 0.37}\n",
      "{'loss': 1.0702, 'grad_norm': 22.053428649902344, 'learning_rate': 8.777375929274664e-06, 'epoch': 0.37}\n",
      "{'loss': 1.0492, 'grad_norm': 23.754392623901367, 'learning_rate': 8.772352822985734e-06, 'epoch': 0.37}\n",
      "{'loss': 1.124, 'grad_norm': 33.600955963134766, 'learning_rate': 8.767329716696807e-06, 'epoch': 0.37}\n",
      "{'loss': 1.0666, 'grad_norm': 8.246692657470703, 'learning_rate': 8.762306610407877e-06, 'epoch': 0.37}\n",
      "{'loss': 1.0615, 'grad_norm': 27.04317855834961, 'learning_rate': 8.757283504118948e-06, 'epoch': 0.37}\n",
      "{'loss': 1.0576, 'grad_norm': 8.194350242614746, 'learning_rate': 8.75226039783002e-06, 'epoch': 0.38}\n",
      "{'loss': 1.0755, 'grad_norm': 36.94575500488281, 'learning_rate': 8.74723729154109e-06, 'epoch': 0.38}\n",
      "{'loss': 1.0596, 'grad_norm': 18.738216400146484, 'learning_rate': 8.742214185252161e-06, 'epoch': 0.38}\n",
      "{'loss': 1.0141, 'grad_norm': 6.174663543701172, 'learning_rate': 8.737191078963232e-06, 'epoch': 0.38}\n",
      "{'loss': 1.0884, 'grad_norm': 33.596317291259766, 'learning_rate': 8.732167972674302e-06, 'epoch': 0.38}\n",
      "{'loss': 1.1299, 'grad_norm': 36.5966796875, 'learning_rate': 8.727144866385373e-06, 'epoch': 0.38}\n",
      "{'loss': 1.0917, 'grad_norm': 18.419519424438477, 'learning_rate': 8.722121760096445e-06, 'epoch': 0.38}\n",
      "{'loss': 1.1119, 'grad_norm': 6.246683597564697, 'learning_rate': 8.717098653807515e-06, 'epoch': 0.39}\n",
      "{'loss': 1.0794, 'grad_norm': 6.531096935272217, 'learning_rate': 8.712075547518586e-06, 'epoch': 0.39}\n",
      "{'loss': 1.1316, 'grad_norm': 17.432912826538086, 'learning_rate': 8.707052441229658e-06, 'epoch': 0.39}\n",
      "{'loss': 1.135, 'grad_norm': 18.228078842163086, 'learning_rate': 8.702029334940729e-06, 'epoch': 0.39}\n",
      "{'loss': 1.06, 'grad_norm': 33.957054138183594, 'learning_rate': 8.697006228651799e-06, 'epoch': 0.39}\n",
      "{'loss': 1.1194, 'grad_norm': 7.146446704864502, 'learning_rate': 8.69198312236287e-06, 'epoch': 0.39}\n",
      "{'loss': 1.0542, 'grad_norm': 23.083269119262695, 'learning_rate': 8.686960016073942e-06, 'epoch': 0.39}\n",
      "{'loss': 1.0614, 'grad_norm': 38.5316047668457, 'learning_rate': 8.681936909785011e-06, 'epoch': 0.4}\n",
      "{'loss': 1.0654, 'grad_norm': 18.63304901123047, 'learning_rate': 8.676913803496083e-06, 'epoch': 0.4}\n",
      "{'loss': 1.0645, 'grad_norm': 15.267038345336914, 'learning_rate': 8.671890697207154e-06, 'epoch': 0.4}\n",
      "{'loss': 1.101, 'grad_norm': 11.123763084411621, 'learning_rate': 8.666867590918224e-06, 'epoch': 0.4}\n",
      "{'loss': 1.0585, 'grad_norm': 16.10366439819336, 'learning_rate': 8.661844484629295e-06, 'epoch': 0.4}\n",
      "{'loss': 1.0662, 'grad_norm': 28.65528106689453, 'learning_rate': 8.656821378340367e-06, 'epoch': 0.4}\n",
      "{'loss': 1.058, 'grad_norm': 36.72369384765625, 'learning_rate': 8.651798272051436e-06, 'epoch': 0.41}\n",
      "{'loss': 1.044, 'grad_norm': 17.40238380432129, 'learning_rate': 8.646775165762508e-06, 'epoch': 0.41}\n",
      "{'loss': 1.0789, 'grad_norm': 17.021251678466797, 'learning_rate': 8.64175205947358e-06, 'epoch': 0.41}\n",
      "{'loss': 1.076, 'grad_norm': 21.224355697631836, 'learning_rate': 8.636728953184649e-06, 'epoch': 0.41}\n",
      "{'loss': 1.0789, 'grad_norm': 22.776823043823242, 'learning_rate': 8.631705846895722e-06, 'epoch': 0.41}\n",
      "{'loss': 1.0745, 'grad_norm': 16.408267974853516, 'learning_rate': 8.626682740606792e-06, 'epoch': 0.41}\n",
      "{'loss': 1.0956, 'grad_norm': 37.794193267822266, 'learning_rate': 8.621659634317863e-06, 'epoch': 0.41}\n",
      "{'loss': 1.0765, 'grad_norm': 22.897985458374023, 'learning_rate': 8.616636528028933e-06, 'epoch': 0.42}\n",
      "{'loss': 1.0653, 'grad_norm': 17.480554580688477, 'learning_rate': 8.611613421740005e-06, 'epoch': 0.42}\n",
      "{'loss': 1.0251, 'grad_norm': 28.06158447265625, 'learning_rate': 8.606590315451076e-06, 'epoch': 0.42}\n",
      "{'loss': 1.0887, 'grad_norm': 23.847352981567383, 'learning_rate': 8.601567209162146e-06, 'epoch': 0.42}\n",
      "{'loss': 1.089, 'grad_norm': 35.560218811035156, 'learning_rate': 8.596544102873217e-06, 'epoch': 0.42}\n",
      "{'loss': 0.9881, 'grad_norm': 18.356849670410156, 'learning_rate': 8.591520996584289e-06, 'epoch': 0.42}\n",
      "{'loss': 1.1083, 'grad_norm': 6.520723819732666, 'learning_rate': 8.586497890295358e-06, 'epoch': 0.42}\n",
      "{'loss': 1.0753, 'grad_norm': 20.040386199951172, 'learning_rate': 8.58147478400643e-06, 'epoch': 0.43}\n",
      "{'loss': 1.0592, 'grad_norm': 33.94344711303711, 'learning_rate': 8.576451677717501e-06, 'epoch': 0.43}\n",
      "{'loss': 1.0896, 'grad_norm': 19.077974319458008, 'learning_rate': 8.571428571428571e-06, 'epoch': 0.43}\n",
      "{'loss': 1.0761, 'grad_norm': 33.935699462890625, 'learning_rate': 8.566405465139644e-06, 'epoch': 0.43}\n",
      "{'loss': 1.0247, 'grad_norm': 25.721725463867188, 'learning_rate': 8.561382358850714e-06, 'epoch': 0.43}\n",
      "{'loss': 1.0286, 'grad_norm': 27.09575843811035, 'learning_rate': 8.556359252561785e-06, 'epoch': 0.43}\n",
      "{'loss': 1.0852, 'grad_norm': 24.861774444580078, 'learning_rate': 8.551336146272857e-06, 'epoch': 0.44}\n",
      "{'loss': 1.0674, 'grad_norm': 28.60853385925293, 'learning_rate': 8.546313039983926e-06, 'epoch': 0.44}\n",
      "{'loss': 1.0966, 'grad_norm': 21.17376136779785, 'learning_rate': 8.541289933694998e-06, 'epoch': 0.44}\n",
      "{'loss': 1.0263, 'grad_norm': 18.819482803344727, 'learning_rate': 8.53626682740607e-06, 'epoch': 0.44}\n",
      "{'loss': 1.0611, 'grad_norm': 6.985131740570068, 'learning_rate': 8.531243721117139e-06, 'epoch': 0.44}\n",
      "{'loss': 1.1129, 'grad_norm': 49.65171813964844, 'learning_rate': 8.52622061482821e-06, 'epoch': 0.44}\n",
      "{'loss': 1.0024, 'grad_norm': 35.98856735229492, 'learning_rate': 8.521197508539282e-06, 'epoch': 0.44}\n",
      "{'loss': 1.1058, 'grad_norm': 21.344886779785156, 'learning_rate': 8.516174402250352e-06, 'epoch': 0.45}\n",
      "{'loss': 1.0059, 'grad_norm': 39.80293655395508, 'learning_rate': 8.511151295961423e-06, 'epoch': 0.45}\n",
      "{'loss': 1.0272, 'grad_norm': 5.016345977783203, 'learning_rate': 8.506128189672494e-06, 'epoch': 0.45}\n",
      "{'loss': 1.0167, 'grad_norm': 5.529295921325684, 'learning_rate': 8.501105083383566e-06, 'epoch': 0.45}\n",
      "{'loss': 1.0989, 'grad_norm': 19.62052345275879, 'learning_rate': 8.496081977094636e-06, 'epoch': 0.45}\n",
      "{'loss': 1.0529, 'grad_norm': 27.832294464111328, 'learning_rate': 8.491058870805707e-06, 'epoch': 0.45}\n",
      "{'loss': 1.0298, 'grad_norm': 26.688386917114258, 'learning_rate': 8.486035764516778e-06, 'epoch': 0.46}\n",
      "{'loss': 1.072, 'grad_norm': 18.425539016723633, 'learning_rate': 8.481012658227848e-06, 'epoch': 0.46}\n",
      "{'loss': 1.0903, 'grad_norm': 22.37983512878418, 'learning_rate': 8.47598955193892e-06, 'epoch': 0.46}\n",
      "{'loss': 1.0639, 'grad_norm': 16.902482986450195, 'learning_rate': 8.470966445649991e-06, 'epoch': 0.46}\n",
      "{'loss': 1.1342, 'grad_norm': 23.876920700073242, 'learning_rate': 8.46594333936106e-06, 'epoch': 0.46}\n",
      "{'loss': 1.0495, 'grad_norm': 26.96391487121582, 'learning_rate': 8.460920233072132e-06, 'epoch': 0.46}\n",
      "{'loss': 1.1106, 'grad_norm': 18.80329704284668, 'learning_rate': 8.455897126783204e-06, 'epoch': 0.46}\n",
      "{'loss': 1.1239, 'grad_norm': 26.033533096313477, 'learning_rate': 8.450874020494273e-06, 'epoch': 0.47}\n",
      "{'loss': 1.0557, 'grad_norm': 24.2742919921875, 'learning_rate': 8.445850914205347e-06, 'epoch': 0.47}\n",
      "{'loss': 1.0417, 'grad_norm': 40.73092269897461, 'learning_rate': 8.440827807916416e-06, 'epoch': 0.47}\n",
      "{'loss': 1.0858, 'grad_norm': 7.192382335662842, 'learning_rate': 8.435804701627488e-06, 'epoch': 0.47}\n",
      "{'loss': 1.1013, 'grad_norm': 18.3418025970459, 'learning_rate': 8.430781595338559e-06, 'epoch': 0.47}\n",
      "{'loss': 1.0532, 'grad_norm': 25.122148513793945, 'learning_rate': 8.425758489049629e-06, 'epoch': 0.47}\n",
      "{'loss': 1.11, 'grad_norm': 38.2026481628418, 'learning_rate': 8.4207353827607e-06, 'epoch': 0.47}\n",
      "{'loss': 1.0441, 'grad_norm': 25.987380981445312, 'learning_rate': 8.415712276471772e-06, 'epoch': 0.48}\n",
      "{'loss': 1.0829, 'grad_norm': 20.79088020324707, 'learning_rate': 8.410689170182841e-06, 'epoch': 0.48}\n",
      "{'loss': 0.9644, 'grad_norm': 5.825385093688965, 'learning_rate': 8.405666063893913e-06, 'epoch': 0.48}\n",
      "{'loss': 1.0734, 'grad_norm': 36.48198318481445, 'learning_rate': 8.400642957604984e-06, 'epoch': 0.48}\n",
      "{'loss': 1.046, 'grad_norm': 22.997905731201172, 'learning_rate': 8.395619851316054e-06, 'epoch': 0.48}\n",
      "{'loss': 1.1012, 'grad_norm': 24.421537399291992, 'learning_rate': 8.390596745027126e-06, 'epoch': 0.48}\n",
      "{'loss': 1.0534, 'grad_norm': 26.00956916809082, 'learning_rate': 8.385573638738195e-06, 'epoch': 0.49}\n",
      "{'loss': 1.0374, 'grad_norm': 20.833959579467773, 'learning_rate': 8.380550532449268e-06, 'epoch': 0.49}\n",
      "{'loss': 1.0801, 'grad_norm': 25.261926651000977, 'learning_rate': 8.375527426160338e-06, 'epoch': 0.49}\n",
      "{'loss': 1.0553, 'grad_norm': 25.162017822265625, 'learning_rate': 8.370504319871408e-06, 'epoch': 0.49}\n",
      "{'loss': 1.0795, 'grad_norm': 37.79768753051758, 'learning_rate': 8.365481213582481e-06, 'epoch': 0.49}\n",
      "{'loss': 1.1272, 'grad_norm': 35.7809944152832, 'learning_rate': 8.36045810729355e-06, 'epoch': 0.49}\n",
      "{'loss': 1.062, 'grad_norm': 33.92374801635742, 'learning_rate': 8.355435001004622e-06, 'epoch': 0.49}\n",
      "{'loss': 1.0904, 'grad_norm': 27.454652786254883, 'learning_rate': 8.350411894715694e-06, 'epoch': 0.5}\n",
      "{'loss': 1.0958, 'grad_norm': 6.759997367858887, 'learning_rate': 8.345388788426763e-06, 'epoch': 0.5}\n",
      "{'loss': 1.0817, 'grad_norm': 5.9480156898498535, 'learning_rate': 8.340365682137835e-06, 'epoch': 0.5}\n",
      "{'loss': 1.0927, 'grad_norm': 8.103293418884277, 'learning_rate': 8.335342575848906e-06, 'epoch': 0.5}\n",
      "{'loss': 1.0547, 'grad_norm': 21.367937088012695, 'learning_rate': 8.330319469559976e-06, 'epoch': 0.5}\n",
      "{'loss': 1.0503, 'grad_norm': 22.038658142089844, 'learning_rate': 8.325296363271047e-06, 'epoch': 0.5}\n",
      "{'loss': 1.0992, 'grad_norm': 33.404701232910156, 'learning_rate': 8.320273256982119e-06, 'epoch': 0.5}\n",
      "{'loss': 1.1367, 'grad_norm': 25.33439064025879, 'learning_rate': 8.315250150693189e-06, 'epoch': 0.51}\n",
      "{'loss': 1.0891, 'grad_norm': 25.971759796142578, 'learning_rate': 8.31022704440426e-06, 'epoch': 0.51}\n",
      "{'loss': 1.0588, 'grad_norm': 39.48655319213867, 'learning_rate': 8.305203938115331e-06, 'epoch': 0.51}\n",
      "{'loss': 1.0728, 'grad_norm': 48.702842712402344, 'learning_rate': 8.300180831826403e-06, 'epoch': 0.51}\n",
      "{'loss': 1.1164, 'grad_norm': 6.2325544357299805, 'learning_rate': 8.295157725537473e-06, 'epoch': 0.51}\n",
      "{'loss': 1.0013, 'grad_norm': 17.498136520385742, 'learning_rate': 8.290134619248544e-06, 'epoch': 0.51}\n",
      "{'loss': 1.0433, 'grad_norm': 35.92337417602539, 'learning_rate': 8.285111512959615e-06, 'epoch': 0.52}\n",
      "{'loss': 1.0297, 'grad_norm': 18.163442611694336, 'learning_rate': 8.280088406670685e-06, 'epoch': 0.52}\n",
      "{'loss': 1.0698, 'grad_norm': 17.917163848876953, 'learning_rate': 8.275065300381757e-06, 'epoch': 0.52}\n",
      "{'loss': 1.0584, 'grad_norm': 26.280851364135742, 'learning_rate': 8.270042194092828e-06, 'epoch': 0.52}\n",
      "{'loss': 1.0629, 'grad_norm': 21.016468048095703, 'learning_rate': 8.265019087803898e-06, 'epoch': 0.52}\n",
      "{'loss': 1.005, 'grad_norm': 19.64383888244629, 'learning_rate': 8.25999598151497e-06, 'epoch': 0.52}\n",
      "{'loss': 1.135, 'grad_norm': 5.766688346862793, 'learning_rate': 8.25497287522604e-06, 'epoch': 0.52}\n",
      "{'loss': 1.1305, 'grad_norm': 24.8607234954834, 'learning_rate': 8.24994976893711e-06, 'epoch': 0.53}\n",
      "{'loss': 1.0195, 'grad_norm': 38.47944259643555, 'learning_rate': 8.244926662648183e-06, 'epoch': 0.53}\n",
      "{'loss': 1.0486, 'grad_norm': 31.429216384887695, 'learning_rate': 8.239903556359253e-06, 'epoch': 0.53}\n",
      "{'loss': 1.0693, 'grad_norm': 19.104333877563477, 'learning_rate': 8.234880450070325e-06, 'epoch': 0.53}\n",
      "{'loss': 1.111, 'grad_norm': 9.216917991638184, 'learning_rate': 8.229857343781396e-06, 'epoch': 0.53}\n",
      "{'loss': 1.1368, 'grad_norm': 20.524232864379883, 'learning_rate': 8.224834237492466e-06, 'epoch': 0.53}\n",
      "{'loss': 1.0751, 'grad_norm': 7.346014976501465, 'learning_rate': 8.219811131203537e-06, 'epoch': 0.53}\n",
      "{'loss': 1.097, 'grad_norm': 16.03124237060547, 'learning_rate': 8.214788024914609e-06, 'epoch': 0.54}\n",
      "{'loss': 1.0547, 'grad_norm': 21.67417335510254, 'learning_rate': 8.209764918625678e-06, 'epoch': 0.54}\n",
      "{'loss': 1.0611, 'grad_norm': 10.047432899475098, 'learning_rate': 8.20474181233675e-06, 'epoch': 0.54}\n",
      "{'loss': 1.0584, 'grad_norm': 24.69029426574707, 'learning_rate': 8.199718706047821e-06, 'epoch': 0.54}\n",
      "{'loss': 1.0604, 'grad_norm': 9.339021682739258, 'learning_rate': 8.194695599758891e-06, 'epoch': 0.54}\n",
      "{'loss': 1.0467, 'grad_norm': 23.553686141967773, 'learning_rate': 8.189672493469962e-06, 'epoch': 0.54}\n",
      "{'loss': 1.0782, 'grad_norm': 17.069700241088867, 'learning_rate': 8.184649387181034e-06, 'epoch': 0.55}\n",
      "{'loss': 1.0333, 'grad_norm': 35.15777587890625, 'learning_rate': 8.179626280892105e-06, 'epoch': 0.55}\n",
      "{'loss': 1.057, 'grad_norm': 28.352304458618164, 'learning_rate': 8.174603174603175e-06, 'epoch': 0.55}\n",
      "{'loss': 1.0618, 'grad_norm': 7.142406463623047, 'learning_rate': 8.169580068314246e-06, 'epoch': 0.55}\n",
      "{'loss': 1.131, 'grad_norm': 14.890678405761719, 'learning_rate': 8.164556962025318e-06, 'epoch': 0.55}\n",
      "{'loss': 1.0907, 'grad_norm': 17.396242141723633, 'learning_rate': 8.159533855736388e-06, 'epoch': 0.55}\n",
      "{'loss': 1.0807, 'grad_norm': 30.258886337280273, 'learning_rate': 8.154510749447459e-06, 'epoch': 0.55}\n",
      "{'loss': 1.0839, 'grad_norm': 22.578426361083984, 'learning_rate': 8.14948764315853e-06, 'epoch': 0.56}\n",
      "{'loss': 1.1295, 'grad_norm': 7.306215286254883, 'learning_rate': 8.1444645368696e-06, 'epoch': 0.56}\n",
      "{'loss': 1.0476, 'grad_norm': 32.35992431640625, 'learning_rate': 8.139441430580672e-06, 'epoch': 0.56}\n",
      "{'loss': 1.0149, 'grad_norm': 44.885475158691406, 'learning_rate': 8.134418324291743e-06, 'epoch': 0.56}\n",
      "{'loss': 1.1261, 'grad_norm': 17.306310653686523, 'learning_rate': 8.129395218002813e-06, 'epoch': 0.56}\n",
      "{'loss': 1.0615, 'grad_norm': 7.884677410125732, 'learning_rate': 8.124372111713884e-06, 'epoch': 0.56}\n",
      "{'loss': 1.0866, 'grad_norm': 30.71525001525879, 'learning_rate': 8.119349005424956e-06, 'epoch': 0.57}\n",
      "{'loss': 1.0695, 'grad_norm': 23.901941299438477, 'learning_rate': 8.114325899136027e-06, 'epoch': 0.57}\n",
      "{'loss': 1.0817, 'grad_norm': 16.530433654785156, 'learning_rate': 8.109302792847097e-06, 'epoch': 0.57}\n",
      "{'loss': 1.0461, 'grad_norm': 15.70505428314209, 'learning_rate': 8.104279686558168e-06, 'epoch': 0.57}\n",
      "{'loss': 1.1086, 'grad_norm': 7.47343111038208, 'learning_rate': 8.09925658026924e-06, 'epoch': 0.57}\n",
      "{'loss': 1.1042, 'grad_norm': 34.178462982177734, 'learning_rate': 8.09423347398031e-06, 'epoch': 0.57}\n",
      "{'loss': 1.0636, 'grad_norm': 15.782319068908691, 'learning_rate': 8.089210367691381e-06, 'epoch': 0.57}\n",
      "{'loss': 1.0225, 'grad_norm': 30.173118591308594, 'learning_rate': 8.084187261402452e-06, 'epoch': 0.58}\n",
      "{'loss': 1.0683, 'grad_norm': 36.394859313964844, 'learning_rate': 8.079164155113522e-06, 'epoch': 0.58}\n",
      "{'loss': 1.0313, 'grad_norm': 8.532203674316406, 'learning_rate': 8.074141048824594e-06, 'epoch': 0.58}\n",
      "{'loss': 1.1184, 'grad_norm': 35.210548400878906, 'learning_rate': 8.069117942535665e-06, 'epoch': 0.58}\n",
      "{'loss': 1.0219, 'grad_norm': 8.428730010986328, 'learning_rate': 8.064094836246735e-06, 'epoch': 0.58}\n",
      "{'loss': 1.0432, 'grad_norm': 43.590721130371094, 'learning_rate': 8.059071729957806e-06, 'epoch': 0.58}\n",
      "{'loss': 1.0569, 'grad_norm': 16.930665969848633, 'learning_rate': 8.054048623668878e-06, 'epoch': 0.58}\n",
      "{'loss': 1.0714, 'grad_norm': 32.77045440673828, 'learning_rate': 8.049025517379947e-06, 'epoch': 0.59}\n",
      "{'loss': 1.0917, 'grad_norm': 16.736572265625, 'learning_rate': 8.04400241109102e-06, 'epoch': 0.59}\n",
      "{'loss': 1.0827, 'grad_norm': 29.567306518554688, 'learning_rate': 8.03897930480209e-06, 'epoch': 0.59}\n",
      "{'loss': 1.0925, 'grad_norm': 9.671088218688965, 'learning_rate': 8.033956198513162e-06, 'epoch': 0.59}\n",
      "{'loss': 1.04, 'grad_norm': 22.876422882080078, 'learning_rate': 8.028933092224233e-06, 'epoch': 0.59}\n",
      "{'loss': 1.0694, 'grad_norm': 24.533512115478516, 'learning_rate': 8.023909985935303e-06, 'epoch': 0.59}\n",
      "{'loss': 1.0577, 'grad_norm': 16.118228912353516, 'learning_rate': 8.018886879646374e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0407, 'grad_norm': 16.833881378173828, 'learning_rate': 8.013863773357446e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0447, 'grad_norm': 23.051340103149414, 'learning_rate': 8.008840667068515e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0505, 'grad_norm': 30.2296085357666, 'learning_rate': 8.003817560779587e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0763, 'grad_norm': 17.289884567260742, 'learning_rate': 7.998794454490658e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0974, 'grad_norm': 38.88982009887695, 'learning_rate': 7.993771348201728e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0578, 'grad_norm': 29.36414337158203, 'learning_rate': 7.9887482419128e-06, 'epoch': 0.6}\n",
      "{'loss': 1.0856, 'grad_norm': 35.71638107299805, 'learning_rate': 7.98372513562387e-06, 'epoch': 0.61}\n",
      "{'loss': 1.0606, 'grad_norm': 16.273286819458008, 'learning_rate': 7.978702029334942e-06, 'epoch': 0.61}\n",
      "{'loss': 1.0907, 'grad_norm': 25.155574798583984, 'learning_rate': 7.973678923046012e-06, 'epoch': 0.61}\n",
      "{'loss': 1.0639, 'grad_norm': 16.400039672851562, 'learning_rate': 7.968655816757083e-06, 'epoch': 0.61}\n",
      "{'loss': 1.1067, 'grad_norm': 30.47612762451172, 'learning_rate': 7.963632710468155e-06, 'epoch': 0.61}\n",
      "{'loss': 1.1121, 'grad_norm': 37.463134765625, 'learning_rate': 7.958609604179225e-06, 'epoch': 0.61}\n",
      "{'loss': 1.0578, 'grad_norm': 27.668590545654297, 'learning_rate': 7.953586497890296e-06, 'epoch': 0.61}\n",
      "{'loss': 1.0879, 'grad_norm': 9.678117752075195, 'learning_rate': 7.948563391601367e-06, 'epoch': 0.62}\n",
      "{'loss': 1.0741, 'grad_norm': 15.123546600341797, 'learning_rate': 7.943540285312437e-06, 'epoch': 0.62}\n",
      "{'loss': 1.0392, 'grad_norm': 46.750938415527344, 'learning_rate': 7.938517179023509e-06, 'epoch': 0.62}\n",
      "{'loss': 1.0762, 'grad_norm': 10.268345832824707, 'learning_rate': 7.93349407273458e-06, 'epoch': 0.62}\n",
      "{'loss': 1.0777, 'grad_norm': 20.880521774291992, 'learning_rate': 7.92847096644565e-06, 'epoch': 0.62}\n",
      "{'loss': 1.0411, 'grad_norm': 14.856050491333008, 'learning_rate': 7.923447860156721e-06, 'epoch': 0.62}\n",
      "{'loss': 1.0462, 'grad_norm': 37.99988555908203, 'learning_rate': 7.918424753867793e-06, 'epoch': 0.63}\n",
      "{'loss': 1.0709, 'grad_norm': 16.704484939575195, 'learning_rate': 7.913401647578864e-06, 'epoch': 0.63}\n",
      "{'loss': 1.052, 'grad_norm': 24.784828186035156, 'learning_rate': 7.908378541289934e-06, 'epoch': 0.63}\n",
      "{'loss': 1.0826, 'grad_norm': 29.52005386352539, 'learning_rate': 7.903355435001005e-06, 'epoch': 0.63}\n",
      "{'loss': 1.0663, 'grad_norm': 8.174399375915527, 'learning_rate': 7.898332328712077e-06, 'epoch': 0.63}\n",
      "{'loss': 1.04, 'grad_norm': 15.68909740447998, 'learning_rate': 7.893309222423146e-06, 'epoch': 0.63}\n",
      "{'loss': 1.0803, 'grad_norm': 16.065725326538086, 'learning_rate': 7.888286116134218e-06, 'epoch': 0.63}\n",
      "{'loss': 1.0493, 'grad_norm': 33.9889030456543, 'learning_rate': 7.88326300984529e-06, 'epoch': 0.64}\n",
      "{'loss': 1.0329, 'grad_norm': 7.922235012054443, 'learning_rate': 7.878239903556359e-06, 'epoch': 0.64}\n",
      "{'loss': 1.0707, 'grad_norm': 16.363933563232422, 'learning_rate': 7.87321679726743e-06, 'epoch': 0.64}\n",
      "{'loss': 1.1308, 'grad_norm': 21.919565200805664, 'learning_rate': 7.868193690978502e-06, 'epoch': 0.64}\n",
      "{'loss': 1.0656, 'grad_norm': 21.056232452392578, 'learning_rate': 7.863170584689572e-06, 'epoch': 0.64}\n",
      "{'loss': 1.0573, 'grad_norm': 19.0661678314209, 'learning_rate': 7.858147478400645e-06, 'epoch': 0.64}\n",
      "{'loss': 0.99, 'grad_norm': 7.786505699157715, 'learning_rate': 7.853124372111714e-06, 'epoch': 0.64}\n",
      "{'loss': 1.087, 'grad_norm': 29.806102752685547, 'learning_rate': 7.848101265822786e-06, 'epoch': 0.65}\n",
      "{'loss': 0.9966, 'grad_norm': 18.552431106567383, 'learning_rate': 7.843078159533857e-06, 'epoch': 0.65}\n",
      "{'loss': 1.0424, 'grad_norm': 7.097705364227295, 'learning_rate': 7.838055053244927e-06, 'epoch': 0.65}\n",
      "{'loss': 1.0015, 'grad_norm': 8.201775550842285, 'learning_rate': 7.833031946955999e-06, 'epoch': 0.65}\n",
      "{'loss': 1.1398, 'grad_norm': 6.459926605224609, 'learning_rate': 7.82800884066707e-06, 'epoch': 0.65}\n",
      "{'loss': 1.0819, 'grad_norm': 26.815664291381836, 'learning_rate': 7.82298573437814e-06, 'epoch': 0.65}\n",
      "{'loss': 1.01, 'grad_norm': 36.31694030761719, 'learning_rate': 7.817962628089211e-06, 'epoch': 0.66}\n",
      "{'loss': 1.065, 'grad_norm': 19.60847282409668, 'learning_rate': 7.812939521800283e-06, 'epoch': 0.66}\n",
      "{'loss': 1.1058, 'grad_norm': 41.131351470947266, 'learning_rate': 7.808418726140245e-06, 'epoch': 0.66}\n",
      "{'loss': 1.007, 'grad_norm': 6.519540786743164, 'learning_rate': 7.803395619851316e-06, 'epoch': 0.66}\n",
      "{'loss': 1.0691, 'grad_norm': 33.203941345214844, 'learning_rate': 7.798372513562388e-06, 'epoch': 0.66}\n",
      "{'loss': 1.0622, 'grad_norm': 20.921911239624023, 'learning_rate': 7.793349407273458e-06, 'epoch': 0.66}\n",
      "{'loss': 1.094, 'grad_norm': 20.727270126342773, 'learning_rate': 7.78832630098453e-06, 'epoch': 0.66}\n",
      "{'loss': 1.1322, 'grad_norm': 22.508501052856445, 'learning_rate': 7.7833031946956e-06, 'epoch': 0.67}\n",
      "{'loss': 1.0202, 'grad_norm': 20.6370849609375, 'learning_rate': 7.778280088406672e-06, 'epoch': 0.67}\n",
      "{'loss': 1.0886, 'grad_norm': 5.3153486251831055, 'learning_rate': 7.773256982117742e-06, 'epoch': 0.67}\n",
      "{'loss': 1.0295, 'grad_norm': 23.087059020996094, 'learning_rate': 7.768233875828813e-06, 'epoch': 0.67}\n",
      "{'loss': 1.0313, 'grad_norm': 41.93136215209961, 'learning_rate': 7.763210769539884e-06, 'epoch': 0.67}\n",
      "{'loss': 1.0456, 'grad_norm': 32.388450622558594, 'learning_rate': 7.758187663250954e-06, 'epoch': 0.67}\n",
      "{'loss': 1.0645, 'grad_norm': 32.98167037963867, 'learning_rate': 7.753164556962026e-06, 'epoch': 0.68}\n",
      "{'loss': 1.0502, 'grad_norm': 19.62592124938965, 'learning_rate': 7.748141450673097e-06, 'epoch': 0.68}\n",
      "{'loss': 1.0979, 'grad_norm': 6.181461811065674, 'learning_rate': 7.743118344384167e-06, 'epoch': 0.68}\n",
      "{'loss': 1.0121, 'grad_norm': 43.14375305175781, 'learning_rate': 7.738095238095238e-06, 'epoch': 0.68}\n",
      "{'loss': 1.0696, 'grad_norm': 33.578346252441406, 'learning_rate': 7.73307213180631e-06, 'epoch': 0.68}\n",
      "{'loss': 1.1759, 'grad_norm': 5.2609639167785645, 'learning_rate': 7.72804902551738e-06, 'epoch': 0.68}\n",
      "{'loss': 1.0102, 'grad_norm': 34.76838302612305, 'learning_rate': 7.723025919228453e-06, 'epoch': 0.68}\n",
      "{'loss': 1.0129, 'grad_norm': 26.622488021850586, 'learning_rate': 7.718002812939522e-06, 'epoch': 0.69}\n",
      "{'loss': 1.044, 'grad_norm': 7.191774845123291, 'learning_rate': 7.712979706650594e-06, 'epoch': 0.69}\n",
      "{'loss': 1.02, 'grad_norm': 24.690126419067383, 'learning_rate': 7.707956600361665e-06, 'epoch': 0.69}\n",
      "{'loss': 1.0653, 'grad_norm': 24.76656150817871, 'learning_rate': 7.702933494072735e-06, 'epoch': 0.69}\n",
      "{'loss': 1.066, 'grad_norm': 41.98654556274414, 'learning_rate': 7.697910387783806e-06, 'epoch': 0.69}\n",
      "{'loss': 1.0217, 'grad_norm': 17.583568572998047, 'learning_rate': 7.692887281494878e-06, 'epoch': 0.69}\n",
      "{'loss': 1.0632, 'grad_norm': 18.83941650390625, 'learning_rate': 7.687864175205947e-06, 'epoch': 0.69}\n",
      "{'loss': 1.0617, 'grad_norm': 20.021909713745117, 'learning_rate': 7.682841068917019e-06, 'epoch': 0.7}\n",
      "{'loss': 1.0326, 'grad_norm': 25.511577606201172, 'learning_rate': 7.67781796262809e-06, 'epoch': 0.7}\n",
      "{'loss': 1.0442, 'grad_norm': 5.111498832702637, 'learning_rate': 7.67279485633916e-06, 'epoch': 0.7}\n",
      "{'loss': 1.0553, 'grad_norm': 26.311140060424805, 'learning_rate': 7.667771750050231e-06, 'epoch': 0.7}\n",
      "{'loss': 0.9917, 'grad_norm': 24.89154624938965, 'learning_rate': 7.662748643761303e-06, 'epoch': 0.7}\n",
      "{'loss': 1.1281, 'grad_norm': 21.468807220458984, 'learning_rate': 7.657725537472374e-06, 'epoch': 0.7}\n",
      "{'loss': 1.0319, 'grad_norm': 5.809548377990723, 'learning_rate': 7.652702431183444e-06, 'epoch': 0.71}\n",
      "{'loss': 1.1013, 'grad_norm': 34.94411849975586, 'learning_rate': 7.647679324894516e-06, 'epoch': 0.71}\n",
      "{'loss': 1.0547, 'grad_norm': 7.251107692718506, 'learning_rate': 7.642656218605587e-06, 'epoch': 0.71}\n",
      "{'loss': 1.112, 'grad_norm': 19.663015365600586, 'learning_rate': 7.637633112316657e-06, 'epoch': 0.71}\n",
      "{'loss': 1.0879, 'grad_norm': 21.773216247558594, 'learning_rate': 7.632610006027728e-06, 'epoch': 0.71}\n",
      "{'loss': 1.0627, 'grad_norm': 18.7210636138916, 'learning_rate': 7.6275868997387996e-06, 'epoch': 0.71}\n",
      "{'loss': 1.0026, 'grad_norm': 26.594112396240234, 'learning_rate': 7.62256379344987e-06, 'epoch': 0.71}\n",
      "{'loss': 1.1023, 'grad_norm': 25.214155197143555, 'learning_rate': 7.6175406871609416e-06, 'epoch': 0.72}\n",
      "{'loss': 1.0894, 'grad_norm': 17.955141067504883, 'learning_rate': 7.612517580872012e-06, 'epoch': 0.72}\n",
      "{'loss': 1.0302, 'grad_norm': 33.10908508300781, 'learning_rate': 7.607494474583083e-06, 'epoch': 0.72}\n",
      "{'loss': 1.049, 'grad_norm': 38.88216781616211, 'learning_rate': 7.602471368294154e-06, 'epoch': 0.72}\n",
      "{'loss': 1.0735, 'grad_norm': 37.1729736328125, 'learning_rate': 7.597448262005225e-06, 'epoch': 0.72}\n",
      "{'loss': 1.0814, 'grad_norm': 27.40474510192871, 'learning_rate': 7.592425155716295e-06, 'epoch': 0.72}\n",
      "{'loss': 1.0695, 'grad_norm': 7.842837333679199, 'learning_rate': 7.587402049427367e-06, 'epoch': 0.72}\n",
      "{'loss': 1.092, 'grad_norm': 17.061599731445312, 'learning_rate': 7.582378943138437e-06, 'epoch': 0.73}\n",
      "{'loss': 1.0981, 'grad_norm': 17.98727798461914, 'learning_rate': 7.577355836849508e-06, 'epoch': 0.73}\n",
      "{'loss': 1.0642, 'grad_norm': 15.01899242401123, 'learning_rate': 7.57233273056058e-06, 'epoch': 0.73}\n",
      "{'loss': 1.0399, 'grad_norm': 9.26037883758545, 'learning_rate': 7.567309624271651e-06, 'epoch': 0.73}\n",
      "{'loss': 1.1386, 'grad_norm': 18.753795623779297, 'learning_rate': 7.5622865179827205e-06, 'epoch': 0.73}\n",
      "{'loss': 1.0663, 'grad_norm': 20.783634185791016, 'learning_rate': 7.557263411693791e-06, 'epoch': 0.73}\n",
      "{'loss': 1.0755, 'grad_norm': 41.801734924316406, 'learning_rate': 7.552240305404863e-06, 'epoch': 0.74}\n",
      "{'loss': 1.086, 'grad_norm': 11.010369300842285, 'learning_rate': 7.547217199115934e-06, 'epoch': 0.74}\n",
      "{'loss': 1.0909, 'grad_norm': 33.13804244995117, 'learning_rate': 7.5421940928270046e-06, 'epoch': 0.74}\n",
      "{'loss': 1.1076, 'grad_norm': 5.7828826904296875, 'learning_rate': 7.537170986538076e-06, 'epoch': 0.74}\n",
      "{'loss': 1.037, 'grad_norm': 17.826541900634766, 'learning_rate': 7.532147880249147e-06, 'epoch': 0.74}\n",
      "{'loss': 1.1047, 'grad_norm': 17.118852615356445, 'learning_rate': 7.527124773960217e-06, 'epoch': 0.74}\n",
      "{'loss': 1.0693, 'grad_norm': 39.41161346435547, 'learning_rate': 7.522101667671289e-06, 'epoch': 0.74}\n",
      "{'loss': 1.0769, 'grad_norm': 19.240129470825195, 'learning_rate': 7.517078561382359e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0605, 'grad_norm': 16.25569725036621, 'learning_rate': 7.51205545509343e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0446, 'grad_norm': 18.637617111206055, 'learning_rate': 7.507032348804501e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0746, 'grad_norm': 31.50228500366211, 'learning_rate': 7.502009242515572e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0719, 'grad_norm': 9.494900703430176, 'learning_rate': 7.496986136226642e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0864, 'grad_norm': 17.087120056152344, 'learning_rate': 7.491963029937715e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0555, 'grad_norm': 30.039043426513672, 'learning_rate': 7.486939923648785e-06, 'epoch': 0.75}\n",
      "{'loss': 1.0568, 'grad_norm': 17.43931007385254, 'learning_rate': 7.481916817359856e-06, 'epoch': 0.76}\n",
      "{'loss': 1.0531, 'grad_norm': 20.879812240600586, 'learning_rate': 7.476893711070927e-06, 'epoch': 0.76}\n",
      "{'loss': 1.0614, 'grad_norm': 28.908981323242188, 'learning_rate': 7.471870604781998e-06, 'epoch': 0.76}\n",
      "{'loss': 1.0933, 'grad_norm': 15.031441688537598, 'learning_rate': 7.466847498493068e-06, 'epoch': 0.76}\n",
      "{'loss': 1.0705, 'grad_norm': 29.145177841186523, 'learning_rate': 7.46182439220414e-06, 'epoch': 0.76}\n",
      "{'loss': 1.0866, 'grad_norm': 15.139404296875, 'learning_rate': 7.4568012859152104e-06, 'epoch': 0.76}\n",
      "{'loss': 1.0921, 'grad_norm': 34.09063720703125, 'learning_rate': 7.451778179626281e-06, 'epoch': 0.77}\n",
      "{'loss': 1.0559, 'grad_norm': 21.18956756591797, 'learning_rate': 7.4467550733373525e-06, 'epoch': 0.77}\n",
      "{'loss': 1.0849, 'grad_norm': 15.72330093383789, 'learning_rate': 7.441731967048423e-06, 'epoch': 0.77}\n",
      "{'loss': 1.0355, 'grad_norm': 24.276805877685547, 'learning_rate': 7.436708860759494e-06, 'epoch': 0.77}\n",
      "{'loss': 1.087, 'grad_norm': 52.6823616027832, 'learning_rate': 7.431685754470566e-06, 'epoch': 0.77}\n",
      "{'loss': 1.065, 'grad_norm': 33.153751373291016, 'learning_rate': 7.4266626481816365e-06, 'epoch': 0.77}\n",
      "{'loss': 1.0253, 'grad_norm': 22.532960891723633, 'learning_rate': 7.421639541892707e-06, 'epoch': 0.77}\n",
      "{'loss': 1.076, 'grad_norm': 30.002151489257812, 'learning_rate': 7.4166164356037785e-06, 'epoch': 0.78}\n",
      "{'loss': 1.0771, 'grad_norm': 36.89802169799805, 'learning_rate': 7.411593329314849e-06, 'epoch': 0.78}\n",
      "{'loss': 1.0726, 'grad_norm': 8.912287712097168, 'learning_rate': 7.40657022302592e-06, 'epoch': 0.78}\n",
      "{'loss': 1.0492, 'grad_norm': 34.67355728149414, 'learning_rate': 7.401547116736991e-06, 'epoch': 0.78}\n",
      "{'loss': 1.059, 'grad_norm': 16.63776397705078, 'learning_rate': 7.396524010448062e-06, 'epoch': 0.78}\n",
      "{'loss': 1.0589, 'grad_norm': 14.647502899169922, 'learning_rate': 7.391500904159132e-06, 'epoch': 0.78}\n",
      "{'loss': 1.0446, 'grad_norm': 29.050260543823242, 'learning_rate': 7.386477797870204e-06, 'epoch': 0.79}\n",
      "{'loss': 1.0653, 'grad_norm': 7.512690544128418, 'learning_rate': 7.381454691581274e-06, 'epoch': 0.79}\n",
      "{'loss': 1.099, 'grad_norm': 10.60838508605957, 'learning_rate': 7.376431585292345e-06, 'epoch': 0.79}\n",
      "{'loss': 1.0534, 'grad_norm': 31.601762771606445, 'learning_rate': 7.371408479003417e-06, 'epoch': 0.79}\n",
      "{'loss': 1.0472, 'grad_norm': 9.12564468383789, 'learning_rate': 7.366385372714488e-06, 'epoch': 0.79}\n",
      "{'loss': 1.0269, 'grad_norm': 16.948410034179688, 'learning_rate': 7.361362266425558e-06, 'epoch': 0.79}\n",
      "{'loss': 1.0386, 'grad_norm': 44.7108039855957, 'learning_rate': 7.35633916013663e-06, 'epoch': 0.79}\n",
      "{'loss': 1.053, 'grad_norm': 9.305625915527344, 'learning_rate': 7.3513160538477e-06, 'epoch': 0.8}\n",
      "{'loss': 1.0284, 'grad_norm': 9.225038528442383, 'learning_rate': 7.346292947558771e-06, 'epoch': 0.8}\n",
      "{'loss': 1.0589, 'grad_norm': 29.373565673828125, 'learning_rate': 7.3412698412698415e-06, 'epoch': 0.8}\n",
      "{'loss': 1.0522, 'grad_norm': 39.553924560546875, 'learning_rate': 7.336246734980913e-06, 'epoch': 0.8}\n",
      "{'loss': 1.0692, 'grad_norm': 10.237128257751465, 'learning_rate': 7.3312236286919835e-06, 'epoch': 0.8}\n",
      "{'loss': 1.0622, 'grad_norm': 21.273151397705078, 'learning_rate': 7.326200522403054e-06, 'epoch': 0.8}\n",
      "{'loss': 1.0093, 'grad_norm': 24.937726974487305, 'learning_rate': 7.3211774161141255e-06, 'epoch': 0.8}\n",
      "{'loss': 1.033, 'grad_norm': 19.527616500854492, 'learning_rate': 7.316154309825196e-06, 'epoch': 0.81}\n",
      "{'loss': 1.0879, 'grad_norm': 9.73019027709961, 'learning_rate': 7.311131203536267e-06, 'epoch': 0.81}\n",
      "{'loss': 1.0723, 'grad_norm': 22.323246002197266, 'learning_rate': 7.306108097247339e-06, 'epoch': 0.81}\n",
      "{'loss': 1.054, 'grad_norm': 26.80691909790039, 'learning_rate': 7.3010849909584096e-06, 'epoch': 0.81}\n",
      "{'loss': 1.0522, 'grad_norm': 21.61240005493164, 'learning_rate': 7.29606188466948e-06, 'epoch': 0.81}\n",
      "{'loss': 1.0735, 'grad_norm': 7.061429500579834, 'learning_rate': 7.291038778380552e-06, 'epoch': 0.81}\n",
      "{'loss': 1.0777, 'grad_norm': 23.965120315551758, 'learning_rate': 7.286015672091622e-06, 'epoch': 0.82}\n",
      "{'loss': 1.0384, 'grad_norm': 19.08785057067871, 'learning_rate': 7.280992565802693e-06, 'epoch': 0.82}\n",
      "{'loss': 1.0574, 'grad_norm': 7.288153648376465, 'learning_rate': 7.275969459513764e-06, 'epoch': 0.82}\n",
      "{'loss': 1.1398, 'grad_norm': 18.04315948486328, 'learning_rate': 7.270946353224835e-06, 'epoch': 0.82}\n",
      "{'loss': 1.057, 'grad_norm': 8.458720207214355, 'learning_rate': 7.265923246935905e-06, 'epoch': 0.82}\n",
      "{'loss': 1.1047, 'grad_norm': 20.2568359375, 'learning_rate': 7.260900140646977e-06, 'epoch': 0.82}\n",
      "{'loss': 1.0731, 'grad_norm': 7.717607021331787, 'learning_rate': 7.255877034358047e-06, 'epoch': 0.82}\n",
      "{'loss': 1.12, 'grad_norm': 40.1910400390625, 'learning_rate': 7.250853928069118e-06, 'epoch': 0.83}\n",
      "{'loss': 1.1259, 'grad_norm': 40.90067672729492, 'learning_rate': 7.24583082178019e-06, 'epoch': 0.83}\n",
      "{'loss': 1.0732, 'grad_norm': 7.1169538497924805, 'learning_rate': 7.24080771549126e-06, 'epoch': 0.83}\n",
      "{'loss': 1.0856, 'grad_norm': 43.919490814208984, 'learning_rate': 7.2357846092023306e-06, 'epoch': 0.83}\n",
      "{'loss': 1.0294, 'grad_norm': 25.7845516204834, 'learning_rate': 7.230761502913403e-06, 'epoch': 0.83}\n",
      "{'loss': 1.0401, 'grad_norm': 43.850425720214844, 'learning_rate': 7.225738396624473e-06, 'epoch': 0.83}\n",
      "{'loss': 1.0492, 'grad_norm': 35.50670623779297, 'learning_rate': 7.220715290335544e-06, 'epoch': 0.83}\n",
      "{'loss': 1.0513, 'grad_norm': 16.36493492126465, 'learning_rate': 7.2156921840466154e-06, 'epoch': 0.84}\n",
      "{'loss': 1.0464, 'grad_norm': 17.394817352294922, 'learning_rate': 7.210669077757686e-06, 'epoch': 0.84}\n",
      "{'loss': 1.0953, 'grad_norm': 9.52885627746582, 'learning_rate': 7.205645971468757e-06, 'epoch': 0.84}\n",
      "{'loss': 1.0315, 'grad_norm': 18.898807525634766, 'learning_rate': 7.200622865179828e-06, 'epoch': 0.84}\n",
      "{'loss': 1.1101, 'grad_norm': 18.459060668945312, 'learning_rate': 7.195599758890899e-06, 'epoch': 0.84}\n",
      "{'loss': 0.9974, 'grad_norm': 22.41156768798828, 'learning_rate': 7.190576652601969e-06, 'epoch': 0.84}\n",
      "{'loss': 1.0371, 'grad_norm': 6.339993000030518, 'learning_rate': 7.185553546313041e-06, 'epoch': 0.85}\n",
      "{'loss': 1.0987, 'grad_norm': 19.405445098876953, 'learning_rate': 7.180530440024111e-06, 'epoch': 0.85}\n",
      "{'loss': 0.964, 'grad_norm': 23.044097900390625, 'learning_rate': 7.175507333735182e-06, 'epoch': 0.85}\n",
      "{'loss': 1.1398, 'grad_norm': 37.16324234008789, 'learning_rate': 7.170484227446254e-06, 'epoch': 0.85}\n",
      "{'loss': 1.0266, 'grad_norm': 23.0771427154541, 'learning_rate': 7.165461121157325e-06, 'epoch': 0.85}\n",
      "{'loss': 1.0428, 'grad_norm': 40.891273498535156, 'learning_rate': 7.160438014868395e-06, 'epoch': 0.85}\n",
      "{'loss': 1.036, 'grad_norm': 19.650638580322266, 'learning_rate': 7.155414908579467e-06, 'epoch': 0.85}\n",
      "{'loss': 1.0863, 'grad_norm': 23.649831771850586, 'learning_rate': 7.150391802290537e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0955, 'grad_norm': 7.209542274475098, 'learning_rate': 7.145368696001608e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0851, 'grad_norm': 26.741825103759766, 'learning_rate': 7.140345589712679e-06, 'epoch': 0.86}\n",
      "{'loss': 1.1166, 'grad_norm': 19.244598388671875, 'learning_rate': 7.13532248342375e-06, 'epoch': 0.86}\n",
      "{'loss': 1.1917, 'grad_norm': 25.210737228393555, 'learning_rate': 7.1302993771348204e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0906, 'grad_norm': 14.223027229309082, 'learning_rate': 7.125276270845891e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0974, 'grad_norm': 18.09499740600586, 'learning_rate': 7.1202531645569625e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0373, 'grad_norm': 17.259296417236328, 'learning_rate': 7.115230058268033e-06, 'epoch': 0.87}\n",
      "{'loss': 1.1085, 'grad_norm': 32.601806640625, 'learning_rate': 7.110206951979104e-06, 'epoch': 0.87}\n",
      "{'loss': 1.0082, 'grad_norm': 9.621514320373535, 'learning_rate': 7.105183845690176e-06, 'epoch': 0.87}\n",
      "{'loss': 1.0306, 'grad_norm': 18.328514099121094, 'learning_rate': 7.1001607394012465e-06, 'epoch': 0.87}\n",
      "{'loss': 1.0348, 'grad_norm': 28.82961082458496, 'learning_rate': 7.095137633112317e-06, 'epoch': 0.87}\n",
      "{'loss': 1.0484, 'grad_norm': 26.94991111755371, 'learning_rate': 7.0901145268233885e-06, 'epoch': 0.87}\n",
      "{'loss': 1.0333, 'grad_norm': 32.33030319213867, 'learning_rate': 7.085091420534459e-06, 'epoch': 0.88}\n",
      "{'loss': 1.1471, 'grad_norm': 39.75229263305664, 'learning_rate': 7.08006831424553e-06, 'epoch': 0.88}\n",
      "{'loss': 1.093, 'grad_norm': 16.970611572265625, 'learning_rate': 7.075045207956601e-06, 'epoch': 0.88}\n",
      "{'loss': 1.06, 'grad_norm': 23.6252384185791, 'learning_rate': 7.070022101667672e-06, 'epoch': 0.88}\n",
      "{'loss': 1.0259, 'grad_norm': 23.930736541748047, 'learning_rate': 7.064998995378742e-06, 'epoch': 0.88}\n",
      "{'loss': 1.0728, 'grad_norm': 19.022201538085938, 'learning_rate': 7.059975889089814e-06, 'epoch': 0.88}\n",
      "{'loss': 1.013, 'grad_norm': 32.82651901245117, 'learning_rate': 7.054952782800884e-06, 'epoch': 0.88}\n",
      "{'loss': 1.092, 'grad_norm': 6.939788818359375, 'learning_rate': 7.049929676511955e-06, 'epoch': 0.89}\n",
      "{'loss': 1.0451, 'grad_norm': 35.49637222290039, 'learning_rate': 7.044906570223027e-06, 'epoch': 0.89}\n",
      "{'loss': 1.1573, 'grad_norm': 15.100226402282715, 'learning_rate': 7.039883463934098e-06, 'epoch': 0.89}\n",
      "{'loss': 1.0731, 'grad_norm': 31.548383712768555, 'learning_rate': 7.034860357645168e-06, 'epoch': 0.89}\n",
      "{'loss': 1.0167, 'grad_norm': 40.20370864868164, 'learning_rate': 7.02983725135624e-06, 'epoch': 0.89}\n",
      "{'loss': 1.0423, 'grad_norm': 24.46550941467285, 'learning_rate': 7.02481414506731e-06, 'epoch': 0.89}\n",
      "{'loss': 1.055, 'grad_norm': 26.447200775146484, 'learning_rate': 7.019791038778381e-06, 'epoch': 0.9}\n",
      "{'loss': 1.1157, 'grad_norm': 7.156772613525391, 'learning_rate': 7.014767932489452e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0618, 'grad_norm': 24.212976455688477, 'learning_rate': 7.009744826200523e-06, 'epoch': 0.9}\n",
      "{'loss': 1.096, 'grad_norm': 25.881120681762695, 'learning_rate': 7.0047217199115935e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0332, 'grad_norm': 27.974388122558594, 'learning_rate': 6.999698613622665e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0451, 'grad_norm': 41.320213317871094, 'learning_rate': 6.9946755073337355e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0838, 'grad_norm': 8.413333892822266, 'learning_rate': 6.989652401044806e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0698, 'grad_norm': 26.172151565551758, 'learning_rate': 6.984629294755878e-06, 'epoch': 0.91}\n",
      "{'loss': 1.0887, 'grad_norm': 30.965787887573242, 'learning_rate': 6.979606188466949e-06, 'epoch': 0.91}\n",
      "{'loss': 1.056, 'grad_norm': 25.65057945251465, 'learning_rate': 6.9745830821780196e-06, 'epoch': 0.91}\n",
      "{'loss': 1.0576, 'grad_norm': 33.40996551513672, 'learning_rate': 6.969559975889091e-06, 'epoch': 0.91}\n",
      "{'loss': 1.0597, 'grad_norm': 17.99664306640625, 'learning_rate': 6.964536869600162e-06, 'epoch': 0.91}\n",
      "{'loss': 1.0466, 'grad_norm': 41.03889465332031, 'learning_rate': 6.959513763311232e-06, 'epoch': 0.91}\n",
      "{'loss': 1.0103, 'grad_norm': 37.27577590942383, 'learning_rate': 6.954490657022304e-06, 'epoch': 0.91}\n",
      "{'loss': 1.004, 'grad_norm': 24.360538482666016, 'learning_rate': 6.949467550733374e-06, 'epoch': 0.92}\n",
      "{'loss': 1.1067, 'grad_norm': 19.267698287963867, 'learning_rate': 6.944444444444445e-06, 'epoch': 0.92}\n",
      "{'loss': 1.032, 'grad_norm': 22.90110206604004, 'learning_rate': 6.939421338155516e-06, 'epoch': 0.92}\n",
      "{'loss': 1.0354, 'grad_norm': 20.46721649169922, 'learning_rate': 6.934398231866587e-06, 'epoch': 0.92}\n",
      "{'loss': 1.024, 'grad_norm': 25.986486434936523, 'learning_rate': 6.929375125577657e-06, 'epoch': 0.92}\n",
      "{'loss': 1.0473, 'grad_norm': 25.48914337158203, 'learning_rate': 6.92435201928873e-06, 'epoch': 0.92}\n",
      "{'loss': 1.0807, 'grad_norm': 32.669898986816406, 'learning_rate': 6.919328912999799e-06, 'epoch': 0.93}\n",
      "{'loss': 1.0206, 'grad_norm': 18.376901626586914, 'learning_rate': 6.91430580671087e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1326, 'grad_norm': 18.777191162109375, 'learning_rate': 6.909282700421942e-06, 'epoch': 0.93}\n",
      "{'loss': 1.0181, 'grad_norm': 19.673246383666992, 'learning_rate': 6.904259594133013e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1644, 'grad_norm': 19.120607376098633, 'learning_rate': 6.8992364878440834e-06, 'epoch': 0.93}\n",
      "{'loss': 1.0482, 'grad_norm': 41.099369049072266, 'learning_rate': 6.894213381555154e-06, 'epoch': 0.93}\n",
      "{'loss': 1.0238, 'grad_norm': 10.887807846069336, 'learning_rate': 6.8891902752662254e-06, 'epoch': 0.93}\n",
      "{'loss': 1.096, 'grad_norm': 15.832133293151855, 'learning_rate': 6.884167168977296e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1111, 'grad_norm': 5.744119644165039, 'learning_rate': 6.879144062688367e-06, 'epoch': 0.94}\n",
      "{'loss': 1.0628, 'grad_norm': 27.240650177001953, 'learning_rate': 6.874120956399438e-06, 'epoch': 0.94}\n",
      "{'loss': 1.0358, 'grad_norm': 21.21881675720215, 'learning_rate': 6.869097850110509e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1287, 'grad_norm': 16.348587036132812, 'learning_rate': 6.864074743821579e-06, 'epoch': 0.94}\n",
      "{'loss': 1.0601, 'grad_norm': 38.58866500854492, 'learning_rate': 6.859051637532651e-06, 'epoch': 0.94}\n",
      "{'loss': 1.0818, 'grad_norm': 20.376773834228516, 'learning_rate': 6.854028531243721e-06, 'epoch': 0.94}\n",
      "{'loss': 1.0236, 'grad_norm': 8.663055419921875, 'learning_rate': 6.849005424954792e-06, 'epoch': 0.95}\n",
      "{'loss': 1.0595, 'grad_norm': 44.32176208496094, 'learning_rate': 6.843982318665864e-06, 'epoch': 0.95}\n",
      "{'loss': 0.9895, 'grad_norm': 7.891946315765381, 'learning_rate': 6.838959212376935e-06, 'epoch': 0.95}\n",
      "{'loss': 1.025, 'grad_norm': 20.640531539916992, 'learning_rate': 6.833936106088005e-06, 'epoch': 0.95}\n",
      "{'loss': 1.0255, 'grad_norm': 6.7700700759887695, 'learning_rate': 6.828912999799077e-06, 'epoch': 0.95}\n",
      "{'loss': 1.142, 'grad_norm': 24.66927719116211, 'learning_rate': 6.823889893510147e-06, 'epoch': 0.95}\n",
      "{'loss': 1.0362, 'grad_norm': 23.651107788085938, 'learning_rate': 6.818866787221218e-06, 'epoch': 0.96}\n",
      "{'loss': 1.0865, 'grad_norm': 19.08624267578125, 'learning_rate': 6.813843680932289e-06, 'epoch': 0.96}\n",
      "{'loss': 1.0745, 'grad_norm': 18.08134651184082, 'learning_rate': 6.80882057464336e-06, 'epoch': 0.96}\n",
      "{'loss': 1.1149, 'grad_norm': 26.93742561340332, 'learning_rate': 6.8037974683544305e-06, 'epoch': 0.96}\n",
      "{'loss': 1.0504, 'grad_norm': 34.82283401489258, 'learning_rate': 6.798774362065502e-06, 'epoch': 0.96}\n",
      "{'loss': 1.09, 'grad_norm': 37.76869201660156, 'learning_rate': 6.7937512557765725e-06, 'epoch': 0.96}\n",
      "{'loss': 1.0191, 'grad_norm': 44.4660530090332, 'learning_rate': 6.788728149487643e-06, 'epoch': 0.96}\n",
      "{'loss': 1.0384, 'grad_norm': 26.025667190551758, 'learning_rate': 6.783705043198715e-06, 'epoch': 0.97}\n",
      "{'loss': 1.0649, 'grad_norm': 26.313753128051758, 'learning_rate': 6.778681936909786e-06, 'epoch': 0.97}\n",
      "{'loss': 1.03, 'grad_norm': 21.968412399291992, 'learning_rate': 6.7736588306208565e-06, 'epoch': 0.97}\n",
      "{'loss': 1.081, 'grad_norm': 9.749284744262695, 'learning_rate': 6.768635724331928e-06, 'epoch': 0.97}\n",
      "{'loss': 0.9689, 'grad_norm': 17.06144905090332, 'learning_rate': 6.7636126180429985e-06, 'epoch': 0.97}\n",
      "{'loss': 1.0153, 'grad_norm': 24.19575309753418, 'learning_rate': 6.758589511754069e-06, 'epoch': 0.97}\n",
      "{'loss': 1.1126, 'grad_norm': 32.30173110961914, 'learning_rate': 6.7535664054651405e-06, 'epoch': 0.97}\n",
      "{'loss': 1.069, 'grad_norm': 19.909534454345703, 'learning_rate': 6.748543299176211e-06, 'epoch': 0.98}\n",
      "{'loss': 1.0839, 'grad_norm': 6.112444877624512, 'learning_rate': 6.743520192887282e-06, 'epoch': 0.98}\n",
      "{'loss': 1.093, 'grad_norm': 38.985748291015625, 'learning_rate': 6.738497086598353e-06, 'epoch': 0.98}\n",
      "{'loss': 1.0031, 'grad_norm': 25.717344284057617, 'learning_rate': 6.733473980309424e-06, 'epoch': 0.98}\n",
      "{'loss': 1.0606, 'grad_norm': 27.380537033081055, 'learning_rate': 6.728450874020494e-06, 'epoch': 0.98}\n",
      "{'loss': 1.0156, 'grad_norm': 7.388888359069824, 'learning_rate': 6.723427767731567e-06, 'epoch': 0.98}\n",
      "{'loss': 1.0764, 'grad_norm': 38.372310638427734, 'learning_rate': 6.718404661442637e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0504, 'grad_norm': 32.684635162353516, 'learning_rate': 6.713381555153708e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0654, 'grad_norm': 38.09490203857422, 'learning_rate': 6.708358448864779e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0977, 'grad_norm': 21.78453254699707, 'learning_rate': 6.70333534257585e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0565, 'grad_norm': 21.135549545288086, 'learning_rate': 6.69831223628692e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0187, 'grad_norm': 8.070841789245605, 'learning_rate': 6.693289129997992e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0241, 'grad_norm': 27.70845603942871, 'learning_rate': 6.688266023709062e-06, 'epoch': 0.99}\n",
      "{'loss': 1.0169, 'grad_norm': 8.260990142822266, 'learning_rate': 6.683242917420133e-06, 'epoch': 1.0}\n",
      "{'loss': 1.0575, 'grad_norm': 26.624217987060547, 'learning_rate': 6.6782198111312035e-06, 'epoch': 1.0}\n",
      "{'loss': 1.0926, 'grad_norm': 9.933438301086426, 'learning_rate': 6.673196704842275e-06, 'epoch': 1.0}\n",
      "{'loss': 1.0596, 'grad_norm': 25.10137176513672, 'learning_rate': 6.6681735985533456e-06, 'epoch': 1.0}\n",
      "{'loss': 1.0727, 'grad_norm': 24.76991081237793, 'learning_rate': 6.663150492264416e-06, 'epoch': 1.0}\n",
      "{'loss': 1.0293, 'grad_norm': 15.486517906188965, 'learning_rate': 6.658127385975488e-06, 'epoch': 1.0}\n",
      "{'loss': 0.9915, 'grad_norm': 44.65043258666992, 'learning_rate': 6.653104279686559e-06, 'epoch': 1.01}\n",
      "{'loss': 1.0511, 'grad_norm': 13.1052885055542, 'learning_rate': 6.648081173397629e-06, 'epoch': 1.01}\n",
      "{'loss': 1.0795, 'grad_norm': 21.817846298217773, 'learning_rate': 6.643058067108701e-06, 'epoch': 1.01}\n",
      "{'loss': 1.1198, 'grad_norm': 21.169628143310547, 'learning_rate': 6.638034960819772e-06, 'epoch': 1.01}\n",
      "{'loss': 1.0674, 'grad_norm': 26.780527114868164, 'learning_rate': 6.633011854530842e-06, 'epoch': 1.01}\n",
      "{'loss': 1.0648, 'grad_norm': 25.17306137084961, 'learning_rate': 6.627988748241914e-06, 'epoch': 1.01}\n",
      "{'loss': 1.0112, 'grad_norm': 7.412703037261963, 'learning_rate': 6.622965641952984e-06, 'epoch': 1.01}\n",
      "{'loss': 0.9642, 'grad_norm': 25.976869583129883, 'learning_rate': 6.617942535664055e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0736, 'grad_norm': 27.480541229248047, 'learning_rate': 6.612919429375126e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0883, 'grad_norm': 17.496389389038086, 'learning_rate': 6.607896323086197e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0814, 'grad_norm': 17.197690963745117, 'learning_rate': 6.602873216797267e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0527, 'grad_norm': 36.343292236328125, 'learning_rate': 6.597850110508339e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0344, 'grad_norm': 18.08538055419922, 'learning_rate': 6.592827004219409e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0567, 'grad_norm': 7.507582187652588, 'learning_rate': 6.58780389793048e-06, 'epoch': 1.02}\n",
      "{'loss': 1.0702, 'grad_norm': 23.53368377685547, 'learning_rate': 6.582780791641552e-06, 'epoch': 1.03}\n",
      "{'loss': 1.1019, 'grad_norm': 36.50556945800781, 'learning_rate': 6.577757685352623e-06, 'epoch': 1.03}\n",
      "{'loss': 1.1654, 'grad_norm': 39.538307189941406, 'learning_rate': 6.5727345790636934e-06, 'epoch': 1.03}\n",
      "{'loss': 1.0329, 'grad_norm': 16.441896438598633, 'learning_rate': 6.567711472774765e-06, 'epoch': 1.03}\n",
      "{'loss': 1.1069, 'grad_norm': 33.04887390136719, 'learning_rate': 6.5626883664858355e-06, 'epoch': 1.03}\n",
      "{'loss': 1.0479, 'grad_norm': 17.449209213256836, 'learning_rate': 6.557665260196906e-06, 'epoch': 1.03}\n",
      "{'loss': 1.0897, 'grad_norm': 38.95306396484375, 'learning_rate': 6.55314446453687e-06, 'epoch': 1.04}\n",
      "{'loss': 1.084, 'grad_norm': 22.331493377685547, 'learning_rate': 6.548121358247941e-06, 'epoch': 1.04}\n",
      "{'loss': 1.0719, 'grad_norm': 27.109201431274414, 'learning_rate': 6.543098251959012e-06, 'epoch': 1.04}\n",
      "{'loss': 1.1191, 'grad_norm': 20.38596534729004, 'learning_rate': 6.538075145670083e-06, 'epoch': 1.04}\n",
      "{'loss': 1.0689, 'grad_norm': 38.918643951416016, 'learning_rate': 6.533052039381153e-06, 'epoch': 1.04}\n",
      "{'loss': 1.0394, 'grad_norm': 28.55242919921875, 'learning_rate': 6.528028933092226e-06, 'epoch': 1.04}\n",
      "{'loss': 1.0208, 'grad_norm': 21.283124923706055, 'learning_rate': 6.523005826803296e-06, 'epoch': 1.04}\n",
      "{'loss': 0.9694, 'grad_norm': 6.408022880554199, 'learning_rate': 6.517982720514367e-06, 'epoch': 1.05}\n",
      "{'loss': 1.0485, 'grad_norm': 27.70806121826172, 'learning_rate': 6.512959614225437e-06, 'epoch': 1.05}\n",
      "{'loss': 1.0559, 'grad_norm': 24.06352996826172, 'learning_rate': 6.507936507936509e-06, 'epoch': 1.05}\n",
      "{'loss': 1.0011, 'grad_norm': 26.58108901977539, 'learning_rate': 6.502913401647579e-06, 'epoch': 1.05}\n",
      "{'loss': 1.1181, 'grad_norm': 38.013832092285156, 'learning_rate': 6.49789029535865e-06, 'epoch': 1.05}\n",
      "{'loss': 1.0277, 'grad_norm': 35.47370529174805, 'learning_rate': 6.492867189069721e-06, 'epoch': 1.05}\n",
      "{'loss': 1.0342, 'grad_norm': 5.497810363769531, 'learning_rate': 6.487844082780792e-06, 'epoch': 1.05}\n",
      "{'loss': 1.0291, 'grad_norm': 24.853904724121094, 'learning_rate': 6.4828209764918626e-06, 'epoch': 1.06}\n",
      "{'loss': 1.0345, 'grad_norm': 23.921955108642578, 'learning_rate': 6.477797870202934e-06, 'epoch': 1.06}\n",
      "{'loss': 1.0459, 'grad_norm': 16.333303451538086, 'learning_rate': 6.472774763914005e-06, 'epoch': 1.06}\n",
      "{'loss': 1.0743, 'grad_norm': 22.406831741333008, 'learning_rate': 6.467751657625075e-06, 'epoch': 1.06}\n",
      "{'loss': 1.1685, 'grad_norm': 21.00757598876953, 'learning_rate': 6.4627285513361475e-06, 'epoch': 1.06}\n",
      "{'loss': 1.0956, 'grad_norm': 25.92829132080078, 'learning_rate': 6.457705445047218e-06, 'epoch': 1.06}\n",
      "{'loss': 1.0643, 'grad_norm': 26.258686065673828, 'learning_rate': 6.452682338758289e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0532, 'grad_norm': 51.5184326171875, 'learning_rate': 6.44765923246936e-06, 'epoch': 1.07}\n",
      "{'loss': 1.1025, 'grad_norm': 25.10045051574707, 'learning_rate': 6.442636126180431e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0077, 'grad_norm': 19.708459854125977, 'learning_rate': 6.437613019891501e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0717, 'grad_norm': 26.82471466064453, 'learning_rate': 6.432589913602573e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0334, 'grad_norm': 29.726354598999023, 'learning_rate': 6.427566807313643e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0782, 'grad_norm': 21.8193416595459, 'learning_rate': 6.422543701024714e-06, 'epoch': 1.07}\n",
      "{'loss': 1.0327, 'grad_norm': 32.143463134765625, 'learning_rate': 6.417520594735785e-06, 'epoch': 1.08}\n",
      "{'loss': 1.0193, 'grad_norm': 18.555469512939453, 'learning_rate': 6.412497488446856e-06, 'epoch': 1.08}\n",
      "{'loss': 1.11, 'grad_norm': 35.32505798339844, 'learning_rate': 6.407474382157926e-06, 'epoch': 1.08}\n",
      "{'loss': 1.1339, 'grad_norm': 38.088626861572266, 'learning_rate': 6.402451275868999e-06, 'epoch': 1.08}\n",
      "{'loss': 1.0331, 'grad_norm': 35.335960388183594, 'learning_rate': 6.3974281695800684e-06, 'epoch': 1.08}\n",
      "{'loss': 1.0444, 'grad_norm': 17.16764259338379, 'learning_rate': 6.392405063291139e-06, 'epoch': 1.08}\n",
      "{'loss': 1.0768, 'grad_norm': 30.32727813720703, 'learning_rate': 6.387381957002211e-06, 'epoch': 1.08}\n",
      "{'loss': 1.0266, 'grad_norm': 18.85688591003418, 'learning_rate': 6.382358850713282e-06, 'epoch': 1.09}\n",
      "{'loss': 1.0915, 'grad_norm': 10.99334716796875, 'learning_rate': 6.3773357444243525e-06, 'epoch': 1.09}\n",
      "{'loss': 1.0933, 'grad_norm': 54.93281555175781, 'learning_rate': 6.372312638135424e-06, 'epoch': 1.09}\n",
      "{'loss': 1.0573, 'grad_norm': 33.04674530029297, 'learning_rate': 6.3672895318464945e-06, 'epoch': 1.09}\n",
      "{'loss': 0.9976, 'grad_norm': 27.785118103027344, 'learning_rate': 6.362266425557565e-06, 'epoch': 1.09}\n",
      "{'loss': 1.0859, 'grad_norm': 25.876102447509766, 'learning_rate': 6.3572433192686365e-06, 'epoch': 1.09}\n",
      "{'loss': 1.0786, 'grad_norm': 9.226035118103027, 'learning_rate': 6.352220212979707e-06, 'epoch': 1.1}\n",
      "{'loss': 1.0167, 'grad_norm': 20.801149368286133, 'learning_rate': 6.347197106690778e-06, 'epoch': 1.1}\n",
      "{'loss': 1.0815, 'grad_norm': 20.540483474731445, 'learning_rate': 6.342174000401849e-06, 'epoch': 1.1}\n",
      "{'loss': 1.0626, 'grad_norm': 29.34609031677246, 'learning_rate': 6.33715089411292e-06, 'epoch': 1.1}\n",
      "{'loss': 1.0402, 'grad_norm': 22.41656494140625, 'learning_rate': 6.33212778782399e-06, 'epoch': 1.1}\n",
      "{'loss': 1.0216, 'grad_norm': 27.87084197998047, 'learning_rate': 6.3271046815350626e-06, 'epoch': 1.1}\n",
      "{'loss': 1.0318, 'grad_norm': 8.117786407470703, 'learning_rate': 6.322081575246133e-06, 'epoch': 1.1}\n",
      "{'loss': 1.1157, 'grad_norm': 19.70301628112793, 'learning_rate': 6.317058468957204e-06, 'epoch': 1.11}\n",
      "{'loss': 1.1194, 'grad_norm': 17.206619262695312, 'learning_rate': 6.312035362668275e-06, 'epoch': 1.11}\n",
      "{'loss': 1.1208, 'grad_norm': 20.02043342590332, 'learning_rate': 6.307012256379346e-06, 'epoch': 1.11}\n",
      "{'loss': 0.9891, 'grad_norm': 8.913411140441895, 'learning_rate': 6.301989150090416e-06, 'epoch': 1.11}\n",
      "{'loss': 1.0729, 'grad_norm': 16.443492889404297, 'learning_rate': 6.296966043801488e-06, 'epoch': 1.11}\n",
      "{'loss': 1.0421, 'grad_norm': 6.460486888885498, 'learning_rate': 6.291942937512558e-06, 'epoch': 1.11}\n",
      "{'loss': 1.0623, 'grad_norm': 18.000944137573242, 'learning_rate': 6.286919831223629e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0395, 'grad_norm': 21.06005096435547, 'learning_rate': 6.2818967249346995e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0503, 'grad_norm': 20.642322540283203, 'learning_rate': 6.276873618645771e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0734, 'grad_norm': 28.37877082824707, 'learning_rate': 6.2718505123568415e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0449, 'grad_norm': 38.45965576171875, 'learning_rate': 6.266827406067912e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0253, 'grad_norm': 18.72831916809082, 'learning_rate': 6.261804299778984e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0873, 'grad_norm': 32.481536865234375, 'learning_rate': 6.256781193490055e-06, 'epoch': 1.12}\n",
      "{'loss': 1.0198, 'grad_norm': 21.90077018737793, 'learning_rate': 6.2517580872011256e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0389, 'grad_norm': 33.52493667602539, 'learning_rate': 6.246734980912197e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0756, 'grad_norm': 40.183555603027344, 'learning_rate': 6.2417118746232676e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0696, 'grad_norm': 44.339027404785156, 'learning_rate': 6.236688768334338e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0719, 'grad_norm': 6.26787805557251, 'learning_rate': 6.23166566204541e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0477, 'grad_norm': 18.689104080200195, 'learning_rate': 6.22664255575648e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0573, 'grad_norm': 32.276729583740234, 'learning_rate': 6.221619449467551e-06, 'epoch': 1.13}\n",
      "{'loss': 1.0882, 'grad_norm': 20.563894271850586, 'learning_rate': 6.216596343178622e-06, 'epoch': 1.14}\n",
      "{'loss': 1.0768, 'grad_norm': 26.91462516784668, 'learning_rate': 6.211573236889693e-06, 'epoch': 1.14}\n",
      "{'loss': 1.0006, 'grad_norm': 23.77053451538086, 'learning_rate': 6.206550130600763e-06, 'epoch': 1.14}\n",
      "{'loss': 1.1183, 'grad_norm': 22.836872100830078, 'learning_rate': 6.201527024311836e-06, 'epoch': 1.14}\n",
      "{'loss': 1.0289, 'grad_norm': 27.245481491088867, 'learning_rate': 6.196503918022906e-06, 'epoch': 1.14}\n",
      "{'loss': 1.1384, 'grad_norm': 39.51879119873047, 'learning_rate': 6.191480811733977e-06, 'epoch': 1.14}\n",
      "{'loss': 1.0463, 'grad_norm': 19.719667434692383, 'learning_rate': 6.186457705445048e-06, 'epoch': 1.15}\n",
      "{'loss': 1.0276, 'grad_norm': 7.284363269805908, 'learning_rate': 6.181434599156119e-06, 'epoch': 1.15}\n",
      "{'loss': 1.1147, 'grad_norm': 29.434452056884766, 'learning_rate': 6.176411492867189e-06, 'epoch': 1.15}\n",
      "{'loss': 0.9904, 'grad_norm': 25.9378662109375, 'learning_rate': 6.171388386578261e-06, 'epoch': 1.15}\n",
      "{'loss': 1.0102, 'grad_norm': 25.54304313659668, 'learning_rate': 6.166365280289331e-06, 'epoch': 1.15}\n",
      "{'loss': 1.0232, 'grad_norm': 39.38056945800781, 'learning_rate': 6.161342174000402e-06, 'epoch': 1.15}\n",
      "{'loss': 1.0929, 'grad_norm': 7.139951229095459, 'learning_rate': 6.1563190677114734e-06, 'epoch': 1.15}\n",
      "{'loss': 1.1279, 'grad_norm': 22.526628494262695, 'learning_rate': 6.151295961422544e-06, 'epoch': 1.16}\n",
      "{'loss': 1.0099, 'grad_norm': 19.332931518554688, 'learning_rate': 6.146272855133615e-06, 'epoch': 1.16}\n",
      "{'loss': 1.0667, 'grad_norm': 32.657989501953125, 'learning_rate': 6.141249748844687e-06, 'epoch': 1.16}\n",
      "{'loss': 1.148, 'grad_norm': 30.972335815429688, 'learning_rate': 6.1362266425557575e-06, 'epoch': 1.16}\n",
      "{'loss': 1.1182, 'grad_norm': 29.481847763061523, 'learning_rate': 6.131203536266828e-06, 'epoch': 1.16}\n",
      "{'loss': 1.0923, 'grad_norm': 39.02006530761719, 'learning_rate': 6.1261804299778995e-06, 'epoch': 1.16}\n",
      "{'loss': 1.0703, 'grad_norm': 28.367483139038086, 'learning_rate': 6.12115732368897e-06, 'epoch': 1.16}\n",
      "{'loss': 1.1496, 'grad_norm': 24.66265106201172, 'learning_rate': 6.116134217400041e-06, 'epoch': 1.17}\n",
      "{'loss': 1.0517, 'grad_norm': 35.27002716064453, 'learning_rate': 6.111111111111112e-06, 'epoch': 1.17}\n",
      "{'loss': 1.0139, 'grad_norm': 27.77920150756836, 'learning_rate': 6.106088004822183e-06, 'epoch': 1.17}\n",
      "{'loss': 1.0712, 'grad_norm': 35.64543533325195, 'learning_rate': 6.101064898533253e-06, 'epoch': 1.17}\n",
      "{'loss': 1.0246, 'grad_norm': 5.905285835266113, 'learning_rate': 6.096041792244325e-06, 'epoch': 1.17}\n",
      "{'loss': 1.0573, 'grad_norm': 34.787174224853516, 'learning_rate': 6.091018685955395e-06, 'epoch': 1.17}\n",
      "{'loss': 1.0619, 'grad_norm': 36.40140914916992, 'learning_rate': 6.085995579666466e-06, 'epoch': 1.18}\n",
      "{'loss': 1.0843, 'grad_norm': 8.085612297058105, 'learning_rate': 6.080972473377538e-06, 'epoch': 1.18}\n",
      "{'loss': 1.1054, 'grad_norm': 7.104891777038574, 'learning_rate': 6.075949367088608e-06, 'epoch': 1.18}\n",
      "{'loss': 1.0358, 'grad_norm': 26.550142288208008, 'learning_rate': 6.0709262607996785e-06, 'epoch': 1.18}\n",
      "{'loss': 1.0691, 'grad_norm': 16.84920883178711, 'learning_rate': 6.065903154510749e-06, 'epoch': 1.18}\n",
      "{'loss': 1.0555, 'grad_norm': 26.896316528320312, 'learning_rate': 6.060880048221821e-06, 'epoch': 1.18}\n",
      "{'loss': 1.0266, 'grad_norm': 22.366458892822266, 'learning_rate': 6.055856941932892e-06, 'epoch': 1.18}\n",
      "{'loss': 1.0762, 'grad_norm': 33.05243682861328, 'learning_rate': 6.0508338356439625e-06, 'epoch': 1.19}\n",
      "{'loss': 1.1033, 'grad_norm': 24.06198501586914, 'learning_rate': 6.045810729355034e-06, 'epoch': 1.19}\n",
      "{'loss': 1.0577, 'grad_norm': 9.06016731262207, 'learning_rate': 6.0407876230661045e-06, 'epoch': 1.19}\n",
      "{'loss': 1.1186, 'grad_norm': 25.62087631225586, 'learning_rate': 6.035764516777175e-06, 'epoch': 1.19}\n",
      "{'loss': 1.0575, 'grad_norm': 23.512727737426758, 'learning_rate': 6.0307414104882465e-06, 'epoch': 1.19}\n",
      "{'loss': 1.0287, 'grad_norm': 17.470930099487305, 'learning_rate': 6.025718304199317e-06, 'epoch': 1.19}\n",
      "{'loss': 1.0731, 'grad_norm': 34.84668731689453, 'learning_rate': 6.020695197910388e-06, 'epoch': 1.19}\n",
      "{'loss': 1.059, 'grad_norm': 7.811486721038818, 'learning_rate': 6.015672091621459e-06, 'epoch': 1.2}\n",
      "{'loss': 1.0655, 'grad_norm': 27.640666961669922, 'learning_rate': 6.01064898533253e-06, 'epoch': 1.2}\n",
      "{'loss': 1.0285, 'grad_norm': 39.63882064819336, 'learning_rate': 6.0056258790436e-06, 'epoch': 1.2}\n",
      "{'loss': 1.0413, 'grad_norm': 7.942190170288086, 'learning_rate': 6.0006027727546726e-06, 'epoch': 1.2}\n",
      "{'loss': 1.1341, 'grad_norm': 53.825862884521484, 'learning_rate': 5.995579666465743e-06, 'epoch': 1.2}\n",
      "{'loss': 1.0831, 'grad_norm': 27.471282958984375, 'learning_rate': 5.990556560176814e-06, 'epoch': 1.2}\n",
      "{'loss': 1.0107, 'grad_norm': 14.422332763671875, 'learning_rate': 5.985533453887885e-06, 'epoch': 1.21}\n",
      "{'loss': 1.0488, 'grad_norm': 17.207630157470703, 'learning_rate': 5.980510347598956e-06, 'epoch': 1.21}\n",
      "{'loss': 1.0257, 'grad_norm': 26.685443878173828, 'learning_rate': 5.975487241310026e-06, 'epoch': 1.21}\n",
      "{'loss': 1.0141, 'grad_norm': 19.20652961730957, 'learning_rate': 5.970464135021098e-06, 'epoch': 1.21}\n",
      "{'loss': 1.1239, 'grad_norm': 6.820115566253662, 'learning_rate': 5.965441028732168e-06, 'epoch': 1.21}\n",
      "{'loss': 1.0774, 'grad_norm': 20.534555435180664, 'learning_rate': 5.960417922443239e-06, 'epoch': 1.21}\n",
      "{'loss': 1.1083, 'grad_norm': 18.66358184814453, 'learning_rate': 5.95539481615431e-06, 'epoch': 1.21}\n",
      "{'loss': 1.0914, 'grad_norm': 20.02007293701172, 'learning_rate': 5.950371709865381e-06, 'epoch': 1.22}\n",
      "{'loss': 1.0263, 'grad_norm': 6.873499393463135, 'learning_rate': 5.9453486035764515e-06, 'epoch': 1.22}\n",
      "{'loss': 0.989, 'grad_norm': 24.846874237060547, 'learning_rate': 5.940325497287524e-06, 'epoch': 1.22}\n",
      "{'loss': 1.1343, 'grad_norm': 42.9857177734375, 'learning_rate': 5.935302390998594e-06, 'epoch': 1.22}\n",
      "{'loss': 0.9804, 'grad_norm': 7.358277797698975, 'learning_rate': 5.930279284709665e-06, 'epoch': 1.22}\n",
      "{'loss': 1.0833, 'grad_norm': 32.838958740234375, 'learning_rate': 5.925256178420736e-06, 'epoch': 1.22}\n",
      "{'loss': 1.0888, 'grad_norm': 35.82650375366211, 'learning_rate': 5.920233072131807e-06, 'epoch': 1.23}\n",
      "{'loss': 1.0004, 'grad_norm': 8.319352149963379, 'learning_rate': 5.915209965842878e-06, 'epoch': 1.23}\n",
      "{'loss': 1.0634, 'grad_norm': 8.457921028137207, 'learning_rate': 5.910186859553949e-06, 'epoch': 1.23}\n",
      "{'loss': 1.0767, 'grad_norm': 22.73214340209961, 'learning_rate': 5.90516375326502e-06, 'epoch': 1.23}\n",
      "{'loss': 1.0228, 'grad_norm': 33.689083099365234, 'learning_rate': 5.90014064697609e-06, 'epoch': 1.23}\n",
      "{'loss': 1.0148, 'grad_norm': 19.101547241210938, 'learning_rate': 5.895117540687162e-06, 'epoch': 1.23}\n",
      "{'loss': 1.1087, 'grad_norm': 8.295209884643555, 'learning_rate': 5.890094434398232e-06, 'epoch': 1.23}\n",
      "{'loss': 1.1168, 'grad_norm': 23.126340866088867, 'learning_rate': 5.885071328109303e-06, 'epoch': 1.24}\n",
      "{'loss': 1.1083, 'grad_norm': 24.869525909423828, 'learning_rate': 5.880048221820375e-06, 'epoch': 1.24}\n",
      "{'loss': 1.0658, 'grad_norm': 24.58983039855957, 'learning_rate': 5.875025115531446e-06, 'epoch': 1.24}\n",
      "{'loss': 1.0381, 'grad_norm': 20.558765411376953, 'learning_rate': 5.870002009242516e-06, 'epoch': 1.24}\n",
      "{'loss': 1.0717, 'grad_norm': 5.562564373016357, 'learning_rate': 5.864978902953588e-06, 'epoch': 1.24}\n",
      "{'loss': 1.0386, 'grad_norm': 19.916397094726562, 'learning_rate': 5.859955796664658e-06, 'epoch': 1.24}\n",
      "{'loss': 1.0972, 'grad_norm': 7.793185234069824, 'learning_rate': 5.854932690375729e-06, 'epoch': 1.24}\n",
      "{'loss': 1.0727, 'grad_norm': 22.868572235107422, 'learning_rate': 5.849909584086799e-06, 'epoch': 1.25}\n",
      "{'loss': 1.0329, 'grad_norm': 28.01286506652832, 'learning_rate': 5.844886477797871e-06, 'epoch': 1.25}\n",
      "{'loss': 1.1002, 'grad_norm': 34.314109802246094, 'learning_rate': 5.8398633715089414e-06, 'epoch': 1.25}\n",
      "{'loss': 1.06, 'grad_norm': 7.963015556335449, 'learning_rate': 5.834840265220012e-06, 'epoch': 1.25}\n",
      "{'loss': 1.0391, 'grad_norm': 5.6206865310668945, 'learning_rate': 5.8298171589310834e-06, 'epoch': 1.25}\n",
      "{'loss': 1.0384, 'grad_norm': 26.67831802368164, 'learning_rate': 5.824794052642154e-06, 'epoch': 1.25}\n",
      "{'loss': 1.0837, 'grad_norm': 7.394624710083008, 'learning_rate': 5.819770946353225e-06, 'epoch': 1.26}\n",
      "{'loss': 1.0933, 'grad_norm': 24.476205825805664, 'learning_rate': 5.814747840064297e-06, 'epoch': 1.26}\n",
      "{'loss': 1.1057, 'grad_norm': 18.655593872070312, 'learning_rate': 5.809724733775367e-06, 'epoch': 1.26}\n",
      "{'loss': 1.0477, 'grad_norm': 19.883264541625977, 'learning_rate': 5.804701627486437e-06, 'epoch': 1.26}\n",
      "{'loss': 1.0036, 'grad_norm': 7.1044416427612305, 'learning_rate': 5.7996785211975095e-06, 'epoch': 1.26}\n",
      "{'loss': 1.0732, 'grad_norm': 23.40485191345215, 'learning_rate': 5.79465541490858e-06, 'epoch': 1.26}\n",
      "{'loss': 1.1029, 'grad_norm': 27.94492530822754, 'learning_rate': 5.789632308619651e-06, 'epoch': 1.26}\n",
      "{'loss': 1.0409, 'grad_norm': 16.126806259155273, 'learning_rate': 5.784609202330722e-06, 'epoch': 1.27}\n",
      "{'loss': 1.0198, 'grad_norm': 25.84477996826172, 'learning_rate': 5.779586096041793e-06, 'epoch': 1.27}\n",
      "{'loss': 1.0286, 'grad_norm': 19.2818660736084, 'learning_rate': 5.774562989752863e-06, 'epoch': 1.27}\n",
      "{'loss': 1.0687, 'grad_norm': 19.36414909362793, 'learning_rate': 5.769539883463935e-06, 'epoch': 1.27}\n",
      "{'loss': 1.082, 'grad_norm': 34.63433837890625, 'learning_rate': 5.764516777175005e-06, 'epoch': 1.27}\n",
      "{'loss': 1.0279, 'grad_norm': 20.940950393676758, 'learning_rate': 5.759493670886076e-06, 'epoch': 1.27}\n",
      "{'loss': 1.0935, 'grad_norm': 22.608009338378906, 'learning_rate': 5.754470564597147e-06, 'epoch': 1.27}\n",
      "{'loss': 1.1152, 'grad_norm': 6.492074489593506, 'learning_rate': 5.749447458308218e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0835, 'grad_norm': 24.094928741455078, 'learning_rate': 5.7444243520192885e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0847, 'grad_norm': 18.37766456604004, 'learning_rate': 5.739401245730361e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0919, 'grad_norm': 16.721853256225586, 'learning_rate': 5.734378139441431e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0512, 'grad_norm': 32.180789947509766, 'learning_rate': 5.729355033152502e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0516, 'grad_norm': 23.01680564880371, 'learning_rate': 5.724331926863573e-06, 'epoch': 1.28}\n",
      "{'loss': 1.0917, 'grad_norm': 32.93423843383789, 'learning_rate': 5.719308820574644e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0341, 'grad_norm': 34.19609451293945, 'learning_rate': 5.7142857142857145e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0596, 'grad_norm': 29.59908676147461, 'learning_rate': 5.709262607996786e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0578, 'grad_norm': 17.025068283081055, 'learning_rate': 5.7042395017078565e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0651, 'grad_norm': 27.44809913635254, 'learning_rate': 5.699216395418927e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0477, 'grad_norm': 21.73680877685547, 'learning_rate': 5.6941932891299985e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0248, 'grad_norm': 28.784164428710938, 'learning_rate': 5.689170182841069e-06, 'epoch': 1.29}\n",
      "{'loss': 1.0866, 'grad_norm': 16.027996063232422, 'learning_rate': 5.68414707655214e-06, 'epoch': 1.3}\n",
      "{'loss': 1.0435, 'grad_norm': 25.058116912841797, 'learning_rate': 5.679123970263212e-06, 'epoch': 1.3}\n",
      "{'loss': 1.0376, 'grad_norm': 6.764988422393799, 'learning_rate': 5.6741008639742826e-06, 'epoch': 1.3}\n",
      "{'loss': 1.0998, 'grad_norm': 29.720718383789062, 'learning_rate': 5.669077757685353e-06, 'epoch': 1.3}\n",
      "{'loss': 1.0494, 'grad_norm': 9.653854370117188, 'learning_rate': 5.664054651396425e-06, 'epoch': 1.3}\n",
      "{'loss': 1.0084, 'grad_norm': 26.639894485473633, 'learning_rate': 5.659031545107495e-06, 'epoch': 1.3}\n",
      "{'loss': 1.1682, 'grad_norm': 14.196158409118652, 'learning_rate': 5.654008438818566e-06, 'epoch': 1.31}\n",
      "{'loss': 1.0586, 'grad_norm': 8.677181243896484, 'learning_rate': 5.648985332529637e-06, 'epoch': 1.31}\n",
      "{'loss': 1.0432, 'grad_norm': 26.88959312438965, 'learning_rate': 5.643962226240708e-06, 'epoch': 1.31}\n",
      "{'loss': 1.0674, 'grad_norm': 37.832786560058594, 'learning_rate': 5.638939119951778e-06, 'epoch': 1.31}\n",
      "{'loss': 1.0336, 'grad_norm': 18.290782928466797, 'learning_rate': 5.633916013662849e-06, 'epoch': 1.31}\n",
      "{'loss': 1.1191, 'grad_norm': 18.1868839263916, 'learning_rate': 5.62889290737392e-06, 'epoch': 1.31}\n",
      "{'loss': 1.0891, 'grad_norm': 6.741872787475586, 'learning_rate': 5.623869801084991e-06, 'epoch': 1.31}\n",
      "{'loss': 1.0449, 'grad_norm': 22.474267959594727, 'learning_rate': 5.6188466947960615e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0222, 'grad_norm': 22.709754943847656, 'learning_rate': 5.613823588507134e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0854, 'grad_norm': 32.879451751708984, 'learning_rate': 5.608800482218204e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0947, 'grad_norm': 27.402833938598633, 'learning_rate': 5.603777375929275e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0424, 'grad_norm': 18.29095458984375, 'learning_rate': 5.5987542696403464e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0073, 'grad_norm': 22.0296630859375, 'learning_rate': 5.593731163351417e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0652, 'grad_norm': 5.768673896789551, 'learning_rate': 5.588708057062488e-06, 'epoch': 1.32}\n",
      "{'loss': 1.0776, 'grad_norm': 8.824529647827148, 'learning_rate': 5.583684950773559e-06, 'epoch': 1.33}\n",
      "{'loss': 1.0924, 'grad_norm': 5.898187637329102, 'learning_rate': 5.57866184448463e-06, 'epoch': 1.33}\n",
      "{'loss': 1.084, 'grad_norm': 8.284741401672363, 'learning_rate': 5.5736387381957e-06, 'epoch': 1.33}\n",
      "{'loss': 1.0805, 'grad_norm': 14.321015357971191, 'learning_rate': 5.568615631906772e-06, 'epoch': 1.33}\n",
      "{'loss': 1.0239, 'grad_norm': 14.947726249694824, 'learning_rate': 5.563592525617842e-06, 'epoch': 1.33}\n",
      "{'loss': 1.1146, 'grad_norm': 16.835254669189453, 'learning_rate': 5.558569419328913e-06, 'epoch': 1.33}\n",
      "{'loss': 1.1017, 'grad_norm': 8.19172191619873, 'learning_rate': 5.553546313039985e-06, 'epoch': 1.34}\n",
      "{'loss': 1.097, 'grad_norm': 29.347644805908203, 'learning_rate': 5.548523206751056e-06, 'epoch': 1.34}\n",
      "{'loss': 1.0394, 'grad_norm': 8.342610359191895, 'learning_rate': 5.543500100462126e-06, 'epoch': 1.34}\n",
      "{'loss': 1.0704, 'grad_norm': 34.929569244384766, 'learning_rate': 5.538476994173198e-06, 'epoch': 1.34}\n",
      "{'loss': 1.0019, 'grad_norm': 28.093639373779297, 'learning_rate': 5.533453887884268e-06, 'epoch': 1.34}\n",
      "{'loss': 1.1174, 'grad_norm': 27.213010787963867, 'learning_rate': 5.528430781595339e-06, 'epoch': 1.34}\n",
      "{'loss': 1.0524, 'grad_norm': 13.16734790802002, 'learning_rate': 5.52340767530641e-06, 'epoch': 1.34}\n",
      "{'loss': 1.0463, 'grad_norm': 31.889299392700195, 'learning_rate': 5.518384569017481e-06, 'epoch': 1.35}\n",
      "{'loss': 1.0501, 'grad_norm': 36.854461669921875, 'learning_rate': 5.5133614627285514e-06, 'epoch': 1.35}\n",
      "{'loss': 1.0548, 'grad_norm': 8.023000717163086, 'learning_rate': 5.508338356439623e-06, 'epoch': 1.35}\n",
      "{'loss': 1.0227, 'grad_norm': 34.65718078613281, 'learning_rate': 5.5033152501506935e-06, 'epoch': 1.35}\n",
      "{'loss': 1.0942, 'grad_norm': 26.562217712402344, 'learning_rate': 5.498794454490658e-06, 'epoch': 1.35}\n",
      "{'loss': 1.0644, 'grad_norm': 31.434743881225586, 'learning_rate': 5.493771348201728e-06, 'epoch': 1.35}\n",
      "{'loss': 1.0263, 'grad_norm': 19.889001846313477, 'learning_rate': 5.488748241912799e-06, 'epoch': 1.35}\n",
      "{'loss': 1.1408, 'grad_norm': 7.7058258056640625, 'learning_rate': 5.483725135623871e-06, 'epoch': 1.36}\n",
      "{'loss': 1.0629, 'grad_norm': 28.191097259521484, 'learning_rate': 5.478702029334942e-06, 'epoch': 1.36}\n",
      "{'loss': 1.0465, 'grad_norm': 23.652292251586914, 'learning_rate': 5.473678923046012e-06, 'epoch': 1.36}\n",
      "{'loss': 1.0664, 'grad_norm': 22.061050415039062, 'learning_rate': 5.468655816757084e-06, 'epoch': 1.36}\n",
      "{'loss': 1.1078, 'grad_norm': 28.981281280517578, 'learning_rate': 5.463632710468154e-06, 'epoch': 1.36}\n",
      "{'loss': 1.0244, 'grad_norm': 20.706892013549805, 'learning_rate': 5.458609604179225e-06, 'epoch': 1.36}\n",
      "{'loss': 1.0023, 'grad_norm': 29.19998550415039, 'learning_rate': 5.453586497890295e-06, 'epoch': 1.37}\n",
      "{'loss': 1.0982, 'grad_norm': 24.947111129760742, 'learning_rate': 5.448563391601367e-06, 'epoch': 1.37}\n",
      "{'loss': 1.0356, 'grad_norm': 24.489233016967773, 'learning_rate': 5.443540285312437e-06, 'epoch': 1.37}\n",
      "{'loss': 1.0559, 'grad_norm': 39.09868621826172, 'learning_rate': 5.438517179023508e-06, 'epoch': 1.37}\n",
      "{'loss': 1.071, 'grad_norm': 11.61293888092041, 'learning_rate': 5.433494072734579e-06, 'epoch': 1.37}\n",
      "{'loss': 1.0815, 'grad_norm': 21.075584411621094, 'learning_rate': 5.42847096644565e-06, 'epoch': 1.37}\n",
      "{'loss': 1.0312, 'grad_norm': 35.69236755371094, 'learning_rate': 5.423447860156721e-06, 'epoch': 1.37}\n",
      "{'loss': 1.1352, 'grad_norm': 23.984426498413086, 'learning_rate': 5.418424753867793e-06, 'epoch': 1.38}\n",
      "{'loss': 1.0183, 'grad_norm': 15.846769332885742, 'learning_rate': 5.4134016475788634e-06, 'epoch': 1.38}\n",
      "{'loss': 1.0421, 'grad_norm': 19.808334350585938, 'learning_rate': 5.408378541289934e-06, 'epoch': 1.38}\n",
      "{'loss': 1.0556, 'grad_norm': 9.01692008972168, 'learning_rate': 5.4033554350010055e-06, 'epoch': 1.38}\n",
      "{'loss': 1.0712, 'grad_norm': 4.390356063842773, 'learning_rate': 5.398332328712076e-06, 'epoch': 1.38}\n",
      "{'loss': 1.0619, 'grad_norm': 26.014816284179688, 'learning_rate': 5.393309222423147e-06, 'epoch': 1.38}\n",
      "{'loss': 1.1298, 'grad_norm': 7.453722953796387, 'learning_rate': 5.388286116134218e-06, 'epoch': 1.38}\n",
      "{'loss': 0.9945, 'grad_norm': 20.49506950378418, 'learning_rate': 5.383263009845289e-06, 'epoch': 1.39}\n",
      "{'loss': 1.0237, 'grad_norm': 17.754947662353516, 'learning_rate': 5.378239903556359e-06, 'epoch': 1.39}\n",
      "{'loss': 1.0799, 'grad_norm': 23.825565338134766, 'learning_rate': 5.373216797267431e-06, 'epoch': 1.39}\n",
      "{'loss': 1.0367, 'grad_norm': 9.051139831542969, 'learning_rate': 5.368193690978501e-06, 'epoch': 1.39}\n",
      "{'loss': 1.0499, 'grad_norm': 23.077043533325195, 'learning_rate': 5.363170584689572e-06, 'epoch': 1.39}\n",
      "{'loss': 1.0702, 'grad_norm': 30.256052017211914, 'learning_rate': 5.358147478400644e-06, 'epoch': 1.39}\n",
      "{'loss': 1.041, 'grad_norm': 18.022302627563477, 'learning_rate': 5.353124372111715e-06, 'epoch': 1.4}\n",
      "{'loss': 1.0935, 'grad_norm': 38.681640625, 'learning_rate': 5.348101265822785e-06, 'epoch': 1.4}\n",
      "{'loss': 1.0758, 'grad_norm': 23.816692352294922, 'learning_rate': 5.343078159533857e-06, 'epoch': 1.4}\n",
      "{'loss': 1.0464, 'grad_norm': 24.210519790649414, 'learning_rate': 5.338055053244927e-06, 'epoch': 1.4}\n",
      "{'loss': 1.054, 'grad_norm': 46.582698822021484, 'learning_rate': 5.333031946955998e-06, 'epoch': 1.4}\n",
      "{'loss': 1.0149, 'grad_norm': 15.18908405303955, 'learning_rate': 5.328008840667069e-06, 'epoch': 1.4}\n",
      "{'loss': 1.0679, 'grad_norm': 7.374090194702148, 'learning_rate': 5.32298573437814e-06, 'epoch': 1.4}\n",
      "{'loss': 1.0218, 'grad_norm': 28.95913314819336, 'learning_rate': 5.3179626280892105e-06, 'epoch': 1.41}\n",
      "{'loss': 1.0611, 'grad_norm': 19.918800354003906, 'learning_rate': 5.312939521800282e-06, 'epoch': 1.41}\n",
      "{'loss': 0.9449, 'grad_norm': 26.28973388671875, 'learning_rate': 5.3079164155113525e-06, 'epoch': 1.41}\n",
      "{'loss': 1.0969, 'grad_norm': 37.297706604003906, 'learning_rate': 5.302893309222423e-06, 'epoch': 1.41}\n",
      "{'loss': 1.0732, 'grad_norm': 52.28599166870117, 'learning_rate': 5.297870202933495e-06, 'epoch': 1.41}\n",
      "{'loss': 1.1121, 'grad_norm': 9.00322151184082, 'learning_rate': 5.292847096644566e-06, 'epoch': 1.41}\n",
      "{'loss': 1.0968, 'grad_norm': 17.662057876586914, 'learning_rate': 5.287823990355636e-06, 'epoch': 1.42}\n",
      "{'loss': 0.9867, 'grad_norm': 45.47655487060547, 'learning_rate': 5.282800884066708e-06, 'epoch': 1.42}\n",
      "{'loss': 1.0247, 'grad_norm': 19.450008392333984, 'learning_rate': 5.2777777777777785e-06, 'epoch': 1.42}\n",
      "{'loss': 1.0102, 'grad_norm': 41.80009460449219, 'learning_rate': 5.272754671488849e-06, 'epoch': 1.42}\n",
      "{'loss': 1.0542, 'grad_norm': 27.901369094848633, 'learning_rate': 5.2677315651999206e-06, 'epoch': 1.42}\n",
      "{'loss': 1.0394, 'grad_norm': 39.971927642822266, 'learning_rate': 5.262708458910991e-06, 'epoch': 1.42}\n",
      "{'loss': 1.0748, 'grad_norm': 10.91565227508545, 'learning_rate': 5.257685352622062e-06, 'epoch': 1.42}\n",
      "{'loss': 1.0526, 'grad_norm': 23.42629623413086, 'learning_rate': 5.252662246333133e-06, 'epoch': 1.43}\n",
      "{'loss': 1.0416, 'grad_norm': 27.892555236816406, 'learning_rate': 5.247639140044204e-06, 'epoch': 1.43}\n",
      "{'loss': 1.0185, 'grad_norm': 36.128257751464844, 'learning_rate': 5.242616033755274e-06, 'epoch': 1.43}\n",
      "{'loss': 1.044, 'grad_norm': 35.021766662597656, 'learning_rate': 5.237592927466345e-06, 'epoch': 1.43}\n",
      "{'loss': 1.1156, 'grad_norm': 29.652267456054688, 'learning_rate': 5.232569821177416e-06, 'epoch': 1.43}\n",
      "{'loss': 1.0836, 'grad_norm': 36.50718688964844, 'learning_rate': 5.227546714888487e-06, 'epoch': 1.43}\n",
      "{'loss': 1.0061, 'grad_norm': 7.520945072174072, 'learning_rate': 5.2225236085995575e-06, 'epoch': 1.43}\n",
      "{'loss': 1.0656, 'grad_norm': 21.426151275634766, 'learning_rate': 5.21750050231063e-06, 'epoch': 1.44}\n",
      "{'loss': 1.0818, 'grad_norm': 34.46543884277344, 'learning_rate': 5.2124773960217e-06, 'epoch': 1.44}\n",
      "{'loss': 1.0641, 'grad_norm': 25.81304359436035, 'learning_rate': 5.207454289732771e-06, 'epoch': 1.44}\n",
      "{'loss': 1.0798, 'grad_norm': 27.098461151123047, 'learning_rate': 5.202431183443842e-06, 'epoch': 1.44}\n",
      "{'loss': 1.0193, 'grad_norm': 27.097429275512695, 'learning_rate': 5.197408077154913e-06, 'epoch': 1.44}\n",
      "{'loss': 1.0713, 'grad_norm': 26.480079650878906, 'learning_rate': 5.1923849708659836e-06, 'epoch': 1.44}\n",
      "{'loss': 1.0474, 'grad_norm': 23.001447677612305, 'learning_rate': 5.187361864577055e-06, 'epoch': 1.45}\n",
      "{'loss': 1.0476, 'grad_norm': 25.680500030517578, 'learning_rate': 5.1823387582881256e-06, 'epoch': 1.45}\n",
      "{'loss': 1.0096, 'grad_norm': 27.27870750427246, 'learning_rate': 5.177315651999196e-06, 'epoch': 1.45}\n",
      "{'loss': 1.0239, 'grad_norm': 16.81580924987793, 'learning_rate': 5.172292545710268e-06, 'epoch': 1.45}\n",
      "{'loss': 1.1105, 'grad_norm': 24.208263397216797, 'learning_rate': 5.167269439421338e-06, 'epoch': 1.45}\n",
      "{'loss': 1.0887, 'grad_norm': 19.311731338500977, 'learning_rate': 5.162246333132409e-06, 'epoch': 1.45}\n",
      "{'loss': 1.0556, 'grad_norm': 22.938091278076172, 'learning_rate': 5.157223226843481e-06, 'epoch': 1.45}\n",
      "{'loss': 1.0339, 'grad_norm': 22.253496170043945, 'learning_rate': 5.152200120554552e-06, 'epoch': 1.46}\n",
      "{'loss': 1.0159, 'grad_norm': 17.48688316345215, 'learning_rate': 5.147177014265622e-06, 'epoch': 1.46}\n",
      "{'loss': 1.0752, 'grad_norm': 39.96870803833008, 'learning_rate': 5.142153907976694e-06, 'epoch': 1.46}\n",
      "{'loss': 1.0913, 'grad_norm': 25.92470359802246, 'learning_rate': 5.137130801687764e-06, 'epoch': 1.46}\n",
      "{'loss': 1.08, 'grad_norm': 14.672914505004883, 'learning_rate': 5.132107695398835e-06, 'epoch': 1.46}\n",
      "{'loss': 1.0451, 'grad_norm': 46.42383575439453, 'learning_rate': 5.127084589109906e-06, 'epoch': 1.46}\n",
      "{'loss': 1.1284, 'grad_norm': 29.187515258789062, 'learning_rate': 5.122061482820977e-06, 'epoch': 1.46}\n",
      "{'loss': 1.0397, 'grad_norm': 17.197509765625, 'learning_rate': 5.117038376532047e-06, 'epoch': 1.47}\n",
      "{'loss': 1.0913, 'grad_norm': 28.008426666259766, 'learning_rate': 5.112015270243119e-06, 'epoch': 1.47}\n",
      "{'loss': 1.0743, 'grad_norm': 9.916955947875977, 'learning_rate': 5.106992163954189e-06, 'epoch': 1.47}\n",
      "{'loss': 1.0588, 'grad_norm': 28.16106414794922, 'learning_rate': 5.10196905766526e-06, 'epoch': 1.47}\n",
      "{'loss': 1.1203, 'grad_norm': 8.446889877319336, 'learning_rate': 5.096945951376332e-06, 'epoch': 1.47}\n",
      "{'loss': 1.079, 'grad_norm': 28.235523223876953, 'learning_rate': 5.091922845087403e-06, 'epoch': 1.47}\n",
      "{'loss': 1.0512, 'grad_norm': 22.42625617980957, 'learning_rate': 5.0868997387984735e-06, 'epoch': 1.48}\n",
      "{'loss': 1.0605, 'grad_norm': 9.396416664123535, 'learning_rate': 5.081876632509545e-06, 'epoch': 1.48}\n",
      "{'loss': 1.0114, 'grad_norm': 20.748788833618164, 'learning_rate': 5.0768535262206155e-06, 'epoch': 1.48}\n",
      "{'loss': 1.0413, 'grad_norm': 9.623832702636719, 'learning_rate': 5.071830419931686e-06, 'epoch': 1.48}\n",
      "{'loss': 1.1357, 'grad_norm': 15.898796081542969, 'learning_rate': 5.0668073136427575e-06, 'epoch': 1.48}\n",
      "{'loss': 1.0775, 'grad_norm': 31.650192260742188, 'learning_rate': 5.061784207353828e-06, 'epoch': 1.48}\n",
      "{'loss': 1.0491, 'grad_norm': 41.20096206665039, 'learning_rate': 5.056761101064899e-06, 'epoch': 1.48}\n",
      "{'loss': 1.0442, 'grad_norm': 16.972997665405273, 'learning_rate': 5.05173799477597e-06, 'epoch': 1.49}\n",
      "{'loss': 1.1169, 'grad_norm': 28.703542709350586, 'learning_rate': 5.046714888487041e-06, 'epoch': 1.49}\n",
      "{'loss': 1.0625, 'grad_norm': 35.04322052001953, 'learning_rate': 5.041691782198111e-06, 'epoch': 1.49}\n",
      "{'loss': 1.0081, 'grad_norm': 21.310043334960938, 'learning_rate': 5.0366686759091835e-06, 'epoch': 1.49}\n",
      "{'loss': 1.0917, 'grad_norm': 8.989176750183105, 'learning_rate': 5.031645569620254e-06, 'epoch': 1.49}\n",
      "{'loss': 1.0384, 'grad_norm': 21.831106185913086, 'learning_rate': 5.026622463331325e-06, 'epoch': 1.49}\n",
      "{'loss': 1.0946, 'grad_norm': 33.938358306884766, 'learning_rate': 5.021599357042395e-06, 'epoch': 1.49}\n",
      "{'loss': 1.0948, 'grad_norm': 31.214706420898438, 'learning_rate': 5.016576250753467e-06, 'epoch': 1.5}\n",
      "{'loss': 1.0681, 'grad_norm': 8.63580322265625, 'learning_rate': 5.011553144464537e-06, 'epoch': 1.5}\n",
      "{'loss': 1.0601, 'grad_norm': 17.59412384033203, 'learning_rate': 5.006530038175608e-06, 'epoch': 1.5}\n",
      "{'loss': 1.1128, 'grad_norm': 18.867708206176758, 'learning_rate': 5.001506931886679e-06, 'epoch': 1.5}\n",
      "{'loss': 1.1015, 'grad_norm': 17.514827728271484, 'learning_rate': 4.99648382559775e-06, 'epoch': 1.5}\n",
      "{'loss': 1.0449, 'grad_norm': 27.37811851501465, 'learning_rate': 4.991460719308821e-06, 'epoch': 1.5}\n",
      "{'loss': 1.0107, 'grad_norm': 27.517595291137695, 'learning_rate': 4.986437613019892e-06, 'epoch': 1.51}\n",
      "{'loss': 1.0408, 'grad_norm': 30.09307098388672, 'learning_rate': 4.9814145067309625e-06, 'epoch': 1.51}\n",
      "{'loss': 0.9922, 'grad_norm': 30.49379539489746, 'learning_rate': 4.976391400442034e-06, 'epoch': 1.51}\n",
      "{'loss': 1.085, 'grad_norm': 33.57603454589844, 'learning_rate': 4.971368294153105e-06, 'epoch': 1.51}\n",
      "{'loss': 1.0711, 'grad_norm': 45.39377975463867, 'learning_rate': 4.966345187864175e-06, 'epoch': 1.51}\n",
      "{'loss': 0.9989, 'grad_norm': 21.743011474609375, 'learning_rate': 4.9613220815752465e-06, 'epoch': 1.51}\n",
      "{'loss': 1.0821, 'grad_norm': 23.21381187438965, 'learning_rate': 4.956298975286317e-06, 'epoch': 1.51}\n",
      "{'loss': 1.0459, 'grad_norm': 15.705220222473145, 'learning_rate': 4.9512758689973886e-06, 'epoch': 1.52}\n",
      "{'loss': 1.05, 'grad_norm': 13.19965934753418, 'learning_rate': 4.946252762708459e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0318, 'grad_norm': 28.35504722595215, 'learning_rate': 4.94122965641953e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0762, 'grad_norm': 28.4377384185791, 'learning_rate': 4.936206550130601e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0442, 'grad_norm': 38.656246185302734, 'learning_rate': 4.931183443841673e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0886, 'grad_norm': 38.54508972167969, 'learning_rate': 4.926160337552743e-06, 'epoch': 1.52}\n",
      "{'loss': 1.0041, 'grad_norm': 28.29036521911621, 'learning_rate': 4.921137231263814e-06, 'epoch': 1.53}\n",
      "{'loss': 1.0821, 'grad_norm': 32.238372802734375, 'learning_rate': 4.916114124974885e-06, 'epoch': 1.53}\n",
      "{'loss': 0.998, 'grad_norm': 7.910130023956299, 'learning_rate': 4.911091018685956e-06, 'epoch': 1.53}\n",
      "{'loss': 1.0816, 'grad_norm': 17.566020965576172, 'learning_rate': 4.906067912397026e-06, 'epoch': 1.53}\n",
      "{'loss': 1.0513, 'grad_norm': 18.46691131591797, 'learning_rate': 4.901044806108098e-06, 'epoch': 1.53}\n",
      "{'loss': 1.1029, 'grad_norm': 38.70887756347656, 'learning_rate': 4.896021699819168e-06, 'epoch': 1.53}\n",
      "{'loss': 1.1576, 'grad_norm': 34.39256286621094, 'learning_rate': 4.89099859353024e-06, 'epoch': 1.53}\n",
      "{'loss': 1.0907, 'grad_norm': 27.758852005004883, 'learning_rate': 4.88597548724131e-06, 'epoch': 1.54}\n",
      "{'loss': 1.1128, 'grad_norm': 16.228660583496094, 'learning_rate': 4.880952380952381e-06, 'epoch': 1.54}\n",
      "{'loss': 1.0183, 'grad_norm': 29.876794815063477, 'learning_rate': 4.875929274663452e-06, 'epoch': 1.54}\n",
      "{'loss': 1.0826, 'grad_norm': 29.574007034301758, 'learning_rate': 4.870906168374524e-06, 'epoch': 1.54}\n",
      "{'loss': 1.036, 'grad_norm': 17.13568878173828, 'learning_rate': 4.865883062085594e-06, 'epoch': 1.54}\n",
      "{'loss': 1.0489, 'grad_norm': 25.96615982055664, 'learning_rate': 4.860859955796665e-06, 'epoch': 1.54}\n",
      "{'loss': 1.0636, 'grad_norm': 14.70272445678711, 'learning_rate': 4.855836849507736e-06, 'epoch': 1.54}\n",
      "{'loss': 1.0557, 'grad_norm': 13.153484344482422, 'learning_rate': 4.850813743218807e-06, 'epoch': 1.55}\n",
      "{'loss': 1.0612, 'grad_norm': 17.994182586669922, 'learning_rate': 4.845790636929878e-06, 'epoch': 1.55}\n",
      "{'loss': 1.037, 'grad_norm': 21.884807586669922, 'learning_rate': 4.840767530640948e-06, 'epoch': 1.55}\n",
      "{'loss': 1.0212, 'grad_norm': 21.96607208251953, 'learning_rate': 4.83574442435202e-06, 'epoch': 1.55}\n",
      "{'loss': 0.9936, 'grad_norm': 43.42321014404297, 'learning_rate': 4.830721318063091e-06, 'epoch': 1.55}\n",
      "{'loss': 1.0118, 'grad_norm': 29.21330451965332, 'learning_rate': 4.825698211774162e-06, 'epoch': 1.55}\n",
      "{'loss': 1.0141, 'grad_norm': 20.231792449951172, 'learning_rate': 4.820675105485232e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0475, 'grad_norm': 25.78421974182129, 'learning_rate': 4.815651999196304e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0285, 'grad_norm': 25.362443923950195, 'learning_rate': 4.810628892907374e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0144, 'grad_norm': 26.192399978637695, 'learning_rate': 4.805605786618445e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0278, 'grad_norm': 8.497125625610352, 'learning_rate': 4.800582680329516e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0944, 'grad_norm': 30.46952247619629, 'learning_rate': 4.795559574040587e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0172, 'grad_norm': 19.489999771118164, 'learning_rate': 4.790536467751658e-06, 'epoch': 1.56}\n",
      "{'loss': 1.0437, 'grad_norm': 16.754894256591797, 'learning_rate': 4.785513361462729e-06, 'epoch': 1.57}\n",
      "{'loss': 1.0372, 'grad_norm': 18.143020629882812, 'learning_rate': 4.7804902551737994e-06, 'epoch': 1.57}\n",
      "{'loss': 1.0423, 'grad_norm': 25.759082794189453, 'learning_rate': 4.775467148884871e-06, 'epoch': 1.57}\n",
      "{'loss': 1.0983, 'grad_norm': 21.720455169677734, 'learning_rate': 4.770444042595942e-06, 'epoch': 1.57}\n",
      "{'loss': 1.0881, 'grad_norm': 7.748888969421387, 'learning_rate': 4.765420936307013e-06, 'epoch': 1.57}\n",
      "{'loss': 0.9954, 'grad_norm': 8.821651458740234, 'learning_rate': 4.7603978300180835e-06, 'epoch': 1.57}\n",
      "{'loss': 1.0943, 'grad_norm': 22.28389549255371, 'learning_rate': 4.755374723729155e-06, 'epoch': 1.57}\n",
      "{'loss': 1.0808, 'grad_norm': 37.903594970703125, 'learning_rate': 4.7503516174402255e-06, 'epoch': 1.58}\n",
      "{'loss': 1.0624, 'grad_norm': 5.500425338745117, 'learning_rate': 4.745328511151296e-06, 'epoch': 1.58}\n",
      "{'loss': 0.9983, 'grad_norm': 18.741180419921875, 'learning_rate': 4.740305404862367e-06, 'epoch': 1.58}\n",
      "{'loss': 1.1064, 'grad_norm': 31.315683364868164, 'learning_rate': 4.735282298573438e-06, 'epoch': 1.58}\n",
      "{'loss': 1.1182, 'grad_norm': 10.389132499694824, 'learning_rate': 4.7302591922845095e-06, 'epoch': 1.58}\n",
      "{'loss': 1.044, 'grad_norm': 27.849292755126953, 'learning_rate': 4.72523608599558e-06, 'epoch': 1.58}\n",
      "{'loss': 0.9904, 'grad_norm': 8.530938148498535, 'learning_rate': 4.720212979706651e-06, 'epoch': 1.59}\n",
      "{'loss': 1.0915, 'grad_norm': 21.040241241455078, 'learning_rate': 4.715189873417722e-06, 'epoch': 1.59}\n",
      "{'loss': 1.1197, 'grad_norm': 5.854125022888184, 'learning_rate': 4.710166767128793e-06, 'epoch': 1.59}\n",
      "{'loss': 0.9921, 'grad_norm': 18.069744110107422, 'learning_rate': 4.705143660839864e-06, 'epoch': 1.59}\n",
      "{'loss': 1.0758, 'grad_norm': 30.478681564331055, 'learning_rate': 4.700120554550935e-06, 'epoch': 1.59}\n",
      "{'loss': 1.0287, 'grad_norm': 29.302478790283203, 'learning_rate': 4.695097448262005e-06, 'epoch': 1.59}\n",
      "{'loss': 1.0664, 'grad_norm': 7.832529544830322, 'learning_rate': 4.690074341973077e-06, 'epoch': 1.59}\n",
      "{'loss': 1.0227, 'grad_norm': 15.872961044311523, 'learning_rate': 4.685051235684147e-06, 'epoch': 1.6}\n",
      "{'loss': 1.0096, 'grad_norm': 34.051231384277344, 'learning_rate': 4.680028129395218e-06, 'epoch': 1.6}\n",
      "{'loss': 1.0161, 'grad_norm': 24.16088104248047, 'learning_rate': 4.675005023106289e-06, 'epoch': 1.6}\n",
      "{'loss': 1.1065, 'grad_norm': 19.125844955444336, 'learning_rate': 4.669981916817361e-06, 'epoch': 1.6}\n",
      "{'loss': 1.0503, 'grad_norm': 16.62343978881836, 'learning_rate': 4.664958810528431e-06, 'epoch': 1.6}\n",
      "{'loss': 1.0006, 'grad_norm': 11.552559852600098, 'learning_rate': 4.659935704239502e-06, 'epoch': 1.6}\n",
      "{'loss': 1.1061, 'grad_norm': 23.6857967376709, 'learning_rate': 4.654912597950573e-06, 'epoch': 1.6}\n",
      "{'loss': 0.9626, 'grad_norm': 7.217194557189941, 'learning_rate': 4.649889491661644e-06, 'epoch': 1.61}\n",
      "{'loss': 1.1059, 'grad_norm': 29.102882385253906, 'learning_rate': 4.6448663853727145e-06, 'epoch': 1.61}\n",
      "{'loss': 1.0944, 'grad_norm': 34.06947326660156, 'learning_rate': 4.639843279083786e-06, 'epoch': 1.61}\n",
      "{'loss': 1.0514, 'grad_norm': 18.019786834716797, 'learning_rate': 4.6348201727948565e-06, 'epoch': 1.61}\n",
      "{'loss': 1.0706, 'grad_norm': 6.502218723297119, 'learning_rate': 4.629797066505928e-06, 'epoch': 1.61}\n",
      "{'loss': 1.0159, 'grad_norm': 19.8540096282959, 'learning_rate': 4.6247739602169986e-06, 'epoch': 1.61}\n",
      "{'loss': 1.0732, 'grad_norm': 36.15620422363281, 'learning_rate': 4.619750853928069e-06, 'epoch': 1.62}\n",
      "{'loss': 1.0491, 'grad_norm': 35.87175750732422, 'learning_rate': 4.614727747639141e-06, 'epoch': 1.62}\n",
      "{'loss': 1.0467, 'grad_norm': 4.669524669647217, 'learning_rate': 4.609704641350211e-06, 'epoch': 1.62}\n",
      "{'loss': 1.0305, 'grad_norm': 22.190715789794922, 'learning_rate': 4.604681535061283e-06, 'epoch': 1.62}\n",
      "{'loss': 1.1319, 'grad_norm': 17.756004333496094, 'learning_rate': 4.599658428772353e-06, 'epoch': 1.62}\n",
      "{'loss': 1.0271, 'grad_norm': 9.315512657165527, 'learning_rate': 4.594635322483424e-06, 'epoch': 1.62}\n",
      "{'loss': 0.9969, 'grad_norm': 41.039588928222656, 'learning_rate': 4.589612216194495e-06, 'epoch': 1.62}\n",
      "{'loss': 1.0632, 'grad_norm': 17.78642463684082, 'learning_rate': 4.584589109905566e-06, 'epoch': 1.63}\n",
      "{'loss': 1.1164, 'grad_norm': 18.135623931884766, 'learning_rate': 4.579566003616636e-06, 'epoch': 1.63}\n",
      "{'loss': 1.0437, 'grad_norm': 21.30677032470703, 'learning_rate': 4.574542897327708e-06, 'epoch': 1.63}\n",
      "{'loss': 1.0934, 'grad_norm': 25.002853393554688, 'learning_rate': 4.569519791038779e-06, 'epoch': 1.63}\n",
      "{'loss': 1.0519, 'grad_norm': 6.101741313934326, 'learning_rate': 4.56449668474985e-06, 'epoch': 1.63}\n",
      "{'loss': 1.0233, 'grad_norm': 20.438562393188477, 'learning_rate': 4.55947357846092e-06, 'epoch': 1.63}\n",
      "{'loss': 1.1044, 'grad_norm': 8.051410675048828, 'learning_rate': 4.554450472171992e-06, 'epoch': 1.64}\n",
      "{'loss': 1.0692, 'grad_norm': 21.445207595825195, 'learning_rate': 4.549427365883062e-06, 'epoch': 1.64}\n",
      "{'loss': 1.0295, 'grad_norm': 25.63932228088379, 'learning_rate': 4.544404259594134e-06, 'epoch': 1.64}\n",
      "{'loss': 1.0224, 'grad_norm': 17.34590721130371, 'learning_rate': 4.5393811533052044e-06, 'epoch': 1.64}\n",
      "{'loss': 1.031, 'grad_norm': 25.025814056396484, 'learning_rate': 4.534358047016275e-06, 'epoch': 1.64}\n",
      "{'loss': 1.1479, 'grad_norm': 4.687157154083252, 'learning_rate': 4.5293349407273464e-06, 'epoch': 1.64}\n",
      "{'loss': 1.0773, 'grad_norm': 37.405765533447266, 'learning_rate': 4.524311834438417e-06, 'epoch': 1.64}\n",
      "{'loss': 1.0818, 'grad_norm': 26.69037628173828, 'learning_rate': 4.519288728149488e-06, 'epoch': 1.65}\n",
      "{'loss': 1.0121, 'grad_norm': 19.814571380615234, 'learning_rate': 4.514265621860559e-06, 'epoch': 1.65}\n",
      "{'loss': 1.0547, 'grad_norm': 18.453960418701172, 'learning_rate': 4.50924251557163e-06, 'epoch': 1.65}\n",
      "{'loss': 1.1423, 'grad_norm': 25.692142486572266, 'learning_rate': 4.504219409282701e-06, 'epoch': 1.65}\n",
      "{'loss': 1.0435, 'grad_norm': 23.96550750732422, 'learning_rate': 4.499196302993772e-06, 'epoch': 1.65}\n",
      "{'loss': 1.046, 'grad_norm': 25.345924377441406, 'learning_rate': 4.494173196704842e-06, 'epoch': 1.65}\n",
      "{'loss': 1.0913, 'grad_norm': 16.290925979614258, 'learning_rate': 4.489150090415914e-06, 'epoch': 1.65}\n",
      "{'loss': 0.993, 'grad_norm': 7.3896613121032715, 'learning_rate': 4.484126984126984e-06, 'epoch': 1.66}\n",
      "{'loss': 1.0562, 'grad_norm': 8.16319751739502, 'learning_rate': 4.479103877838055e-06, 'epoch': 1.66}\n",
      "{'loss': 1.0977, 'grad_norm': 33.46919631958008, 'learning_rate': 4.474080771549126e-06, 'epoch': 1.66}\n",
      "{'loss': 1.09, 'grad_norm': 16.725330352783203, 'learning_rate': 4.46955997588909e-06, 'epoch': 1.66}\n",
      "{'loss': 1.0192, 'grad_norm': 6.251108169555664, 'learning_rate': 4.464536869600161e-06, 'epoch': 1.66}\n",
      "{'loss': 0.993, 'grad_norm': 18.974498748779297, 'learning_rate': 4.4595137633112315e-06, 'epoch': 1.66}\n",
      "{'loss': 1.0811, 'grad_norm': 20.80388832092285, 'learning_rate': 4.454490657022303e-06, 'epoch': 1.67}\n",
      "{'loss': 1.0902, 'grad_norm': 41.17837142944336, 'learning_rate': 4.449467550733374e-06, 'epoch': 1.67}\n",
      "{'loss': 1.1146, 'grad_norm': 33.330074310302734, 'learning_rate': 4.444444444444444e-06, 'epoch': 1.67}\n",
      "{'loss': 1.0052, 'grad_norm': 6.053566932678223, 'learning_rate': 4.439421338155516e-06, 'epoch': 1.67}\n",
      "{'loss': 1.0188, 'grad_norm': 42.41409683227539, 'learning_rate': 4.434398231866587e-06, 'epoch': 1.67}\n",
      "{'loss': 1.0779, 'grad_norm': 9.230944633483887, 'learning_rate': 4.429375125577658e-06, 'epoch': 1.67}\n",
      "{'loss': 1.0615, 'grad_norm': 9.045004844665527, 'learning_rate': 4.424352019288728e-06, 'epoch': 1.67}\n",
      "{'loss': 1.045, 'grad_norm': 28.02617835998535, 'learning_rate': 4.4193289129998e-06, 'epoch': 1.68}\n",
      "{'loss': 1.0569, 'grad_norm': 32.28337478637695, 'learning_rate': 4.41430580671087e-06, 'epoch': 1.68}\n",
      "{'loss': 1.1568, 'grad_norm': 16.063291549682617, 'learning_rate': 4.409282700421942e-06, 'epoch': 1.68}\n",
      "{'loss': 1.0694, 'grad_norm': 24.499805450439453, 'learning_rate': 4.404259594133012e-06, 'epoch': 1.68}\n",
      "{'loss': 1.0133, 'grad_norm': 44.387752532958984, 'learning_rate': 4.399236487844083e-06, 'epoch': 1.68}\n",
      "{'loss': 1.1225, 'grad_norm': 20.401611328125, 'learning_rate': 4.394213381555154e-06, 'epoch': 1.68}\n",
      "{'loss': 1.0499, 'grad_norm': 22.710634231567383, 'learning_rate': 4.389190275266225e-06, 'epoch': 1.68}\n",
      "{'loss': 0.9897, 'grad_norm': 20.24970245361328, 'learning_rate': 4.384167168977295e-06, 'epoch': 1.69}\n",
      "{'loss': 1.0341, 'grad_norm': 15.836944580078125, 'learning_rate': 4.379144062688367e-06, 'epoch': 1.69}\n",
      "{'loss': 1.1243, 'grad_norm': 26.762306213378906, 'learning_rate': 4.374120956399438e-06, 'epoch': 1.69}\n",
      "{'loss': 1.09, 'grad_norm': 23.310226440429688, 'learning_rate': 4.369097850110509e-06, 'epoch': 1.69}\n",
      "{'loss': 1.0983, 'grad_norm': 15.970901489257812, 'learning_rate': 4.3640747438215794e-06, 'epoch': 1.69}\n",
      "{'loss': 1.0789, 'grad_norm': 28.70100975036621, 'learning_rate': 4.359051637532651e-06, 'epoch': 1.69}\n",
      "{'loss': 1.1292, 'grad_norm': 19.124696731567383, 'learning_rate': 4.3540285312437214e-06, 'epoch': 1.7}\n",
      "{'loss': 1.04, 'grad_norm': 18.20471954345703, 'learning_rate': 4.349005424954793e-06, 'epoch': 1.7}\n",
      "{'loss': 1.06, 'grad_norm': 8.823535919189453, 'learning_rate': 4.3439823186658635e-06, 'epoch': 1.7}\n",
      "{'loss': 1.0335, 'grad_norm': 14.818130493164062, 'learning_rate': 4.338959212376934e-06, 'epoch': 1.7}\n",
      "{'loss': 1.0418, 'grad_norm': 10.49352741241455, 'learning_rate': 4.3339361060880055e-06, 'epoch': 1.7}\n",
      "{'loss': 1.0809, 'grad_norm': 29.6165828704834, 'learning_rate': 4.328912999799076e-06, 'epoch': 1.7}\n",
      "{'loss': 1.0972, 'grad_norm': 33.09550857543945, 'learning_rate': 4.323889893510147e-06, 'epoch': 1.7}\n",
      "{'loss': 1.071, 'grad_norm': 29.757644653320312, 'learning_rate': 4.318866787221218e-06, 'epoch': 1.71}\n",
      "{'loss': 0.9774, 'grad_norm': 18.549562454223633, 'learning_rate': 4.313843680932289e-06, 'epoch': 1.71}\n",
      "{'loss': 1.056, 'grad_norm': 15.627469062805176, 'learning_rate': 4.30882057464336e-06, 'epoch': 1.71}\n",
      "{'loss': 1.1284, 'grad_norm': 38.65363693237305, 'learning_rate': 4.303797468354431e-06, 'epoch': 1.71}\n",
      "{'loss': 0.9707, 'grad_norm': 29.176191329956055, 'learning_rate': 4.298774362065501e-06, 'epoch': 1.71}\n",
      "{'loss': 1.0473, 'grad_norm': 23.125272750854492, 'learning_rate': 4.293751255776573e-06, 'epoch': 1.71}\n",
      "{'loss': 1.0368, 'grad_norm': 21.286413192749023, 'learning_rate': 4.288728149487644e-06, 'epoch': 1.71}\n",
      "{'loss': 1.0345, 'grad_norm': 7.7064642906188965, 'learning_rate': 4.283705043198714e-06, 'epoch': 1.72}\n",
      "{'loss': 1.1169, 'grad_norm': 17.641782760620117, 'learning_rate': 4.278681936909785e-06, 'epoch': 1.72}\n",
      "{'loss': 1.0626, 'grad_norm': 32.34742736816406, 'learning_rate': 4.273658830620857e-06, 'epoch': 1.72}\n",
      "{'loss': 1.0279, 'grad_norm': 18.304555892944336, 'learning_rate': 4.268635724331927e-06, 'epoch': 1.72}\n",
      "{'loss': 1.0172, 'grad_norm': 22.61194610595703, 'learning_rate': 4.263612618042998e-06, 'epoch': 1.72}\n",
      "{'loss': 1.1495, 'grad_norm': 18.857810974121094, 'learning_rate': 4.258589511754069e-06, 'epoch': 1.72}\n",
      "{'loss': 0.9968, 'grad_norm': 43.19444274902344, 'learning_rate': 4.25356640546514e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0751, 'grad_norm': 30.313825607299805, 'learning_rate': 4.248543299176211e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0294, 'grad_norm': 25.66057777404785, 'learning_rate': 4.243520192887282e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0945, 'grad_norm': 33.2005615234375, 'learning_rate': 4.2384970865983525e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0551, 'grad_norm': 7.126201152801514, 'learning_rate': 4.233473980309424e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0433, 'grad_norm': 7.061488628387451, 'learning_rate': 4.2284508740204945e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0344, 'grad_norm': 27.5867862701416, 'learning_rate': 4.223427767731565e-06, 'epoch': 1.73}\n",
      "{'loss': 1.0826, 'grad_norm': 13.537322044372559, 'learning_rate': 4.2184046614426365e-06, 'epoch': 1.74}\n",
      "{'loss': 1.0514, 'grad_norm': 14.653817176818848, 'learning_rate': 4.213381555153707e-06, 'epoch': 1.74}\n",
      "{'loss': 1.0239, 'grad_norm': 40.0058708190918, 'learning_rate': 4.2083584488647786e-06, 'epoch': 1.74}\n",
      "{'loss': 1.0793, 'grad_norm': 38.65816879272461, 'learning_rate': 4.203335342575849e-06, 'epoch': 1.74}\n",
      "{'loss': 1.1434, 'grad_norm': 16.10201072692871, 'learning_rate': 4.19831223628692e-06, 'epoch': 1.74}\n",
      "{'loss': 1.0938, 'grad_norm': 9.128857612609863, 'learning_rate': 4.193289129997991e-06, 'epoch': 1.74}\n",
      "{'loss': 1.0284, 'grad_norm': 15.663607597351074, 'learning_rate': 4.188266023709063e-06, 'epoch': 1.75}\n",
      "{'loss': 1.0652, 'grad_norm': 17.817941665649414, 'learning_rate': 4.183242917420133e-06, 'epoch': 1.75}\n",
      "{'loss': 1.0458, 'grad_norm': 9.530441284179688, 'learning_rate': 4.178219811131204e-06, 'epoch': 1.75}\n",
      "{'loss': 0.9853, 'grad_norm': 23.480897903442383, 'learning_rate': 4.173196704842275e-06, 'epoch': 1.75}\n",
      "{'loss': 1.0468, 'grad_norm': 23.019906997680664, 'learning_rate': 4.168173598553346e-06, 'epoch': 1.75}\n",
      "{'loss': 1.03, 'grad_norm': 16.742141723632812, 'learning_rate': 4.163150492264416e-06, 'epoch': 1.75}\n",
      "{'loss': 1.1202, 'grad_norm': 13.003677368164062, 'learning_rate': 4.158127385975488e-06, 'epoch': 1.75}\n",
      "{'loss': 1.0631, 'grad_norm': 34.00270462036133, 'learning_rate': 4.153104279686558e-06, 'epoch': 1.76}\n",
      "{'loss': 1.022, 'grad_norm': 7.056775093078613, 'learning_rate': 4.14808117339763e-06, 'epoch': 1.76}\n",
      "{'loss': 1.0713, 'grad_norm': 27.60353660583496, 'learning_rate': 4.1430580671087e-06, 'epoch': 1.76}\n",
      "{'loss': 1.0016, 'grad_norm': 20.69703483581543, 'learning_rate': 4.138034960819771e-06, 'epoch': 1.76}\n",
      "{'loss': 1.0546, 'grad_norm': 51.979915618896484, 'learning_rate': 4.133011854530842e-06, 'epoch': 1.76}\n",
      "{'loss': 1.0156, 'grad_norm': 7.938925266265869, 'learning_rate': 4.127988748241913e-06, 'epoch': 1.76}\n",
      "{'loss': 1.0192, 'grad_norm': 20.49100685119629, 'learning_rate': 4.122965641952984e-06, 'epoch': 1.76}\n",
      "{'loss': 1.0115, 'grad_norm': 15.271355628967285, 'learning_rate': 4.117942535664055e-06, 'epoch': 1.77}\n",
      "{'loss': 1.051, 'grad_norm': 40.501007080078125, 'learning_rate': 4.112919429375126e-06, 'epoch': 1.77}\n",
      "{'loss': 1.1065, 'grad_norm': 34.371829986572266, 'learning_rate': 4.107896323086197e-06, 'epoch': 1.77}\n",
      "{'loss': 1.1229, 'grad_norm': 25.210674285888672, 'learning_rate': 4.102873216797268e-06, 'epoch': 1.77}\n",
      "{'loss': 1.02, 'grad_norm': 6.691837310791016, 'learning_rate': 4.097850110508338e-06, 'epoch': 1.77}\n",
      "{'loss': 1.1133, 'grad_norm': 21.8546199798584, 'learning_rate': 4.09282700421941e-06, 'epoch': 1.77}\n",
      "{'loss': 1.0814, 'grad_norm': 24.338117599487305, 'learning_rate': 4.087803897930481e-06, 'epoch': 1.78}\n",
      "{'loss': 1.0533, 'grad_norm': 29.934656143188477, 'learning_rate': 4.082780791641552e-06, 'epoch': 1.78}\n",
      "{'loss': 1.0583, 'grad_norm': 32.99212646484375, 'learning_rate': 4.077757685352622e-06, 'epoch': 1.78}\n",
      "{'loss': 1.0693, 'grad_norm': 18.15148162841797, 'learning_rate': 4.072734579063694e-06, 'epoch': 1.78}\n",
      "{'loss': 1.0139, 'grad_norm': 32.57255554199219, 'learning_rate': 4.067711472774764e-06, 'epoch': 1.78}\n",
      "{'loss': 0.9788, 'grad_norm': 18.722753524780273, 'learning_rate': 4.062688366485835e-06, 'epoch': 1.78}\n",
      "{'loss': 1.0565, 'grad_norm': 6.448488235473633, 'learning_rate': 4.057665260196906e-06, 'epoch': 1.78}\n",
      "{'loss': 1.0264, 'grad_norm': 39.825775146484375, 'learning_rate': 4.052642153907977e-06, 'epoch': 1.79}\n",
      "{'loss': 1.0601, 'grad_norm': 14.566261291503906, 'learning_rate': 4.047619047619048e-06, 'epoch': 1.79}\n",
      "{'loss': 1.1506, 'grad_norm': 16.857534408569336, 'learning_rate': 4.042595941330119e-06, 'epoch': 1.79}\n",
      "{'loss': 0.9965, 'grad_norm': 23.181428909301758, 'learning_rate': 4.0375728350411894e-06, 'epoch': 1.79}\n",
      "{'loss': 1.0697, 'grad_norm': 6.577893257141113, 'learning_rate': 4.032549728752261e-06, 'epoch': 1.79}\n",
      "{'loss': 1.0845, 'grad_norm': 17.50031089782715, 'learning_rate': 4.027526622463332e-06, 'epoch': 1.79}\n",
      "{'loss': 1.0569, 'grad_norm': 19.602088928222656, 'learning_rate': 4.022503516174403e-06, 'epoch': 1.79}\n",
      "{'loss': 1.1083, 'grad_norm': 34.39719009399414, 'learning_rate': 4.0174804098854735e-06, 'epoch': 1.8}\n",
      "{'loss': 1.0156, 'grad_norm': 19.860244750976562, 'learning_rate': 4.012457303596544e-06, 'epoch': 1.8}\n",
      "{'loss': 1.0382, 'grad_norm': 17.200298309326172, 'learning_rate': 4.0074341973076155e-06, 'epoch': 1.8}\n",
      "{'loss': 1.058, 'grad_norm': 30.218994140625, 'learning_rate': 4.002411091018686e-06, 'epoch': 1.8}\n",
      "{'loss': 0.999, 'grad_norm': 16.293540954589844, 'learning_rate': 3.997387984729757e-06, 'epoch': 1.8}\n",
      "{'loss': 1.1006, 'grad_norm': 19.99662208557129, 'learning_rate': 3.992364878440828e-06, 'epoch': 1.8}\n",
      "{'loss': 1.0133, 'grad_norm': 16.747407913208008, 'learning_rate': 3.9873417721518995e-06, 'epoch': 1.81}\n",
      "{'loss': 1.092, 'grad_norm': 7.372130870819092, 'learning_rate': 3.98231866586297e-06, 'epoch': 1.81}\n",
      "{'loss': 1.0039, 'grad_norm': 50.68888473510742, 'learning_rate': 3.977295559574041e-06, 'epoch': 1.81}\n",
      "{'loss': 1.0246, 'grad_norm': 26.58576011657715, 'learning_rate': 3.972272453285112e-06, 'epoch': 1.81}\n",
      "{'loss': 1.0582, 'grad_norm': 38.4345817565918, 'learning_rate': 3.967249346996183e-06, 'epoch': 1.81}\n",
      "{'loss': 1.0839, 'grad_norm': 27.93115234375, 'learning_rate': 3.962226240707253e-06, 'epoch': 1.81}\n",
      "{'loss': 1.0293, 'grad_norm': 38.70587921142578, 'learning_rate': 3.957203134418325e-06, 'epoch': 1.81}\n",
      "{'loss': 1.0868, 'grad_norm': 16.917274475097656, 'learning_rate': 3.952180028129395e-06, 'epoch': 1.82}\n",
      "{'loss': 1.021, 'grad_norm': 37.83464813232422, 'learning_rate': 3.947156921840467e-06, 'epoch': 1.82}\n",
      "{'loss': 1.0464, 'grad_norm': 39.245849609375, 'learning_rate': 3.942133815551537e-06, 'epoch': 1.82}\n",
      "{'loss': 1.0503, 'grad_norm': 26.893287658691406, 'learning_rate': 3.937110709262608e-06, 'epoch': 1.82}\n",
      "{'loss': 1.0088, 'grad_norm': 22.35740852355957, 'learning_rate': 3.932087602973679e-06, 'epoch': 1.82}\n",
      "{'loss': 1.0274, 'grad_norm': 20.646589279174805, 'learning_rate': 3.927064496684751e-06, 'epoch': 1.82}\n",
      "{'loss': 1.0663, 'grad_norm': 17.235044479370117, 'learning_rate': 3.922041390395821e-06, 'epoch': 1.82}\n",
      "{'loss': 0.9898, 'grad_norm': 17.402393341064453, 'learning_rate': 3.917018284106892e-06, 'epoch': 1.83}\n",
      "{'loss': 1.0245, 'grad_norm': 40.59597396850586, 'learning_rate': 3.9119951778179625e-06, 'epoch': 1.83}\n",
      "{'loss': 1.0319, 'grad_norm': 21.518428802490234, 'learning_rate': 3.906972071529034e-06, 'epoch': 1.83}\n",
      "{'loss': 1.0319, 'grad_norm': 7.444129467010498, 'learning_rate': 3.9019489652401045e-06, 'epoch': 1.83}\n",
      "{'loss': 1.078, 'grad_norm': 18.475662231445312, 'learning_rate': 3.896925858951175e-06, 'epoch': 1.83}\n",
      "{'loss': 1.0652, 'grad_norm': 18.403072357177734, 'learning_rate': 3.8919027526622466e-06, 'epoch': 1.83}\n",
      "{'loss': 1.0398, 'grad_norm': 8.674921989440918, 'learning_rate': 3.886879646373318e-06, 'epoch': 1.84}\n",
      "{'loss': 1.0293, 'grad_norm': 23.67412757873535, 'learning_rate': 3.8818565400843886e-06, 'epoch': 1.84}\n",
      "{'loss': 1.0483, 'grad_norm': 26.596498489379883, 'learning_rate': 3.876833433795459e-06, 'epoch': 1.84}\n",
      "{'loss': 1.0222, 'grad_norm': 29.86682891845703, 'learning_rate': 3.871810327506531e-06, 'epoch': 1.84}\n",
      "{'loss': 0.9959, 'grad_norm': 24.959774017333984, 'learning_rate': 3.866787221217601e-06, 'epoch': 1.84}\n",
      "{'loss': 1.0549, 'grad_norm': 18.31269073486328, 'learning_rate': 3.861764114928673e-06, 'epoch': 1.84}\n",
      "{'loss': 1.0677, 'grad_norm': 23.945606231689453, 'learning_rate': 3.856741008639743e-06, 'epoch': 1.84}\n",
      "{'loss': 1.0332, 'grad_norm': 17.238040924072266, 'learning_rate': 3.851717902350814e-06, 'epoch': 1.85}\n",
      "{'loss': 1.0548, 'grad_norm': 17.371583938598633, 'learning_rate': 3.846694796061885e-06, 'epoch': 1.85}\n",
      "{'loss': 1.0004, 'grad_norm': 19.56285285949707, 'learning_rate': 3.841671689772956e-06, 'epoch': 1.85}\n",
      "{'loss': 0.9899, 'grad_norm': 26.653717041015625, 'learning_rate': 3.836648583484026e-06, 'epoch': 1.85}\n",
      "{'loss': 1.1117, 'grad_norm': 40.177574157714844, 'learning_rate': 3.831625477195098e-06, 'epoch': 1.85}\n",
      "{'loss': 1.0327, 'grad_norm': 18.892656326293945, 'learning_rate': 3.826602370906169e-06, 'epoch': 1.85}\n",
      "{'loss': 1.0019, 'grad_norm': 19.80651092529297, 'learning_rate': 3.82157926461724e-06, 'epoch': 1.86}\n",
      "{'loss': 1.1458, 'grad_norm': 27.87141227722168, 'learning_rate': 3.81655615832831e-06, 'epoch': 1.86}\n",
      "{'loss': 1.0453, 'grad_norm': 18.852197647094727, 'learning_rate': 3.811533052039382e-06, 'epoch': 1.86}\n",
      "{'loss': 1.1041, 'grad_norm': 31.405399322509766, 'learning_rate': 3.8065099457504524e-06, 'epoch': 1.86}\n",
      "{'loss': 1.1573, 'grad_norm': 26.417356491088867, 'learning_rate': 3.8014868394615234e-06, 'epoch': 1.86}\n",
      "{'loss': 1.0415, 'grad_norm': 17.117881774902344, 'learning_rate': 3.796463733172594e-06, 'epoch': 1.86}\n",
      "{'loss': 1.122, 'grad_norm': 46.26213455200195, 'learning_rate': 3.791440626883665e-06, 'epoch': 1.86}\n",
      "{'loss': 1.0838, 'grad_norm': 33.51094055175781, 'learning_rate': 3.786417520594736e-06, 'epoch': 1.87}\n",
      "{'loss': 1.0417, 'grad_norm': 25.539487838745117, 'learning_rate': 3.7813944143058066e-06, 'epoch': 1.87}\n",
      "{'loss': 1.0535, 'grad_norm': 44.183372497558594, 'learning_rate': 3.776371308016878e-06, 'epoch': 1.87}\n",
      "{'loss': 0.9836, 'grad_norm': 20.637897491455078, 'learning_rate': 3.771348201727949e-06, 'epoch': 1.87}\n",
      "{'loss': 1.0852, 'grad_norm': 18.406278610229492, 'learning_rate': 3.7663250954390196e-06, 'epoch': 1.87}\n",
      "{'loss': 1.0427, 'grad_norm': 7.932685375213623, 'learning_rate': 3.7613019891500906e-06, 'epoch': 1.87}\n",
      "{'loss': 1.0341, 'grad_norm': 28.590557098388672, 'learning_rate': 3.7562788828611617e-06, 'epoch': 1.87}\n",
      "{'loss': 1.0367, 'grad_norm': 36.246429443359375, 'learning_rate': 3.7512557765722322e-06, 'epoch': 1.88}\n",
      "{'loss': 1.0694, 'grad_norm': 21.038331985473633, 'learning_rate': 3.7462326702833037e-06, 'epoch': 1.88}\n",
      "{'loss': 1.122, 'grad_norm': 30.34848403930664, 'learning_rate': 3.7412095639943747e-06, 'epoch': 1.88}\n",
      "{'loss': 1.0505, 'grad_norm': 21.172588348388672, 'learning_rate': 3.7361864577054453e-06, 'epoch': 1.88}\n",
      "{'loss': 1.0725, 'grad_norm': 22.40717124938965, 'learning_rate': 3.7311633514165163e-06, 'epoch': 1.88}\n",
      "{'loss': 0.9994, 'grad_norm': 19.9255428314209, 'learning_rate': 3.7261402451275873e-06, 'epoch': 1.88}\n",
      "{'loss': 1.0492, 'grad_norm': 7.122097492218018, 'learning_rate': 3.721117138838658e-06, 'epoch': 1.89}\n",
      "{'loss': 1.0613, 'grad_norm': 20.369220733642578, 'learning_rate': 3.7160940325497293e-06, 'epoch': 1.89}\n",
      "{'loss': 1.0389, 'grad_norm': 28.10103988647461, 'learning_rate': 3.7110709262608003e-06, 'epoch': 1.89}\n",
      "{'loss': 1.072, 'grad_norm': 27.390827178955078, 'learning_rate': 3.706047819971871e-06, 'epoch': 1.89}\n",
      "{'loss': 1.095, 'grad_norm': 4.777846813201904, 'learning_rate': 3.701024713682942e-06, 'epoch': 1.89}\n",
      "{'loss': 1.0463, 'grad_norm': 39.082908630371094, 'learning_rate': 3.696001607394013e-06, 'epoch': 1.89}\n",
      "{'loss': 0.9878, 'grad_norm': 19.167884826660156, 'learning_rate': 3.6909785011050835e-06, 'epoch': 1.89}\n",
      "{'loss': 1.0581, 'grad_norm': 32.88241195678711, 'learning_rate': 3.685955394816155e-06, 'epoch': 1.9}\n",
      "{'loss': 1.0425, 'grad_norm': 8.12844181060791, 'learning_rate': 3.680932288527225e-06, 'epoch': 1.9}\n",
      "{'loss': 1.092, 'grad_norm': 34.674903869628906, 'learning_rate': 3.6759091822382965e-06, 'epoch': 1.9}\n",
      "{'loss': 1.0715, 'grad_norm': 8.633092880249023, 'learning_rate': 3.6708860759493675e-06, 'epoch': 1.9}\n",
      "{'loss': 1.0666, 'grad_norm': 6.4004998207092285, 'learning_rate': 3.665862969660438e-06, 'epoch': 1.9}\n",
      "{'loss': 1.0297, 'grad_norm': 24.990522384643555, 'learning_rate': 3.660839863371509e-06, 'epoch': 1.9}\n",
      "{'loss': 1.0494, 'grad_norm': 21.26899528503418, 'learning_rate': 3.65581675708258e-06, 'epoch': 1.9}\n",
      "{'loss': 1.0288, 'grad_norm': 17.507801055908203, 'learning_rate': 3.6507936507936507e-06, 'epoch': 1.91}\n",
      "{'loss': 1.0197, 'grad_norm': 42.843387603759766, 'learning_rate': 3.645770544504722e-06, 'epoch': 1.91}\n",
      "{'loss': 1.0911, 'grad_norm': 40.045597076416016, 'learning_rate': 3.640747438215793e-06, 'epoch': 1.91}\n",
      "{'loss': 1.087, 'grad_norm': 39.54267501831055, 'learning_rate': 3.6357243319268637e-06, 'epoch': 1.91}\n",
      "{'loss': 0.9545, 'grad_norm': 33.33302688598633, 'learning_rate': 3.6307012256379347e-06, 'epoch': 1.91}\n",
      "{'loss': 1.0588, 'grad_norm': 27.176727294921875, 'learning_rate': 3.6256781193490057e-06, 'epoch': 1.91}\n",
      "{'loss': 0.9663, 'grad_norm': 28.816184997558594, 'learning_rate': 3.6206550130600763e-06, 'epoch': 1.92}\n",
      "{'loss': 0.9981, 'grad_norm': 6.531992435455322, 'learning_rate': 3.6156319067711478e-06, 'epoch': 1.92}\n",
      "{'loss': 1.0221, 'grad_norm': 23.471769332885742, 'learning_rate': 3.6106088004822188e-06, 'epoch': 1.92}\n",
      "{'loss': 0.972, 'grad_norm': 26.65683937072754, 'learning_rate': 3.6055856941932894e-06, 'epoch': 1.92}\n",
      "{'loss': 1.1472, 'grad_norm': 18.229650497436523, 'learning_rate': 3.6005625879043604e-06, 'epoch': 1.92}\n",
      "{'loss': 1.1035, 'grad_norm': 18.04300880432129, 'learning_rate': 3.5955394816154314e-06, 'epoch': 1.92}\n",
      "{'loss': 1.0452, 'grad_norm': 34.42076110839844, 'learning_rate': 3.590516375326502e-06, 'epoch': 1.92}\n",
      "{'loss': 1.0703, 'grad_norm': 27.902912139892578, 'learning_rate': 3.5854932690375734e-06, 'epoch': 1.93}\n",
      "{'loss': 1.0638, 'grad_norm': 6.107842922210693, 'learning_rate': 3.580470162748644e-06, 'epoch': 1.93}\n",
      "{'loss': 1.0055, 'grad_norm': 18.078014373779297, 'learning_rate': 3.575447056459715e-06, 'epoch': 1.93}\n",
      "{'loss': 1.0501, 'grad_norm': 19.09136390686035, 'learning_rate': 3.570423950170786e-06, 'epoch': 1.93}\n",
      "{'loss': 1.0423, 'grad_norm': 7.86173677444458, 'learning_rate': 3.5654008438818566e-06, 'epoch': 1.93}\n",
      "{'loss': 1.0509, 'grad_norm': 25.66550636291504, 'learning_rate': 3.5603777375929276e-06, 'epoch': 1.93}\n",
      "{'loss': 1.054, 'grad_norm': 19.11385154724121, 'learning_rate': 3.555354631303999e-06, 'epoch': 1.93}\n",
      "{'loss': 1.0114, 'grad_norm': 24.446636199951172, 'learning_rate': 3.5503315250150696e-06, 'epoch': 1.94}\n",
      "{'loss': 1.1031, 'grad_norm': 40.18471145629883, 'learning_rate': 3.5453084187261406e-06, 'epoch': 1.94}\n",
      "{'loss': 1.0947, 'grad_norm': 22.306320190429688, 'learning_rate': 3.5402853124372116e-06, 'epoch': 1.94}\n",
      "{'loss': 0.9867, 'grad_norm': 21.526294708251953, 'learning_rate': 3.535262206148282e-06, 'epoch': 1.94}\n",
      "{'loss': 1.0663, 'grad_norm': 41.02607727050781, 'learning_rate': 3.530239099859353e-06, 'epoch': 1.94}\n",
      "{'loss': 1.0337, 'grad_norm': 17.735843658447266, 'learning_rate': 3.5252159935704246e-06, 'epoch': 1.94}\n",
      "{'loss': 1.1073, 'grad_norm': 26.331233978271484, 'learning_rate': 3.520192887281495e-06, 'epoch': 1.95}\n",
      "{'loss': 1.0714, 'grad_norm': 17.528181076049805, 'learning_rate': 3.5151697809925662e-06, 'epoch': 1.95}\n",
      "{'loss': 0.9683, 'grad_norm': 41.76327133178711, 'learning_rate': 3.5101466747036372e-06, 'epoch': 1.95}\n",
      "{'loss': 0.9944, 'grad_norm': 26.38214874267578, 'learning_rate': 3.505123568414708e-06, 'epoch': 1.95}\n",
      "{'loss': 1.0485, 'grad_norm': 22.8593692779541, 'learning_rate': 3.500100462125779e-06, 'epoch': 1.95}\n",
      "{'loss': 1.0771, 'grad_norm': 42.054168701171875, 'learning_rate': 3.49507735583685e-06, 'epoch': 1.95}\n",
      "{'loss': 1.0231, 'grad_norm': 18.936498641967773, 'learning_rate': 3.4900542495479204e-06, 'epoch': 1.95}\n",
      "{'loss': 1.0506, 'grad_norm': 18.12116813659668, 'learning_rate': 3.485031143258992e-06, 'epoch': 1.96}\n",
      "{'loss': 1.0547, 'grad_norm': 16.88102149963379, 'learning_rate': 3.480008036970063e-06, 'epoch': 1.96}\n",
      "{'loss': 1.0755, 'grad_norm': 5.246124744415283, 'learning_rate': 3.4749849306811334e-06, 'epoch': 1.96}\n",
      "{'loss': 0.9654, 'grad_norm': 7.8033599853515625, 'learning_rate': 3.4699618243922044e-06, 'epoch': 1.96}\n",
      "{'loss': 0.9712, 'grad_norm': 34.021759033203125, 'learning_rate': 3.464938718103275e-06, 'epoch': 1.96}\n",
      "{'loss': 1.0302, 'grad_norm': 30.838623046875, 'learning_rate': 3.459915611814346e-06, 'epoch': 1.96}\n",
      "{'loss': 0.9829, 'grad_norm': 24.23141860961914, 'learning_rate': 3.4548925055254175e-06, 'epoch': 1.97}\n",
      "{'loss': 1.0468, 'grad_norm': 18.02598762512207, 'learning_rate': 3.449869399236488e-06, 'epoch': 1.97}\n",
      "{'loss': 1.1019, 'grad_norm': 19.961410522460938, 'learning_rate': 3.445348603576452e-06, 'epoch': 1.97}\n",
      "{'loss': 1.1028, 'grad_norm': 25.767414093017578, 'learning_rate': 3.4403254972875228e-06, 'epoch': 1.97}\n",
      "{'loss': 1.0525, 'grad_norm': 18.477338790893555, 'learning_rate': 3.4353023909985938e-06, 'epoch': 1.97}\n",
      "{'loss': 1.011, 'grad_norm': 25.66539764404297, 'learning_rate': 3.4302792847096648e-06, 'epoch': 1.97}\n",
      "{'loss': 1.0596, 'grad_norm': 26.321125030517578, 'learning_rate': 3.4252561784207354e-06, 'epoch': 1.97}\n",
      "{'loss': 1.0926, 'grad_norm': 42.078311920166016, 'learning_rate': 3.420233072131807e-06, 'epoch': 1.98}\n",
      "{'loss': 1.0522, 'grad_norm': 37.071083068847656, 'learning_rate': 3.415209965842878e-06, 'epoch': 1.98}\n",
      "{'loss': 1.0422, 'grad_norm': 44.56529998779297, 'learning_rate': 3.4101868595539484e-06, 'epoch': 1.98}\n",
      "{'loss': 1.057, 'grad_norm': 20.755821228027344, 'learning_rate': 3.4051637532650194e-06, 'epoch': 1.98}\n",
      "{'loss': 1.0775, 'grad_norm': 23.96490478515625, 'learning_rate': 3.40014064697609e-06, 'epoch': 1.98}\n",
      "{'loss': 1.0141, 'grad_norm': 5.869777202606201, 'learning_rate': 3.395117540687161e-06, 'epoch': 1.98}\n",
      "{'loss': 1.0985, 'grad_norm': 5.533105373382568, 'learning_rate': 3.3900944343982324e-06, 'epoch': 1.98}\n",
      "{'loss': 1.0687, 'grad_norm': 28.093799591064453, 'learning_rate': 3.385071328109303e-06, 'epoch': 1.99}\n",
      "{'loss': 1.1205, 'grad_norm': 34.50830841064453, 'learning_rate': 3.380048221820374e-06, 'epoch': 1.99}\n",
      "{'loss': 1.0276, 'grad_norm': 50.11745834350586, 'learning_rate': 3.375025115531445e-06, 'epoch': 1.99}\n",
      "{'loss': 1.0421, 'grad_norm': 19.011232376098633, 'learning_rate': 3.3700020092425156e-06, 'epoch': 1.99}\n",
      "{'loss': 1.0277, 'grad_norm': 21.103607177734375, 'learning_rate': 3.3649789029535866e-06, 'epoch': 1.99}\n",
      "{'loss': 1.0582, 'grad_norm': 5.2522735595703125, 'learning_rate': 3.359955796664658e-06, 'epoch': 1.99}\n",
      "{'loss': 1.0677, 'grad_norm': 21.641115188598633, 'learning_rate': 3.3549326903757286e-06, 'epoch': 2.0}\n",
      "{'loss': 1.1172, 'grad_norm': 24.60450553894043, 'learning_rate': 3.3499095840867996e-06, 'epoch': 2.0}\n",
      "{'loss': 1.0565, 'grad_norm': 19.005062103271484, 'learning_rate': 3.3448864777978706e-06, 'epoch': 2.0}\n",
      "{'loss': 1.0978, 'grad_norm': 20.828157424926758, 'learning_rate': 3.3398633715089412e-06, 'epoch': 2.0}\n",
      "{'loss': 1.113, 'grad_norm': 39.08491134643555, 'learning_rate': 3.3348402652200122e-06, 'epoch': 2.0}\n",
      "{'loss': 0.976, 'grad_norm': 21.700157165527344, 'learning_rate': 3.3298171589310837e-06, 'epoch': 2.0}\n",
      "{'loss': 1.0636, 'grad_norm': 11.333660125732422, 'learning_rate': 3.3247940526421542e-06, 'epoch': 2.0}\n",
      "{'loss': 1.0778, 'grad_norm': 19.263273239135742, 'learning_rate': 3.3197709463532253e-06, 'epoch': 2.01}\n",
      "{'loss': 0.9988, 'grad_norm': 16.808612823486328, 'learning_rate': 3.3147478400642963e-06, 'epoch': 2.01}\n",
      "{'loss': 1.1239, 'grad_norm': 28.950960159301758, 'learning_rate': 3.309724733775367e-06, 'epoch': 2.01}\n",
      "{'loss': 1.073, 'grad_norm': 17.866823196411133, 'learning_rate': 3.304701627486438e-06, 'epoch': 2.01}\n",
      "{'loss': 1.1111, 'grad_norm': 8.419529914855957, 'learning_rate': 3.2996785211975084e-06, 'epoch': 2.01}\n",
      "{'loss': 1.0775, 'grad_norm': 31.01176643371582, 'learning_rate': 3.2946554149085794e-06, 'epoch': 2.01}\n",
      "{'loss': 1.0024, 'grad_norm': 27.943695068359375, 'learning_rate': 3.289632308619651e-06, 'epoch': 2.01}\n",
      "{'loss': 1.0734, 'grad_norm': 21.440645217895508, 'learning_rate': 3.2846092023307215e-06, 'epoch': 2.02}\n",
      "{'loss': 1.0783, 'grad_norm': 8.498106002807617, 'learning_rate': 3.2795860960417925e-06, 'epoch': 2.02}\n",
      "{'loss': 1.0825, 'grad_norm': 36.14838409423828, 'learning_rate': 3.2745629897528635e-06, 'epoch': 2.02}\n",
      "{'loss': 1.1186, 'grad_norm': 9.526063919067383, 'learning_rate': 3.269539883463934e-06, 'epoch': 2.02}\n",
      "{'loss': 1.0532, 'grad_norm': 24.552391052246094, 'learning_rate': 3.264516777175005e-06, 'epoch': 2.02}\n",
      "{'loss': 1.0314, 'grad_norm': 26.427749633789062, 'learning_rate': 3.2594936708860765e-06, 'epoch': 2.02}\n",
      "{'loss': 1.0127, 'grad_norm': 17.58131217956543, 'learning_rate': 3.254470564597147e-06, 'epoch': 2.03}\n",
      "{'loss': 1.085, 'grad_norm': 16.36882972717285, 'learning_rate': 3.249447458308218e-06, 'epoch': 2.03}\n",
      "{'loss': 1.0575, 'grad_norm': 24.5743408203125, 'learning_rate': 3.244424352019289e-06, 'epoch': 2.03}\n",
      "{'loss': 1.0158, 'grad_norm': 8.726222038269043, 'learning_rate': 3.2394012457303597e-06, 'epoch': 2.03}\n",
      "{'loss': 1.0681, 'grad_norm': 32.80137634277344, 'learning_rate': 3.2343781394414307e-06, 'epoch': 2.03}\n",
      "{'loss': 1.0078, 'grad_norm': 6.568422794342041, 'learning_rate': 3.229355033152502e-06, 'epoch': 2.03}\n",
      "{'loss': 1.0302, 'grad_norm': 17.436628341674805, 'learning_rate': 3.2243319268635727e-06, 'epoch': 2.03}\n",
      "{'loss': 1.0698, 'grad_norm': 15.534242630004883, 'learning_rate': 3.2193088205746437e-06, 'epoch': 2.04}\n",
      "{'loss': 1.0137, 'grad_norm': 16.641284942626953, 'learning_rate': 3.2142857142857147e-06, 'epoch': 2.04}\n",
      "{'loss': 1.0918, 'grad_norm': 38.99853515625, 'learning_rate': 3.2092626079967853e-06, 'epoch': 2.04}\n",
      "{'loss': 1.0222, 'grad_norm': 34.6673469543457, 'learning_rate': 3.2042395017078563e-06, 'epoch': 2.04}\n",
      "{'loss': 1.0397, 'grad_norm': 21.24736976623535, 'learning_rate': 3.1992163954189278e-06, 'epoch': 2.04}\n",
      "{'loss': 0.9976, 'grad_norm': 37.52821350097656, 'learning_rate': 3.1941932891299983e-06, 'epoch': 2.04}\n",
      "{'loss': 1.0326, 'grad_norm': 17.109865188598633, 'learning_rate': 3.1891701828410693e-06, 'epoch': 2.04}\n",
      "{'loss': 1.0171, 'grad_norm': 25.817523956298828, 'learning_rate': 3.18414707655214e-06, 'epoch': 2.05}\n",
      "{'loss': 1.0734, 'grad_norm': 9.269380569458008, 'learning_rate': 3.179123970263211e-06, 'epoch': 2.05}\n",
      "{'loss': 1.0577, 'grad_norm': 16.030122756958008, 'learning_rate': 3.174100863974282e-06, 'epoch': 2.05}\n",
      "{'loss': 1.0112, 'grad_norm': 6.761674404144287, 'learning_rate': 3.1690777576853525e-06, 'epoch': 2.05}\n",
      "{'loss': 1.0246, 'grad_norm': 23.077735900878906, 'learning_rate': 3.164054651396424e-06, 'epoch': 2.05}\n",
      "{'loss': 0.9369, 'grad_norm': 6.1202712059021, 'learning_rate': 3.159031545107495e-06, 'epoch': 2.05}\n",
      "{'loss': 1.0242, 'grad_norm': 19.58685302734375, 'learning_rate': 3.1540084388185656e-06, 'epoch': 2.06}\n",
      "{'loss': 1.0903, 'grad_norm': 33.065879821777344, 'learning_rate': 3.1489853325296366e-06, 'epoch': 2.06}\n",
      "{'loss': 1.0423, 'grad_norm': 30.263256072998047, 'learning_rate': 3.1439622262407076e-06, 'epoch': 2.06}\n",
      "{'loss': 1.0861, 'grad_norm': 22.464929580688477, 'learning_rate': 3.138939119951778e-06, 'epoch': 2.06}\n",
      "{'loss': 1.0359, 'grad_norm': 18.278013229370117, 'learning_rate': 3.133916013662849e-06, 'epoch': 2.06}\n",
      "{'loss': 0.9729, 'grad_norm': 19.801414489746094, 'learning_rate': 3.1288929073739206e-06, 'epoch': 2.06}\n",
      "{'loss': 1.0678, 'grad_norm': 38.577903747558594, 'learning_rate': 3.123869801084991e-06, 'epoch': 2.06}\n",
      "{'loss': 1.1291, 'grad_norm': 7.539736747741699, 'learning_rate': 3.118846694796062e-06, 'epoch': 2.07}\n",
      "{'loss': 1.1327, 'grad_norm': 24.043682098388672, 'learning_rate': 3.113823588507133e-06, 'epoch': 2.07}\n",
      "{'loss': 1.1141, 'grad_norm': 18.206195831298828, 'learning_rate': 3.1088004822182038e-06, 'epoch': 2.07}\n",
      "{'loss': 0.9918, 'grad_norm': 8.022019386291504, 'learning_rate': 3.1037773759292748e-06, 'epoch': 2.07}\n",
      "{'loss': 1.095, 'grad_norm': 19.164871215820312, 'learning_rate': 3.0987542696403462e-06, 'epoch': 2.07}\n",
      "{'loss': 1.0719, 'grad_norm': 33.96076202392578, 'learning_rate': 3.093731163351417e-06, 'epoch': 2.07}\n",
      "{'loss': 1.0566, 'grad_norm': 24.072311401367188, 'learning_rate': 3.088708057062488e-06, 'epoch': 2.08}\n",
      "{'loss': 1.0827, 'grad_norm': 6.778695106506348, 'learning_rate': 3.083684950773559e-06, 'epoch': 2.08}\n",
      "{'loss': 0.9998, 'grad_norm': 22.418954849243164, 'learning_rate': 3.0786618444846294e-06, 'epoch': 2.08}\n",
      "{'loss': 0.9889, 'grad_norm': 7.9630818367004395, 'learning_rate': 3.0736387381957004e-06, 'epoch': 2.08}\n",
      "{'loss': 1.0072, 'grad_norm': 18.67897605895996, 'learning_rate': 3.068615631906771e-06, 'epoch': 2.08}\n",
      "{'loss': 1.0141, 'grad_norm': 34.17778015136719, 'learning_rate': 3.0635925256178424e-06, 'epoch': 2.08}\n",
      "{'loss': 1.1056, 'grad_norm': 17.728721618652344, 'learning_rate': 3.0585694193289134e-06, 'epoch': 2.08}\n",
      "{'loss': 1.0361, 'grad_norm': 35.495758056640625, 'learning_rate': 3.053546313039984e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0724, 'grad_norm': 22.003341674804688, 'learning_rate': 3.048523206751055e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0446, 'grad_norm': 27.52016830444336, 'learning_rate': 3.043500100462126e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0862, 'grad_norm': 20.21331024169922, 'learning_rate': 3.0384769941731966e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0097, 'grad_norm': 39.24645233154297, 'learning_rate': 3.033453887884268e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0545, 'grad_norm': 22.4814510345459, 'learning_rate': 3.028430781595339e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0544, 'grad_norm': 16.260684967041016, 'learning_rate': 3.0234076753064096e-06, 'epoch': 2.09}\n",
      "{'loss': 1.0826, 'grad_norm': 33.52134323120117, 'learning_rate': 3.0183845690174807e-06, 'epoch': 2.1}\n",
      "{'loss': 1.0085, 'grad_norm': 26.695226669311523, 'learning_rate': 3.0133614627285517e-06, 'epoch': 2.1}\n",
      "{'loss': 1.1214, 'grad_norm': 18.271780014038086, 'learning_rate': 3.0083383564396222e-06, 'epoch': 2.1}\n",
      "{'loss': 1.1148, 'grad_norm': 22.119312286376953, 'learning_rate': 3.0033152501506937e-06, 'epoch': 2.1}\n",
      "{'loss': 1.0605, 'grad_norm': 34.54469680786133, 'learning_rate': 2.9982921438617647e-06, 'epoch': 2.1}\n",
      "{'loss': 1.1114, 'grad_norm': 40.50520324707031, 'learning_rate': 2.9932690375728353e-06, 'epoch': 2.1}\n",
      "{'loss': 1.0663, 'grad_norm': 17.984207153320312, 'learning_rate': 2.9882459312839063e-06, 'epoch': 2.11}\n",
      "{'loss': 1.1402, 'grad_norm': 4.8123579025268555, 'learning_rate': 2.9832228249949773e-06, 'epoch': 2.11}\n",
      "{'loss': 1.0492, 'grad_norm': 23.399219512939453, 'learning_rate': 2.978199718706048e-06, 'epoch': 2.11}\n",
      "{'loss': 1.0438, 'grad_norm': 23.525545120239258, 'learning_rate': 2.973176612417119e-06, 'epoch': 2.11}\n",
      "{'loss': 1.0638, 'grad_norm': 7.2702155113220215, 'learning_rate': 2.9681535061281895e-06, 'epoch': 2.11}\n",
      "{'loss': 1.065, 'grad_norm': 26.43081283569336, 'learning_rate': 2.963130399839261e-06, 'epoch': 2.11}\n",
      "{'loss': 0.992, 'grad_norm': 7.117351531982422, 'learning_rate': 2.958107293550332e-06, 'epoch': 2.11}\n",
      "{'loss': 1.0205, 'grad_norm': 32.28355026245117, 'learning_rate': 2.9530841872614025e-06, 'epoch': 2.12}\n",
      "{'loss': 1.1459, 'grad_norm': 21.364267349243164, 'learning_rate': 2.9480610809724735e-06, 'epoch': 2.12}\n",
      "{'loss': 1.0572, 'grad_norm': 35.027557373046875, 'learning_rate': 2.9430379746835445e-06, 'epoch': 2.12}\n",
      "{'loss': 1.0161, 'grad_norm': 21.387399673461914, 'learning_rate': 2.938014868394615e-06, 'epoch': 2.12}\n",
      "{'loss': 1.1246, 'grad_norm': 17.072738647460938, 'learning_rate': 2.9329917621056865e-06, 'epoch': 2.12}\n",
      "{'loss': 1.0776, 'grad_norm': 36.784019470214844, 'learning_rate': 2.9279686558167575e-06, 'epoch': 2.12}\n",
      "{'loss': 1.1277, 'grad_norm': 39.25039291381836, 'learning_rate': 2.922945549527828e-06, 'epoch': 2.12}\n",
      "{'loss': 1.0563, 'grad_norm': 24.006023406982422, 'learning_rate': 2.917922443238899e-06, 'epoch': 2.13}\n",
      "{'loss': 1.0141, 'grad_norm': 22.359981536865234, 'learning_rate': 2.91289933694997e-06, 'epoch': 2.13}\n",
      "{'loss': 1.0419, 'grad_norm': 26.15127944946289, 'learning_rate': 2.9078762306610407e-06, 'epoch': 2.13}\n",
      "{'loss': 1.0045, 'grad_norm': 27.597827911376953, 'learning_rate': 2.902853124372112e-06, 'epoch': 2.13}\n",
      "{'loss': 1.0876, 'grad_norm': 13.516782760620117, 'learning_rate': 2.897830018083183e-06, 'epoch': 2.13}\n",
      "{'loss': 1.1333, 'grad_norm': 22.64847755432129, 'learning_rate': 2.8928069117942537e-06, 'epoch': 2.13}\n",
      "{'loss': 1.1381, 'grad_norm': 41.20819854736328, 'learning_rate': 2.8877838055053247e-06, 'epoch': 2.14}\n",
      "{'loss': 0.9883, 'grad_norm': 6.85252046585083, 'learning_rate': 2.8827606992163958e-06, 'epoch': 2.14}\n",
      "{'loss': 1.0093, 'grad_norm': 25.691530227661133, 'learning_rate': 2.8777375929274663e-06, 'epoch': 2.14}\n",
      "{'loss': 1.0487, 'grad_norm': 18.77013397216797, 'learning_rate': 2.8727144866385378e-06, 'epoch': 2.14}\n",
      "{'loss': 1.0432, 'grad_norm': 21.284120559692383, 'learning_rate': 2.8676913803496088e-06, 'epoch': 2.14}\n",
      "{'loss': 1.0338, 'grad_norm': 20.52528190612793, 'learning_rate': 2.8626682740606794e-06, 'epoch': 2.14}\n",
      "{'loss': 1.0082, 'grad_norm': 30.91250991821289, 'learning_rate': 2.8576451677717504e-06, 'epoch': 2.14}\n",
      "{'loss': 1.0755, 'grad_norm': 20.701841354370117, 'learning_rate': 2.852622061482821e-06, 'epoch': 2.15}\n",
      "{'loss': 1.0926, 'grad_norm': 26.822431564331055, 'learning_rate': 2.847598955193892e-06, 'epoch': 2.15}\n",
      "{'loss': 1.1206, 'grad_norm': 38.06250762939453, 'learning_rate': 2.8425758489049634e-06, 'epoch': 2.15}\n",
      "{'loss': 1.0425, 'grad_norm': 17.557430267333984, 'learning_rate': 2.8375527426160336e-06, 'epoch': 2.15}\n",
      "{'loss': 1.0582, 'grad_norm': 7.318880558013916, 'learning_rate': 2.832529636327105e-06, 'epoch': 2.15}\n",
      "{'loss': 1.036, 'grad_norm': 22.22705078125, 'learning_rate': 2.827506530038176e-06, 'epoch': 2.15}\n",
      "{'loss': 1.0607, 'grad_norm': 14.302507400512695, 'learning_rate': 2.8224834237492466e-06, 'epoch': 2.15}\n",
      "{'loss': 1.0233, 'grad_norm': 27.174556732177734, 'learning_rate': 2.8174603174603176e-06, 'epoch': 2.16}\n",
      "{'loss': 1.0893, 'grad_norm': 24.83285903930664, 'learning_rate': 2.8124372111713886e-06, 'epoch': 2.16}\n",
      "{'loss': 1.05, 'grad_norm': 43.206356048583984, 'learning_rate': 2.807414104882459e-06, 'epoch': 2.16}\n",
      "{'loss': 0.997, 'grad_norm': 26.3067626953125, 'learning_rate': 2.8023909985935306e-06, 'epoch': 2.16}\n",
      "{'loss': 1.0286, 'grad_norm': 8.011673927307129, 'learning_rate': 2.7973678923046016e-06, 'epoch': 2.16}\n",
      "{'loss': 1.034, 'grad_norm': 8.37952709197998, 'learning_rate': 2.792344786015672e-06, 'epoch': 2.16}\n",
      "{'loss': 1.0847, 'grad_norm': 26.720577239990234, 'learning_rate': 2.787321679726743e-06, 'epoch': 2.17}\n",
      "{'loss': 1.005, 'grad_norm': 10.971723556518555, 'learning_rate': 2.7822985734378142e-06, 'epoch': 2.17}\n",
      "{'loss': 1.0675, 'grad_norm': 19.486183166503906, 'learning_rate': 2.777275467148885e-06, 'epoch': 2.17}\n",
      "{'loss': 1.0339, 'grad_norm': 29.56355094909668, 'learning_rate': 2.7722523608599562e-06, 'epoch': 2.17}\n",
      "{'loss': 1.0625, 'grad_norm': 6.598643779754639, 'learning_rate': 2.7672292545710272e-06, 'epoch': 2.17}\n",
      "{'loss': 1.0778, 'grad_norm': 15.219287872314453, 'learning_rate': 2.762206148282098e-06, 'epoch': 2.17}\n",
      "{'loss': 1.1136, 'grad_norm': 15.136608123779297, 'learning_rate': 2.757183041993169e-06, 'epoch': 2.17}\n",
      "{'loss': 1.0166, 'grad_norm': 27.359785079956055, 'learning_rate': 2.7521599357042394e-06, 'epoch': 2.18}\n",
      "{'loss': 1.0634, 'grad_norm': 39.52435302734375, 'learning_rate': 2.7471368294153104e-06, 'epoch': 2.18}\n",
      "{'loss': 1.0126, 'grad_norm': 6.3111186027526855, 'learning_rate': 2.742113723126382e-06, 'epoch': 2.18}\n",
      "{'loss': 0.9893, 'grad_norm': 9.534281730651855, 'learning_rate': 2.7370906168374524e-06, 'epoch': 2.18}\n",
      "{'loss': 1.1169, 'grad_norm': 7.316402912139893, 'learning_rate': 2.7320675105485234e-06, 'epoch': 2.18}\n",
      "{'loss': 1.0607, 'grad_norm': 7.5797953605651855, 'learning_rate': 2.7270444042595945e-06, 'epoch': 2.18}\n",
      "{'loss': 0.988, 'grad_norm': 18.828086853027344, 'learning_rate': 2.722021297970665e-06, 'epoch': 2.19}\n",
      "{'loss': 1.0476, 'grad_norm': 21.838340759277344, 'learning_rate': 2.716998191681736e-06, 'epoch': 2.19}\n",
      "{'loss': 1.036, 'grad_norm': 24.896032333374023, 'learning_rate': 2.7119750853928075e-06, 'epoch': 2.19}\n",
      "{'loss': 1.0456, 'grad_norm': 24.030797958374023, 'learning_rate': 2.706951979103878e-06, 'epoch': 2.19}\n",
      "{'loss': 1.0772, 'grad_norm': 19.023605346679688, 'learning_rate': 2.701928872814949e-06, 'epoch': 2.19}\n",
      "{'loss': 1.0378, 'grad_norm': 18.15884780883789, 'learning_rate': 2.69690576652602e-06, 'epoch': 2.19}\n",
      "{'loss': 1.0544, 'grad_norm': 8.26440143585205, 'learning_rate': 2.6918826602370907e-06, 'epoch': 2.19}\n",
      "{'loss': 1.1082, 'grad_norm': 18.823787689208984, 'learning_rate': 2.6868595539481617e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0457, 'grad_norm': 19.232141494750977, 'learning_rate': 2.681836447659233e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0625, 'grad_norm': 29.703489303588867, 'learning_rate': 2.6768133413703033e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0917, 'grad_norm': 23.3596134185791, 'learning_rate': 2.6717902350813747e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0864, 'grad_norm': 11.262578964233398, 'learning_rate': 2.6667671287924457e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0734, 'grad_norm': 36.70306396484375, 'learning_rate': 2.6617440225035163e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0434, 'grad_norm': 7.0728960037231445, 'learning_rate': 2.6567209162145873e-06, 'epoch': 2.2}\n",
      "{'loss': 1.0896, 'grad_norm': 18.673490524291992, 'learning_rate': 2.6516978099256583e-06, 'epoch': 2.21}\n",
      "{'loss': 1.0969, 'grad_norm': 15.922908782958984, 'learning_rate': 2.646674703636729e-06, 'epoch': 2.21}\n",
      "{'loss': 1.0301, 'grad_norm': 26.73260498046875, 'learning_rate': 2.6416515973478003e-06, 'epoch': 2.21}\n",
      "{'loss': 1.106, 'grad_norm': 25.808773040771484, 'learning_rate': 2.636628491058871e-06, 'epoch': 2.21}\n",
      "{'loss': 1.0795, 'grad_norm': 55.666988372802734, 'learning_rate': 2.631605384769942e-06, 'epoch': 2.21}\n",
      "{'loss': 1.0489, 'grad_norm': 6.854949951171875, 'learning_rate': 2.626582278481013e-06, 'epoch': 2.21}\n",
      "{'loss': 1.0144, 'grad_norm': 19.76049041748047, 'learning_rate': 2.6215591721920835e-06, 'epoch': 2.22}\n",
      "{'loss': 1.0921, 'grad_norm': 26.82805061340332, 'learning_rate': 2.6165360659031545e-06, 'epoch': 2.22}\n",
      "{'loss': 1.0809, 'grad_norm': 43.90106201171875, 'learning_rate': 2.611512959614226e-06, 'epoch': 2.22}\n",
      "{'loss': 1.0906, 'grad_norm': 29.953876495361328, 'learning_rate': 2.6064898533252965e-06, 'epoch': 2.22}\n",
      "{'loss': 1.1538, 'grad_norm': 40.90496826171875, 'learning_rate': 2.6014667470363675e-06, 'epoch': 2.22}\n",
      "{'loss': 1.0779, 'grad_norm': 35.632469177246094, 'learning_rate': 2.5964436407474385e-06, 'epoch': 2.22}\n",
      "{'loss': 1.1164, 'grad_norm': 38.15812683105469, 'learning_rate': 2.591420534458509e-06, 'epoch': 2.22}\n",
      "{'loss': 1.0235, 'grad_norm': 37.560874938964844, 'learning_rate': 2.58639742816958e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0296, 'grad_norm': 43.06644821166992, 'learning_rate': 2.5813743218806516e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0604, 'grad_norm': 4.945642948150635, 'learning_rate': 2.576351215591722e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0214, 'grad_norm': 33.43479919433594, 'learning_rate': 2.571328109302793e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0612, 'grad_norm': 10.369243621826172, 'learning_rate': 2.566305003013864e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0968, 'grad_norm': 17.307336807250977, 'learning_rate': 2.5612818967249348e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0242, 'grad_norm': 28.615427017211914, 'learning_rate': 2.5562587904360058e-06, 'epoch': 2.23}\n",
      "{'loss': 1.0444, 'grad_norm': 31.33346176147461, 'learning_rate': 2.551235684147077e-06, 'epoch': 2.24}\n",
      "{'loss': 1.0656, 'grad_norm': 7.329921245574951, 'learning_rate': 2.5462125778581478e-06, 'epoch': 2.24}\n",
      "{'loss': 1.0898, 'grad_norm': 29.497516632080078, 'learning_rate': 2.5411894715692188e-06, 'epoch': 2.24}\n",
      "{'loss': 1.1107, 'grad_norm': 29.555419921875, 'learning_rate': 2.53616636528029e-06, 'epoch': 2.24}\n",
      "{'loss': 1.0004, 'grad_norm': 21.314006805419922, 'learning_rate': 2.5311432589913604e-06, 'epoch': 2.24}\n",
      "{'loss': 1.1212, 'grad_norm': 23.25728988647461, 'learning_rate': 2.5261201527024314e-06, 'epoch': 2.24}\n",
      "{'loss': 1.0182, 'grad_norm': 19.396583557128906, 'learning_rate': 2.521097046413502e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0796, 'grad_norm': 15.571603775024414, 'learning_rate': 2.516073940124573e-06, 'epoch': 2.25}\n",
      "{'loss': 0.983, 'grad_norm': 9.150422096252441, 'learning_rate': 2.5110508338356444e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0295, 'grad_norm': 50.896244049072266, 'learning_rate': 2.506027727546715e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0741, 'grad_norm': 36.74966812133789, 'learning_rate': 2.501004621257786e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0171, 'grad_norm': 30.43620491027832, 'learning_rate': 2.495981514968857e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0517, 'grad_norm': 13.794710159301758, 'learning_rate': 2.490958408679928e-06, 'epoch': 2.25}\n",
      "{'loss': 1.0371, 'grad_norm': 20.442745208740234, 'learning_rate': 2.4859353023909986e-06, 'epoch': 2.26}\n",
      "{'loss': 1.0399, 'grad_norm': 11.588712692260742, 'learning_rate': 2.4809121961020696e-06, 'epoch': 2.26}\n",
      "{'loss': 0.9974, 'grad_norm': 19.637142181396484, 'learning_rate': 2.4758890898131406e-06, 'epoch': 2.26}\n",
      "{'loss': 1.1143, 'grad_norm': 39.90449142456055, 'learning_rate': 2.4708659835242116e-06, 'epoch': 2.26}\n",
      "{'loss': 1.015, 'grad_norm': 45.05992889404297, 'learning_rate': 2.4658428772352826e-06, 'epoch': 2.26}\n",
      "{'loss': 1.1159, 'grad_norm': 40.03225326538086, 'learning_rate': 2.4608197709463536e-06, 'epoch': 2.26}\n",
      "{'loss': 1.0532, 'grad_norm': 26.116552352905273, 'learning_rate': 2.4557966646574242e-06, 'epoch': 2.26}\n",
      "{'loss': 0.9776, 'grad_norm': 37.332515716552734, 'learning_rate': 2.4507735583684952e-06, 'epoch': 2.27}\n",
      "{'loss': 1.0755, 'grad_norm': 54.49224090576172, 'learning_rate': 2.4457504520795662e-06, 'epoch': 2.27}\n",
      "{'loss': 1.068, 'grad_norm': 20.2816219329834, 'learning_rate': 2.4407273457906373e-06, 'epoch': 2.27}\n",
      "{'loss': 1.0217, 'grad_norm': 28.744094848632812, 'learning_rate': 2.435704239501708e-06, 'epoch': 2.27}\n",
      "{'loss': 1.0559, 'grad_norm': 36.367801666259766, 'learning_rate': 2.430681133212779e-06, 'epoch': 2.27}\n",
      "{'loss': 1.041, 'grad_norm': 16.89544677734375, 'learning_rate': 2.426160337552743e-06, 'epoch': 2.27}\n",
      "{'loss': 1.0683, 'grad_norm': 40.48700714111328, 'learning_rate': 2.4211372312638135e-06, 'epoch': 2.28}\n",
      "{'loss': 1.0165, 'grad_norm': 25.327848434448242, 'learning_rate': 2.4161141249748846e-06, 'epoch': 2.28}\n",
      "{'loss': 1.0548, 'grad_norm': 20.54457664489746, 'learning_rate': 2.4110910186859556e-06, 'epoch': 2.28}\n",
      "{'loss': 1.0152, 'grad_norm': 21.37043571472168, 'learning_rate': 2.4060679123970266e-06, 'epoch': 2.28}\n",
      "{'loss': 1.1767, 'grad_norm': 51.98261642456055, 'learning_rate': 2.4010448061080976e-06, 'epoch': 2.28}\n",
      "{'loss': 1.0431, 'grad_norm': 29.544803619384766, 'learning_rate': 2.3960216998191686e-06, 'epoch': 2.28}\n",
      "{'loss': 1.0159, 'grad_norm': 25.341602325439453, 'learning_rate': 2.390998593530239e-06, 'epoch': 2.28}\n",
      "{'loss': 1.0693, 'grad_norm': 38.93205261230469, 'learning_rate': 2.38597548724131e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0713, 'grad_norm': 16.866079330444336, 'learning_rate': 2.380952380952381e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0704, 'grad_norm': 6.3952860832214355, 'learning_rate': 2.375929274663452e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0898, 'grad_norm': 9.067618370056152, 'learning_rate': 2.3709061683745228e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0764, 'grad_norm': 30.716970443725586, 'learning_rate': 2.3658830620855938e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0191, 'grad_norm': 17.607070922851562, 'learning_rate': 2.360859955796665e-06, 'epoch': 2.29}\n",
      "{'loss': 1.0211, 'grad_norm': 8.118441581726074, 'learning_rate': 2.355836849507736e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0961, 'grad_norm': 9.2584867477417, 'learning_rate': 2.350813743218807e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0874, 'grad_norm': 5.862968444824219, 'learning_rate': 2.345790636929878e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0751, 'grad_norm': 19.487958908081055, 'learning_rate': 2.3407675306409484e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0913, 'grad_norm': 10.418949127197266, 'learning_rate': 2.3357444243520194e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0458, 'grad_norm': 31.736417770385742, 'learning_rate': 2.3307213180630904e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0319, 'grad_norm': 6.564932346343994, 'learning_rate': 2.3256982117741614e-06, 'epoch': 2.3}\n",
      "{'loss': 1.0157, 'grad_norm': 30.37006378173828, 'learning_rate': 2.3206751054852324e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0597, 'grad_norm': 19.096973419189453, 'learning_rate': 2.315651999196303e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0797, 'grad_norm': 36.90789031982422, 'learning_rate': 2.310628892907374e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0028, 'grad_norm': 7.475784778594971, 'learning_rate': 2.305605786618445e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0942, 'grad_norm': 20.096874237060547, 'learning_rate': 2.300582680329516e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0714, 'grad_norm': 55.441680908203125, 'learning_rate': 2.295559574040587e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0936, 'grad_norm': 34.745540618896484, 'learning_rate': 2.2905364677516576e-06, 'epoch': 2.31}\n",
      "{'loss': 1.0316, 'grad_norm': 8.308268547058105, 'learning_rate': 2.2855133614627286e-06, 'epoch': 2.32}\n",
      "{'loss': 1.0253, 'grad_norm': 29.06877899169922, 'learning_rate': 2.2804902551737997e-06, 'epoch': 2.32}\n",
      "{'loss': 1.0487, 'grad_norm': 52.57854080200195, 'learning_rate': 2.2754671488848707e-06, 'epoch': 2.32}\n",
      "{'loss': 1.0795, 'grad_norm': 17.221805572509766, 'learning_rate': 2.2704440425959417e-06, 'epoch': 2.32}\n",
      "{'loss': 1.0675, 'grad_norm': 20.856306076049805, 'learning_rate': 2.2654209363070123e-06, 'epoch': 2.32}\n",
      "{'loss': 1.1034, 'grad_norm': 13.698269844055176, 'learning_rate': 2.2603978300180833e-06, 'epoch': 2.32}\n",
      "{'loss': 1.0635, 'grad_norm': 26.239545822143555, 'learning_rate': 2.2553747237291543e-06, 'epoch': 2.33}\n",
      "{'loss': 1.0376, 'grad_norm': 32.37785339355469, 'learning_rate': 2.2503516174402253e-06, 'epoch': 2.33}\n",
      "{'loss': 1.1001, 'grad_norm': 11.665786743164062, 'learning_rate': 2.2453285111512963e-06, 'epoch': 2.33}\n",
      "{'loss': 1.0125, 'grad_norm': 29.691390991210938, 'learning_rate': 2.2403054048623673e-06, 'epoch': 2.33}\n",
      "{'loss': 0.9832, 'grad_norm': 20.402591705322266, 'learning_rate': 2.235282298573438e-06, 'epoch': 2.33}\n",
      "{'loss': 1.0703, 'grad_norm': 31.98261833190918, 'learning_rate': 2.230259192284509e-06, 'epoch': 2.33}\n",
      "{'loss': 1.0522, 'grad_norm': 16.8134822845459, 'learning_rate': 2.22523608599558e-06, 'epoch': 2.33}\n",
      "{'loss': 1.038, 'grad_norm': 33.70927047729492, 'learning_rate': 2.220212979706651e-06, 'epoch': 2.34}\n",
      "{'loss': 1.0676, 'grad_norm': 33.263675689697266, 'learning_rate': 2.2151898734177215e-06, 'epoch': 2.34}\n",
      "{'loss': 0.999, 'grad_norm': 37.68437194824219, 'learning_rate': 2.2101667671287925e-06, 'epoch': 2.34}\n",
      "{'loss': 1.0281, 'grad_norm': 34.65367126464844, 'learning_rate': 2.2051436608398635e-06, 'epoch': 2.34}\n",
      "{'loss': 1.0623, 'grad_norm': 20.87607765197754, 'learning_rate': 2.2001205545509345e-06, 'epoch': 2.34}\n",
      "{'loss': 1.0307, 'grad_norm': 16.259531021118164, 'learning_rate': 2.1950974482620055e-06, 'epoch': 2.34}\n",
      "{'loss': 1.071, 'grad_norm': 24.239912033081055, 'learning_rate': 2.1900743419730765e-06, 'epoch': 2.34}\n",
      "{'loss': 1.0566, 'grad_norm': 44.27286148071289, 'learning_rate': 2.185051235684147e-06, 'epoch': 2.35}\n",
      "{'loss': 1.1464, 'grad_norm': 40.26388931274414, 'learning_rate': 2.180028129395218e-06, 'epoch': 2.35}\n",
      "{'loss': 1.0654, 'grad_norm': 16.39666175842285, 'learning_rate': 2.175005023106289e-06, 'epoch': 2.35}\n",
      "{'loss': 1.097, 'grad_norm': 11.099730491638184, 'learning_rate': 2.16998191681736e-06, 'epoch': 2.35}\n",
      "{'loss': 1.097, 'grad_norm': 8.731277465820312, 'learning_rate': 2.1649588105284307e-06, 'epoch': 2.35}\n",
      "{'loss': 1.0035, 'grad_norm': 9.490903854370117, 'learning_rate': 2.159935704239502e-06, 'epoch': 2.35}\n",
      "{'loss': 1.0578, 'grad_norm': 16.03202247619629, 'learning_rate': 2.1549125979505727e-06, 'epoch': 2.36}\n",
      "{'loss': 1.0093, 'grad_norm': 8.171530723571777, 'learning_rate': 2.1498894916616437e-06, 'epoch': 2.36}\n",
      "{'loss': 1.113, 'grad_norm': 31.40558624267578, 'learning_rate': 2.1448663853727148e-06, 'epoch': 2.36}\n",
      "{'loss': 1.12, 'grad_norm': 18.464797973632812, 'learning_rate': 2.1398432790837858e-06, 'epoch': 2.36}\n",
      "{'loss': 1.0676, 'grad_norm': 18.392770767211914, 'learning_rate': 2.1348201727948563e-06, 'epoch': 2.36}\n",
      "{'loss': 1.0047, 'grad_norm': 36.351139068603516, 'learning_rate': 2.1297970665059274e-06, 'epoch': 2.36}\n",
      "{'loss': 1.046, 'grad_norm': 7.010880947113037, 'learning_rate': 2.1247739602169984e-06, 'epoch': 2.36}\n",
      "{'loss': 1.0749, 'grad_norm': 30.29153060913086, 'learning_rate': 2.1197508539280694e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0848, 'grad_norm': 21.512495040893555, 'learning_rate': 2.1147277476391404e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0193, 'grad_norm': 10.714816093444824, 'learning_rate': 2.1097046413502114e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0839, 'grad_norm': 32.69293975830078, 'learning_rate': 2.104681535061282e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0399, 'grad_norm': 38.17431640625, 'learning_rate': 2.099658428772353e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0699, 'grad_norm': 25.62946891784668, 'learning_rate': 2.094635322483424e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0621, 'grad_norm': 17.455318450927734, 'learning_rate': 2.089612216194495e-06, 'epoch': 2.37}\n",
      "{'loss': 1.0167, 'grad_norm': 33.57369613647461, 'learning_rate': 2.0845891099055656e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0154, 'grad_norm': 25.264963150024414, 'learning_rate': 2.079566003616637e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0458, 'grad_norm': 8.609153747558594, 'learning_rate': 2.0745428973277076e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0381, 'grad_norm': 21.889883041381836, 'learning_rate': 2.0695197910387786e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0905, 'grad_norm': 16.839265823364258, 'learning_rate': 2.0644966847498496e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0506, 'grad_norm': 10.748668670654297, 'learning_rate': 2.0594735784609206e-06, 'epoch': 2.38}\n",
      "{'loss': 1.0966, 'grad_norm': 32.31547164916992, 'learning_rate': 2.054450472171991e-06, 'epoch': 2.39}\n",
      "{'loss': 1.1022, 'grad_norm': 10.203685760498047, 'learning_rate': 2.049427365883062e-06, 'epoch': 2.39}\n",
      "{'loss': 1.0076, 'grad_norm': 28.639856338500977, 'learning_rate': 2.0444042595941332e-06, 'epoch': 2.39}\n",
      "{'loss': 1.0568, 'grad_norm': 26.473377227783203, 'learning_rate': 2.0393811533052042e-06, 'epoch': 2.39}\n",
      "{'loss': 1.0735, 'grad_norm': 25.841962814331055, 'learning_rate': 2.034358047016275e-06, 'epoch': 2.39}\n",
      "{'loss': 1.0428, 'grad_norm': 45.1536750793457, 'learning_rate': 2.0293349407273462e-06, 'epoch': 2.39}\n",
      "{'loss': 1.0699, 'grad_norm': 8.28825569152832, 'learning_rate': 2.024311834438417e-06, 'epoch': 2.39}\n",
      "{'loss': 1.0895, 'grad_norm': 29.461206436157227, 'learning_rate': 2.019288728149488e-06, 'epoch': 2.4}\n",
      "{'loss': 1.0452, 'grad_norm': 7.157302379608154, 'learning_rate': 2.014265621860559e-06, 'epoch': 2.4}\n",
      "{'loss': 1.0336, 'grad_norm': 8.556427955627441, 'learning_rate': 2.00924251557163e-06, 'epoch': 2.4}\n",
      "{'loss': 1.0114, 'grad_norm': 27.201183319091797, 'learning_rate': 2.0042194092827004e-06, 'epoch': 2.4}\n",
      "{'loss': 1.0414, 'grad_norm': 17.928146362304688, 'learning_rate': 1.9991963029937714e-06, 'epoch': 2.4}\n",
      "{'loss': 1.0226, 'grad_norm': 18.264970779418945, 'learning_rate': 1.9941731967048424e-06, 'epoch': 2.4}\n",
      "{'loss': 1.0104, 'grad_norm': 11.54747486114502, 'learning_rate': 1.9891500904159135e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0596, 'grad_norm': 32.49303436279297, 'learning_rate': 1.984126984126984e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0408, 'grad_norm': 9.253735542297363, 'learning_rate': 1.9791038778380555e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0687, 'grad_norm': 26.397563934326172, 'learning_rate': 1.974080771549126e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0416, 'grad_norm': 11.39215087890625, 'learning_rate': 1.969057665260197e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0074, 'grad_norm': 23.884761810302734, 'learning_rate': 1.964034558971268e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0344, 'grad_norm': 17.956253051757812, 'learning_rate': 1.959011452682339e-06, 'epoch': 2.41}\n",
      "{'loss': 1.0899, 'grad_norm': 38.065120697021484, 'learning_rate': 1.9539883463934097e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0675, 'grad_norm': 15.577049255371094, 'learning_rate': 1.948965240104481e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0769, 'grad_norm': 38.51351547241211, 'learning_rate': 1.9439421338155517e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0616, 'grad_norm': 52.37898635864258, 'learning_rate': 1.9389190275266227e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0809, 'grad_norm': 12.977716445922852, 'learning_rate': 1.9338959212376933e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0757, 'grad_norm': 47.531829833984375, 'learning_rate': 1.9288728149487647e-06, 'epoch': 2.42}\n",
      "{'loss': 1.0693, 'grad_norm': 18.407800674438477, 'learning_rate': 1.9238497086598353e-06, 'epoch': 2.42}\n",
      "{'loss': 1.02, 'grad_norm': 6.28074836730957, 'learning_rate': 1.9188266023709063e-06, 'epoch': 2.43}\n",
      "{'loss': 1.0627, 'grad_norm': 17.74395179748535, 'learning_rate': 1.9138034960819773e-06, 'epoch': 2.43}\n",
      "{'loss': 1.0852, 'grad_norm': 16.694517135620117, 'learning_rate': 1.9087803897930483e-06, 'epoch': 2.43}\n",
      "{'loss': 1.0519, 'grad_norm': 29.07562828063965, 'learning_rate': 1.9037572835041191e-06, 'epoch': 2.43}\n",
      "{'loss': 1.0936, 'grad_norm': 8.062955856323242, 'learning_rate': 1.8987341772151901e-06, 'epoch': 2.43}\n",
      "{'loss': 0.9766, 'grad_norm': 43.236934661865234, 'learning_rate': 1.893711070926261e-06, 'epoch': 2.43}\n",
      "{'loss': 1.1259, 'grad_norm': 8.658350944519043, 'learning_rate': 1.888687964637332e-06, 'epoch': 2.44}\n",
      "{'loss': 0.9916, 'grad_norm': 18.615917205810547, 'learning_rate': 1.8836648583484027e-06, 'epoch': 2.44}\n",
      "{'loss': 1.045, 'grad_norm': 18.91106605529785, 'learning_rate': 1.8786417520594737e-06, 'epoch': 2.44}\n",
      "{'loss': 1.085, 'grad_norm': 29.002117156982422, 'learning_rate': 1.8736186457705447e-06, 'epoch': 2.44}\n",
      "{'loss': 0.9899, 'grad_norm': 13.96438217163086, 'learning_rate': 1.8685955394816155e-06, 'epoch': 2.44}\n",
      "{'loss': 1.1114, 'grad_norm': 11.597484588623047, 'learning_rate': 1.8635724331926865e-06, 'epoch': 2.44}\n",
      "{'loss': 1.0817, 'grad_norm': 18.561614990234375, 'learning_rate': 1.8585493269037575e-06, 'epoch': 2.44}\n",
      "{'loss': 1.0575, 'grad_norm': 28.118013381958008, 'learning_rate': 1.8535262206148283e-06, 'epoch': 2.45}\n",
      "{'loss': 0.9754, 'grad_norm': 26.047401428222656, 'learning_rate': 1.8485031143258993e-06, 'epoch': 2.45}\n",
      "{'loss': 1.0539, 'grad_norm': 21.141298294067383, 'learning_rate': 1.8434800080369701e-06, 'epoch': 2.45}\n",
      "{'loss': 1.0525, 'grad_norm': 56.56588363647461, 'learning_rate': 1.8384569017480412e-06, 'epoch': 2.45}\n",
      "{'loss': 1.077, 'grad_norm': 18.461442947387695, 'learning_rate': 1.833433795459112e-06, 'epoch': 2.45}\n",
      "{'loss': 1.0294, 'grad_norm': 6.802295684814453, 'learning_rate': 1.828410689170183e-06, 'epoch': 2.45}\n",
      "{'loss': 1.078, 'grad_norm': 30.84673309326172, 'learning_rate': 1.823387582881254e-06, 'epoch': 2.45}\n",
      "{'loss': 1.0695, 'grad_norm': 12.549666404724121, 'learning_rate': 1.8183644765923248e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0147, 'grad_norm': 21.814781188964844, 'learning_rate': 1.8133413703033958e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0662, 'grad_norm': 18.548511505126953, 'learning_rate': 1.8083182640144668e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0747, 'grad_norm': 28.277164459228516, 'learning_rate': 1.8032951577255376e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0435, 'grad_norm': 27.777807235717773, 'learning_rate': 1.7982720514366086e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0511, 'grad_norm': 16.48189353942871, 'learning_rate': 1.7932489451476796e-06, 'epoch': 2.46}\n",
      "{'loss': 1.0368, 'grad_norm': 31.583024978637695, 'learning_rate': 1.7882258388587504e-06, 'epoch': 2.47}\n",
      "{'loss': 1.1204, 'grad_norm': 23.579858779907227, 'learning_rate': 1.7832027325698214e-06, 'epoch': 2.47}\n",
      "{'loss': 1.0713, 'grad_norm': 21.93096923828125, 'learning_rate': 1.7781796262808924e-06, 'epoch': 2.47}\n",
      "{'loss': 1.1443, 'grad_norm': 6.3611555099487305, 'learning_rate': 1.7731565199919632e-06, 'epoch': 2.47}\n",
      "{'loss': 1.0211, 'grad_norm': 8.786531448364258, 'learning_rate': 1.768133413703034e-06, 'epoch': 2.47}\n",
      "{'loss': 1.0256, 'grad_norm': 23.623462677001953, 'learning_rate': 1.763110307414105e-06, 'epoch': 2.47}\n",
      "{'loss': 1.0775, 'grad_norm': 27.682531356811523, 'learning_rate': 1.758087201125176e-06, 'epoch': 2.47}\n",
      "{'loss': 1.0643, 'grad_norm': 18.253307342529297, 'learning_rate': 1.7530640948362468e-06, 'epoch': 2.48}\n",
      "{'loss': 1.0699, 'grad_norm': 29.04212760925293, 'learning_rate': 1.7480409885473178e-06, 'epoch': 2.48}\n",
      "{'loss': 1.0664, 'grad_norm': 17.271963119506836, 'learning_rate': 1.7430178822583888e-06, 'epoch': 2.48}\n",
      "{'loss': 1.0526, 'grad_norm': 24.20075225830078, 'learning_rate': 1.7379947759694596e-06, 'epoch': 2.48}\n",
      "{'loss': 1.0837, 'grad_norm': 8.458816528320312, 'learning_rate': 1.7329716696805306e-06, 'epoch': 2.48}\n",
      "{'loss': 1.0158, 'grad_norm': 7.190365791320801, 'learning_rate': 1.7279485633916016e-06, 'epoch': 2.48}\n",
      "{'loss': 0.9502, 'grad_norm': 10.215150833129883, 'learning_rate': 1.7229254571026724e-06, 'epoch': 2.48}\n",
      "{'loss': 1.0864, 'grad_norm': 20.424325942993164, 'learning_rate': 1.7179023508137432e-06, 'epoch': 2.49}\n",
      "{'loss': 1.0487, 'grad_norm': 31.195173263549805, 'learning_rate': 1.7128792445248144e-06, 'epoch': 2.49}\n",
      "{'loss': 1.0403, 'grad_norm': 37.549198150634766, 'learning_rate': 1.7078561382358852e-06, 'epoch': 2.49}\n",
      "{'loss': 0.9987, 'grad_norm': 26.214763641357422, 'learning_rate': 1.702833031946956e-06, 'epoch': 2.49}\n",
      "{'loss': 1.0244, 'grad_norm': 28.397708892822266, 'learning_rate': 1.6978099256580273e-06, 'epoch': 2.49}\n",
      "{'loss': 1.0531, 'grad_norm': 8.031594276428223, 'learning_rate': 1.692786819369098e-06, 'epoch': 2.49}\n",
      "{'loss': 1.0707, 'grad_norm': 44.58408737182617, 'learning_rate': 1.6877637130801689e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0505, 'grad_norm': 7.939800262451172, 'learning_rate': 1.6827406067912399e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0305, 'grad_norm': 20.518198013305664, 'learning_rate': 1.6777175005023109e-06, 'epoch': 2.5}\n",
      "{'loss': 0.941, 'grad_norm': 25.223726272583008, 'learning_rate': 1.6726943942133817e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0556, 'grad_norm': 9.632889747619629, 'learning_rate': 1.6676712879244525e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0469, 'grad_norm': 18.909740447998047, 'learning_rate': 1.6626481816355237e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0773, 'grad_norm': 8.311344146728516, 'learning_rate': 1.6576250753465945e-06, 'epoch': 2.5}\n",
      "{'loss': 1.0173, 'grad_norm': 48.802696228027344, 'learning_rate': 1.6526019690576653e-06, 'epoch': 2.51}\n",
      "{'loss': 1.0638, 'grad_norm': 7.743668556213379, 'learning_rate': 1.6475788627687365e-06, 'epoch': 2.51}\n",
      "{'loss': 1.0424, 'grad_norm': 24.068246841430664, 'learning_rate': 1.6425557564798073e-06, 'epoch': 2.51}\n",
      "{'loss': 1.0768, 'grad_norm': 31.179153442382812, 'learning_rate': 1.637532650190878e-06, 'epoch': 2.51}\n",
      "{'loss': 1.0443, 'grad_norm': 22.695858001708984, 'learning_rate': 1.6325095439019493e-06, 'epoch': 2.51}\n",
      "{'loss': 1.0158, 'grad_norm': 17.105051040649414, 'learning_rate': 1.62748643761302e-06, 'epoch': 2.51}\n",
      "{'loss': 1.0991, 'grad_norm': 30.171302795410156, 'learning_rate': 1.622463331324091e-06, 'epoch': 2.52}\n",
      "{'loss': 1.0229, 'grad_norm': 18.038545608520508, 'learning_rate': 1.6174402250351621e-06, 'epoch': 2.52}\n",
      "{'loss': 1.0204, 'grad_norm': 6.170473098754883, 'learning_rate': 1.612417118746233e-06, 'epoch': 2.52}\n",
      "{'loss': 1.0491, 'grad_norm': 39.982276916503906, 'learning_rate': 1.6073940124573037e-06, 'epoch': 2.52}\n",
      "{'loss': 1.0921, 'grad_norm': 23.115863800048828, 'learning_rate': 1.6023709061683745e-06, 'epoch': 2.52}\n",
      "{'loss': 1.0879, 'grad_norm': 54.06723403930664, 'learning_rate': 1.5973477998794457e-06, 'epoch': 2.52}\n",
      "{'loss': 0.9889, 'grad_norm': 39.13865661621094, 'learning_rate': 1.5923246935905165e-06, 'epoch': 2.52}\n",
      "{'loss': 1.0429, 'grad_norm': 22.509552001953125, 'learning_rate': 1.5873015873015873e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0257, 'grad_norm': 20.45787811279297, 'learning_rate': 1.5822784810126585e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0715, 'grad_norm': 22.38105010986328, 'learning_rate': 1.5772553747237293e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0714, 'grad_norm': 23.209901809692383, 'learning_rate': 1.5722322684348001e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0691, 'grad_norm': 37.42449188232422, 'learning_rate': 1.5672091621458713e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0462, 'grad_norm': 22.70913314819336, 'learning_rate': 1.5621860558569421e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0685, 'grad_norm': 40.67946243286133, 'learning_rate': 1.557162949568013e-06, 'epoch': 2.53}\n",
      "{'loss': 1.0526, 'grad_norm': 21.25375747680664, 'learning_rate': 1.5521398432790837e-06, 'epoch': 2.54}\n",
      "{'loss': 1.0982, 'grad_norm': 18.72864532470703, 'learning_rate': 1.547116736990155e-06, 'epoch': 2.54}\n",
      "{'loss': 1.0438, 'grad_norm': 38.00486755371094, 'learning_rate': 1.5420936307012258e-06, 'epoch': 2.54}\n",
      "{'loss': 1.0291, 'grad_norm': 7.4927287101745605, 'learning_rate': 1.5370705244122965e-06, 'epoch': 2.54}\n",
      "{'loss': 1.0978, 'grad_norm': 18.226303100585938, 'learning_rate': 1.5320474181233678e-06, 'epoch': 2.54}\n",
      "{'loss': 0.9775, 'grad_norm': 25.316734313964844, 'learning_rate': 1.5270243118344386e-06, 'epoch': 2.54}\n",
      "{'loss': 1.057, 'grad_norm': 19.156234741210938, 'learning_rate': 1.5220012055455094e-06, 'epoch': 2.55}\n",
      "{'loss': 1.1102, 'grad_norm': 20.852516174316406, 'learning_rate': 1.5169780992565806e-06, 'epoch': 2.55}\n",
      "{'loss': 1.0478, 'grad_norm': 13.383572578430176, 'learning_rate': 1.5119549929676514e-06, 'epoch': 2.55}\n",
      "{'loss': 1.0515, 'grad_norm': 27.92833137512207, 'learning_rate': 1.5069318866787222e-06, 'epoch': 2.55}\n",
      "{'loss': 1.0664, 'grad_norm': 8.290708541870117, 'learning_rate': 1.501908780389793e-06, 'epoch': 2.55}\n",
      "{'loss': 1.0754, 'grad_norm': 18.361244201660156, 'learning_rate': 1.4968856741008642e-06, 'epoch': 2.55}\n",
      "{'loss': 1.0301, 'grad_norm': 27.171321868896484, 'learning_rate': 1.491862567811935e-06, 'epoch': 2.55}\n",
      "{'loss': 1.0564, 'grad_norm': 28.147703170776367, 'learning_rate': 1.4868394615230058e-06, 'epoch': 2.56}\n",
      "{'loss': 1.0524, 'grad_norm': 26.476884841918945, 'learning_rate': 1.481816355234077e-06, 'epoch': 2.56}\n",
      "{'loss': 1.0332, 'grad_norm': 32.54120635986328, 'learning_rate': 1.4767932489451478e-06, 'epoch': 2.56}\n",
      "{'loss': 1.0838, 'grad_norm': 24.16207504272461, 'learning_rate': 1.4717701426562186e-06, 'epoch': 2.56}\n",
      "{'loss': 1.0968, 'grad_norm': 7.701263427734375, 'learning_rate': 1.4667470363672898e-06, 'epoch': 2.56}\n",
      "{'loss': 1.072, 'grad_norm': 19.721071243286133, 'learning_rate': 1.4617239300783606e-06, 'epoch': 2.56}\n",
      "{'loss': 1.0667, 'grad_norm': 27.45901870727539, 'learning_rate': 1.4567008237894314e-06, 'epoch': 2.56}\n",
      "{'loss': 1.0624, 'grad_norm': 26.635562896728516, 'learning_rate': 1.4516777175005022e-06, 'epoch': 2.57}\n",
      "{'loss': 1.0884, 'grad_norm': 28.121517181396484, 'learning_rate': 1.4466546112115734e-06, 'epoch': 2.57}\n",
      "{'loss': 1.0244, 'grad_norm': 26.185752868652344, 'learning_rate': 1.4416315049226442e-06, 'epoch': 2.57}\n",
      "{'loss': 0.9552, 'grad_norm': 5.514767646789551, 'learning_rate': 1.436608398633715e-06, 'epoch': 2.57}\n",
      "{'loss': 1.0701, 'grad_norm': 28.589357376098633, 'learning_rate': 1.4315852923447862e-06, 'epoch': 2.57}\n",
      "{'loss': 1.046, 'grad_norm': 22.046775817871094, 'learning_rate': 1.426562186055857e-06, 'epoch': 2.57}\n",
      "{'loss': 1.0205, 'grad_norm': 26.793787002563477, 'learning_rate': 1.4215390797669278e-06, 'epoch': 2.58}\n",
      "{'loss': 0.9893, 'grad_norm': 6.130334854125977, 'learning_rate': 1.416515973477999e-06, 'epoch': 2.58}\n",
      "{'loss': 1.0057, 'grad_norm': 4.961259841918945, 'learning_rate': 1.4114928671890698e-06, 'epoch': 2.58}\n",
      "{'loss': 1.0897, 'grad_norm': 35.9765739440918, 'learning_rate': 1.4064697609001406e-06, 'epoch': 2.58}\n",
      "{'loss': 1.0624, 'grad_norm': 24.198219299316406, 'learning_rate': 1.4014466546112119e-06, 'epoch': 2.58}\n",
      "{'loss': 1.1782, 'grad_norm': 39.77297592163086, 'learning_rate': 1.3964235483222827e-06, 'epoch': 2.58}\n",
      "{'loss': 1.0119, 'grad_norm': 28.681947708129883, 'learning_rate': 1.3914004420333535e-06, 'epoch': 2.58}\n",
      "{'loss': 1.0398, 'grad_norm': 43.550045013427734, 'learning_rate': 1.3863773357444242e-06, 'epoch': 2.59}\n",
      "{'loss': 1.1469, 'grad_norm': 8.11479663848877, 'learning_rate': 1.3813542294554955e-06, 'epoch': 2.59}\n",
      "{'loss': 1.0174, 'grad_norm': 20.37932777404785, 'learning_rate': 1.3763311231665663e-06, 'epoch': 2.59}\n",
      "{'loss': 1.0845, 'grad_norm': 20.65559959411621, 'learning_rate': 1.371308016877637e-06, 'epoch': 2.59}\n",
      "{'loss': 1.1144, 'grad_norm': 8.58968734741211, 'learning_rate': 1.3662849105887083e-06, 'epoch': 2.59}\n",
      "{'loss': 1.0982, 'grad_norm': 22.762619018554688, 'learning_rate': 1.361261804299779e-06, 'epoch': 2.59}\n",
      "{'loss': 1.0384, 'grad_norm': 19.60458755493164, 'learning_rate': 1.3562386980108499e-06, 'epoch': 2.59}\n",
      "{'loss': 1.0593, 'grad_norm': 15.828850746154785, 'learning_rate': 1.351215591721921e-06, 'epoch': 2.6}\n",
      "{'loss': 1.0509, 'grad_norm': 21.12273597717285, 'learning_rate': 1.3461924854329919e-06, 'epoch': 2.6}\n",
      "{'loss': 1.1039, 'grad_norm': 44.25828552246094, 'learning_rate': 1.3411693791440627e-06, 'epoch': 2.6}\n",
      "{'loss': 1.0137, 'grad_norm': 42.84970474243164, 'learning_rate': 1.3361462728551337e-06, 'epoch': 2.6}\n",
      "{'loss': 1.0135, 'grad_norm': 16.161035537719727, 'learning_rate': 1.3311231665662047e-06, 'epoch': 2.6}\n",
      "{'loss': 1.0633, 'grad_norm': 21.477888107299805, 'learning_rate': 1.3261000602772755e-06, 'epoch': 2.6}\n",
      "{'loss': 1.0615, 'grad_norm': 18.534700393676758, 'learning_rate': 1.3215792646172392e-06, 'epoch': 2.61}\n",
      "{'loss': 1.0877, 'grad_norm': 21.530900955200195, 'learning_rate': 1.3165561583283104e-06, 'epoch': 2.61}\n",
      "{'loss': 0.9955, 'grad_norm': 14.316713333129883, 'learning_rate': 1.3115330520393812e-06, 'epoch': 2.61}\n",
      "{'loss': 1.1038, 'grad_norm': 6.889313220977783, 'learning_rate': 1.306509945750452e-06, 'epoch': 2.61}\n",
      "{'loss': 1.1068, 'grad_norm': 19.627338409423828, 'learning_rate': 1.3014868394615232e-06, 'epoch': 2.61}\n",
      "{'loss': 1.0836, 'grad_norm': 17.098115921020508, 'learning_rate': 1.296463733172594e-06, 'epoch': 2.61}\n",
      "{'loss': 1.0081, 'grad_norm': 28.15509796142578, 'learning_rate': 1.2914406268836648e-06, 'epoch': 2.61}\n",
      "{'loss': 1.0412, 'grad_norm': 20.302854537963867, 'learning_rate': 1.286417520594736e-06, 'epoch': 2.62}\n",
      "{'loss': 1.0591, 'grad_norm': 6.462316989898682, 'learning_rate': 1.2813944143058068e-06, 'epoch': 2.62}\n",
      "{'loss': 1.1819, 'grad_norm': 34.952388763427734, 'learning_rate': 1.2763713080168776e-06, 'epoch': 2.62}\n",
      "{'loss': 1.0731, 'grad_norm': 18.317787170410156, 'learning_rate': 1.2713482017279486e-06, 'epoch': 2.62}\n",
      "{'loss': 1.0185, 'grad_norm': 5.908395290374756, 'learning_rate': 1.2663250954390196e-06, 'epoch': 2.62}\n",
      "{'loss': 1.0274, 'grad_norm': 26.965906143188477, 'learning_rate': 1.2613019891500904e-06, 'epoch': 2.62}\n",
      "{'loss': 1.0894, 'grad_norm': 19.670541763305664, 'learning_rate': 1.2562788828611612e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0183, 'grad_norm': 46.47904586791992, 'learning_rate': 1.2512557765722325e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0152, 'grad_norm': 44.498409271240234, 'learning_rate': 1.2462326702833033e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0349, 'grad_norm': 14.710627555847168, 'learning_rate': 1.2412095639943743e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0375, 'grad_norm': 13.763113975524902, 'learning_rate': 1.236186457705445e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0151, 'grad_norm': 19.248416900634766, 'learning_rate': 1.231163351416516e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0444, 'grad_norm': 6.992576599121094, 'learning_rate': 1.2261402451275869e-06, 'epoch': 2.63}\n",
      "{'loss': 1.0439, 'grad_norm': 20.849323272705078, 'learning_rate': 1.2211171388386579e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0838, 'grad_norm': 18.53030776977539, 'learning_rate': 1.2160940325497289e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0414, 'grad_norm': 12.00285530090332, 'learning_rate': 1.2110709262607997e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0388, 'grad_norm': 29.158376693725586, 'learning_rate': 1.2060478199718707e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0654, 'grad_norm': 28.298933029174805, 'learning_rate': 1.2010247136829415e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0316, 'grad_norm': 6.322293281555176, 'learning_rate': 1.1960016073940125e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0369, 'grad_norm': 7.820493698120117, 'learning_rate': 1.1909785011050835e-06, 'epoch': 2.64}\n",
      "{'loss': 1.0554, 'grad_norm': 40.849403381347656, 'learning_rate': 1.1859553948161543e-06, 'epoch': 2.65}\n",
      "{'loss': 1.0589, 'grad_norm': 33.74162292480469, 'learning_rate': 1.1809322885272253e-06, 'epoch': 2.65}\n",
      "{'loss': 1.0818, 'grad_norm': 27.469324111938477, 'learning_rate': 1.175909182238296e-06, 'epoch': 2.65}\n",
      "{'loss': 1.0765, 'grad_norm': 36.225303649902344, 'learning_rate': 1.170886075949367e-06, 'epoch': 2.65}\n",
      "{'loss': 1.0559, 'grad_norm': 18.381959915161133, 'learning_rate': 1.1658629696604381e-06, 'epoch': 2.65}\n",
      "{'loss': 1.0447, 'grad_norm': 33.52761459350586, 'learning_rate': 1.160839863371509e-06, 'epoch': 2.65}\n",
      "{'loss': 0.9515, 'grad_norm': 14.399674415588379, 'learning_rate': 1.15581675708258e-06, 'epoch': 2.66}\n",
      "{'loss': 1.0172, 'grad_norm': 34.60038757324219, 'learning_rate': 1.150793650793651e-06, 'epoch': 2.66}\n",
      "{'loss': 0.9865, 'grad_norm': 23.82455825805664, 'learning_rate': 1.1457705445047217e-06, 'epoch': 2.66}\n",
      "{'loss': 1.1159, 'grad_norm': 18.562292098999023, 'learning_rate': 1.1407474382157927e-06, 'epoch': 2.66}\n",
      "{'loss': 1.073, 'grad_norm': 30.543960571289062, 'learning_rate': 1.1357243319268635e-06, 'epoch': 2.66}\n",
      "{'loss': 1.1426, 'grad_norm': 40.10887908935547, 'learning_rate': 1.1307012256379345e-06, 'epoch': 2.66}\n",
      "{'loss': 1.1375, 'grad_norm': 23.526002883911133, 'learning_rate': 1.1256781193490055e-06, 'epoch': 2.66}\n",
      "{'loss': 1.029, 'grad_norm': 14.406643867492676, 'learning_rate': 1.1206550130600763e-06, 'epoch': 2.67}\n",
      "{'loss': 0.9903, 'grad_norm': 14.853352546691895, 'learning_rate': 1.1156319067711473e-06, 'epoch': 2.67}\n",
      "{'loss': 1.0531, 'grad_norm': 44.590484619140625, 'learning_rate': 1.1106088004822183e-06, 'epoch': 2.67}\n",
      "{'loss': 1.104, 'grad_norm': 23.54288101196289, 'learning_rate': 1.1055856941932891e-06, 'epoch': 2.67}\n",
      "{'loss': 1.0603, 'grad_norm': 26.106176376342773, 'learning_rate': 1.1005625879043602e-06, 'epoch': 2.67}\n",
      "{'loss': 1.0602, 'grad_norm': 8.19044017791748, 'learning_rate': 1.095539481615431e-06, 'epoch': 2.67}\n",
      "{'loss': 1.0994, 'grad_norm': 22.194644927978516, 'learning_rate': 1.090516375326502e-06, 'epoch': 2.67}\n",
      "{'loss': 1.1011, 'grad_norm': 27.909517288208008, 'learning_rate': 1.085493269037573e-06, 'epoch': 2.68}\n",
      "{'loss': 1.0779, 'grad_norm': 23.70679473876953, 'learning_rate': 1.0804701627486438e-06, 'epoch': 2.68}\n",
      "{'loss': 1.017, 'grad_norm': 7.616274833679199, 'learning_rate': 1.0754470564597148e-06, 'epoch': 2.68}\n",
      "{'loss': 0.9997, 'grad_norm': 28.79390525817871, 'learning_rate': 1.0704239501707858e-06, 'epoch': 2.68}\n",
      "{'loss': 1.1363, 'grad_norm': 20.885099411010742, 'learning_rate': 1.0654008438818566e-06, 'epoch': 2.68}\n",
      "{'loss': 1.1066, 'grad_norm': 38.77884292602539, 'learning_rate': 1.0603777375929276e-06, 'epoch': 2.68}\n",
      "{'loss': 1.061, 'grad_norm': 5.302215576171875, 'learning_rate': 1.0553546313039984e-06, 'epoch': 2.69}\n",
      "{'loss': 1.1082, 'grad_norm': 7.943367004394531, 'learning_rate': 1.0503315250150694e-06, 'epoch': 2.69}\n",
      "{'loss': 1.0326, 'grad_norm': 48.29277801513672, 'learning_rate': 1.0453084187261404e-06, 'epoch': 2.69}\n",
      "{'loss': 1.0604, 'grad_norm': 18.72554588317871, 'learning_rate': 1.0402853124372112e-06, 'epoch': 2.69}\n",
      "{'loss': 1.0385, 'grad_norm': 21.970478057861328, 'learning_rate': 1.0352622061482822e-06, 'epoch': 2.69}\n",
      "{'loss': 1.0761, 'grad_norm': 35.05076217651367, 'learning_rate': 1.0302390998593532e-06, 'epoch': 2.69}\n",
      "{'loss': 1.0415, 'grad_norm': 28.430509567260742, 'learning_rate': 1.025215993570424e-06, 'epoch': 2.69}\n",
      "{'loss': 1.0703, 'grad_norm': 16.91114616394043, 'learning_rate': 1.020192887281495e-06, 'epoch': 2.7}\n",
      "{'loss': 1.0329, 'grad_norm': 34.8924674987793, 'learning_rate': 1.0151697809925658e-06, 'epoch': 2.7}\n",
      "{'loss': 1.0266, 'grad_norm': 13.485289573669434, 'learning_rate': 1.0101466747036368e-06, 'epoch': 2.7}\n",
      "{'loss': 1.0355, 'grad_norm': 16.265213012695312, 'learning_rate': 1.0051235684147078e-06, 'epoch': 2.7}\n",
      "{'loss': 1.087, 'grad_norm': 28.229602813720703, 'learning_rate': 1.0001004621257786e-06, 'epoch': 2.7}\n",
      "{'loss': 1.0401, 'grad_norm': 25.880964279174805, 'learning_rate': 9.950773558368496e-07, 'epoch': 2.7}\n",
      "{'loss': 1.0689, 'grad_norm': 17.336524963378906, 'learning_rate': 9.900542495479206e-07, 'epoch': 2.7}\n",
      "{'loss': 1.0599, 'grad_norm': 26.885656356811523, 'learning_rate': 9.850311432589914e-07, 'epoch': 2.71}\n",
      "{'loss': 1.077, 'grad_norm': 10.173903465270996, 'learning_rate': 9.800080369700624e-07, 'epoch': 2.71}\n",
      "{'loss': 1.0473, 'grad_norm': 16.78685760498047, 'learning_rate': 9.749849306811332e-07, 'epoch': 2.71}\n",
      "{'loss': 1.0875, 'grad_norm': 31.14177131652832, 'learning_rate': 9.699618243922042e-07, 'epoch': 2.71}\n",
      "{'loss': 1.0212, 'grad_norm': 38.27389144897461, 'learning_rate': 9.649387181032753e-07, 'epoch': 2.71}\n",
      "{'loss': 1.0252, 'grad_norm': 16.77320098876953, 'learning_rate': 9.59915611814346e-07, 'epoch': 2.71}\n",
      "{'loss': 1.0772, 'grad_norm': 28.51963996887207, 'learning_rate': 9.54892505525417e-07, 'epoch': 2.72}\n",
      "{'loss': 0.9792, 'grad_norm': 22.289621353149414, 'learning_rate': 9.49869399236488e-07, 'epoch': 2.72}\n",
      "{'loss': 0.9788, 'grad_norm': 26.839950561523438, 'learning_rate': 9.448462929475589e-07, 'epoch': 2.72}\n",
      "{'loss': 1.0534, 'grad_norm': 19.85647964477539, 'learning_rate': 9.398231866586298e-07, 'epoch': 2.72}\n",
      "{'loss': 1.1174, 'grad_norm': 39.50119400024414, 'learning_rate': 9.348000803697008e-07, 'epoch': 2.72}\n",
      "{'loss': 1.0366, 'grad_norm': 26.374135971069336, 'learning_rate': 9.297769740807716e-07, 'epoch': 2.72}\n",
      "{'loss': 1.0544, 'grad_norm': 6.728783130645752, 'learning_rate': 9.247538677918426e-07, 'epoch': 2.72}\n",
      "{'loss': 1.0273, 'grad_norm': 8.38523006439209, 'learning_rate': 9.197307615029135e-07, 'epoch': 2.73}\n",
      "{'loss': 1.1404, 'grad_norm': 18.53340721130371, 'learning_rate': 9.147076552139844e-07, 'epoch': 2.73}\n",
      "{'loss': 1.0125, 'grad_norm': 18.191102981567383, 'learning_rate': 9.096845489250554e-07, 'epoch': 2.73}\n",
      "{'loss': 1.1103, 'grad_norm': 13.349407196044922, 'learning_rate': 9.046614426361263e-07, 'epoch': 2.73}\n",
      "{'loss': 1.0206, 'grad_norm': 25.671754837036133, 'learning_rate': 8.996383363471972e-07, 'epoch': 2.73}\n",
      "{'loss': 1.0945, 'grad_norm': 35.12118148803711, 'learning_rate': 8.946152300582681e-07, 'epoch': 2.73}\n",
      "{'loss': 1.049, 'grad_norm': 24.47845458984375, 'learning_rate': 8.89592123769339e-07, 'epoch': 2.74}\n",
      "{'loss': 1.0428, 'grad_norm': 10.97589111328125, 'learning_rate': 8.8456901748041e-07, 'epoch': 2.74}\n",
      "{'loss': 1.0764, 'grad_norm': 16.695858001708984, 'learning_rate': 8.795459111914809e-07, 'epoch': 2.74}\n",
      "{'loss': 1.0075, 'grad_norm': 6.9666924476623535, 'learning_rate': 8.745228049025518e-07, 'epoch': 2.74}\n",
      "{'loss': 1.0659, 'grad_norm': 7.851252555847168, 'learning_rate': 8.694996986136227e-07, 'epoch': 2.74}\n",
      "{'loss': 0.9889, 'grad_norm': 25.06646156311035, 'learning_rate': 8.644765923246937e-07, 'epoch': 2.74}\n",
      "{'loss': 1.0065, 'grad_norm': 19.245664596557617, 'learning_rate': 8.594534860357646e-07, 'epoch': 2.74}\n",
      "{'loss': 1.0393, 'grad_norm': 18.488500595092773, 'learning_rate': 8.544303797468355e-07, 'epoch': 2.75}\n",
      "{'loss': 1.0345, 'grad_norm': 7.17365837097168, 'learning_rate': 8.494072734579064e-07, 'epoch': 2.75}\n",
      "{'loss': 1.0697, 'grad_norm': 8.76273250579834, 'learning_rate': 8.443841671689773e-07, 'epoch': 2.75}\n",
      "{'loss': 1.0741, 'grad_norm': 8.002900123596191, 'learning_rate': 8.393610608800483e-07, 'epoch': 2.75}\n",
      "{'loss': 1.0753, 'grad_norm': 32.85817337036133, 'learning_rate': 8.343379545911192e-07, 'epoch': 2.75}\n",
      "{'loss': 1.0451, 'grad_norm': 51.310420989990234, 'learning_rate': 8.293148483021901e-07, 'epoch': 2.75}\n",
      "{'loss': 1.041, 'grad_norm': 7.830127239227295, 'learning_rate': 8.242917420132611e-07, 'epoch': 2.75}\n",
      "{'loss': 1.0688, 'grad_norm': 20.97039794921875, 'learning_rate': 8.192686357243319e-07, 'epoch': 2.76}\n",
      "{'loss': 1.0706, 'grad_norm': 19.425983428955078, 'learning_rate': 8.14245529435403e-07, 'epoch': 2.76}\n",
      "{'loss': 1.0237, 'grad_norm': 19.56017303466797, 'learning_rate': 8.092224231464739e-07, 'epoch': 2.76}\n",
      "{'loss': 1.099, 'grad_norm': 19.544172286987305, 'learning_rate': 8.041993168575448e-07, 'epoch': 2.76}\n",
      "{'loss': 1.0679, 'grad_norm': 16.306644439697266, 'learning_rate': 7.991762105686158e-07, 'epoch': 2.76}\n",
      "{'loss': 1.0286, 'grad_norm': 23.092281341552734, 'learning_rate': 7.941531042796866e-07, 'epoch': 2.76}\n",
      "{'loss': 1.0909, 'grad_norm': 21.57022476196289, 'learning_rate': 7.891299979907576e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0372, 'grad_norm': 6.915538787841797, 'learning_rate': 7.841068917018286e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0818, 'grad_norm': 23.03497314453125, 'learning_rate': 7.790837854128994e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0671, 'grad_norm': 16.632699966430664, 'learning_rate': 7.740606791239704e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0212, 'grad_norm': 23.13468360900879, 'learning_rate': 7.690375728350412e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0376, 'grad_norm': 37.011165618896484, 'learning_rate': 7.640144665461122e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0011, 'grad_norm': 18.506858825683594, 'learning_rate': 7.589913602571832e-07, 'epoch': 2.77}\n",
      "{'loss': 1.0946, 'grad_norm': 36.691810607910156, 'learning_rate': 7.53968253968254e-07, 'epoch': 2.78}\n",
      "{'loss': 1.0225, 'grad_norm': 24.906158447265625, 'learning_rate': 7.48945147679325e-07, 'epoch': 2.78}\n",
      "{'loss': 1.0236, 'grad_norm': 40.533023834228516, 'learning_rate': 7.43922041390396e-07, 'epoch': 2.78}\n",
      "{'loss': 1.1177, 'grad_norm': 29.940988540649414, 'learning_rate': 7.388989351014668e-07, 'epoch': 2.78}\n",
      "{'loss': 1.0017, 'grad_norm': 19.8173828125, 'learning_rate': 7.338758288125378e-07, 'epoch': 2.78}\n",
      "{'loss': 1.0282, 'grad_norm': 8.246529579162598, 'learning_rate': 7.288527225236086e-07, 'epoch': 2.78}\n",
      "{'loss': 0.8987, 'grad_norm': 21.883821487426758, 'learning_rate': 7.238296162346796e-07, 'epoch': 2.78}\n",
      "{'loss': 1.0097, 'grad_norm': 22.631765365600586, 'learning_rate': 7.188065099457506e-07, 'epoch': 2.79}\n",
      "{'loss': 1.0842, 'grad_norm': 17.467430114746094, 'learning_rate': 7.137834036568214e-07, 'epoch': 2.79}\n",
      "{'loss': 1.0364, 'grad_norm': 19.536136627197266, 'learning_rate': 7.087602973678924e-07, 'epoch': 2.79}\n",
      "{'loss': 0.9996, 'grad_norm': 5.79257345199585, 'learning_rate': 7.037371910789632e-07, 'epoch': 2.79}\n",
      "{'loss': 1.0756, 'grad_norm': 28.779401779174805, 'learning_rate': 6.987140847900342e-07, 'epoch': 2.79}\n",
      "{'loss': 0.9888, 'grad_norm': 28.410572052001953, 'learning_rate': 6.936909785011052e-07, 'epoch': 2.79}\n",
      "{'loss': 1.0915, 'grad_norm': 25.259124755859375, 'learning_rate': 6.88667872212176e-07, 'epoch': 2.8}\n",
      "{'loss': 0.996, 'grad_norm': 23.14093780517578, 'learning_rate': 6.83644765923247e-07, 'epoch': 2.8}\n",
      "{'loss': 1.0626, 'grad_norm': 32.724002838134766, 'learning_rate': 6.786216596343178e-07, 'epoch': 2.8}\n",
      "{'loss': 1.017, 'grad_norm': 27.78187370300293, 'learning_rate': 6.735985533453888e-07, 'epoch': 2.8}\n",
      "{'loss': 1.0286, 'grad_norm': 14.317702293395996, 'learning_rate': 6.685754470564599e-07, 'epoch': 2.8}\n",
      "{'loss': 1.0365, 'grad_norm': 8.969950675964355, 'learning_rate': 6.635523407675306e-07, 'epoch': 2.8}\n",
      "{'loss': 1.0372, 'grad_norm': 20.437990188598633, 'learning_rate': 6.585292344786017e-07, 'epoch': 2.8}\n",
      "{'loss': 1.0179, 'grad_norm': 12.014900207519531, 'learning_rate': 6.535061281896725e-07, 'epoch': 2.81}\n",
      "{'loss': 1.0825, 'grad_norm': 24.084762573242188, 'learning_rate': 6.484830219007435e-07, 'epoch': 2.81}\n",
      "{'loss': 1.0739, 'grad_norm': 19.35439682006836, 'learning_rate': 6.434599156118145e-07, 'epoch': 2.81}\n",
      "{'loss': 1.1205, 'grad_norm': 22.226486206054688, 'learning_rate': 6.384368093228853e-07, 'epoch': 2.81}\n",
      "{'loss': 1.0162, 'grad_norm': 32.52653884887695, 'learning_rate': 6.334137030339563e-07, 'epoch': 2.81}\n",
      "{'loss': 0.9886, 'grad_norm': 17.90261459350586, 'learning_rate': 6.283905967450271e-07, 'epoch': 2.81}\n",
      "{'loss': 1.1517, 'grad_norm': 14.898615837097168, 'learning_rate': 6.233674904560981e-07, 'epoch': 2.81}\n",
      "{'loss': 1.0815, 'grad_norm': 16.262928009033203, 'learning_rate': 6.18344384167169e-07, 'epoch': 2.82}\n",
      "{'loss': 1.0394, 'grad_norm': 22.39447593688965, 'learning_rate': 6.1332127787824e-07, 'epoch': 2.82}\n",
      "{'loss': 1.0791, 'grad_norm': 35.61320114135742, 'learning_rate': 6.082981715893109e-07, 'epoch': 2.82}\n",
      "{'loss': 0.9958, 'grad_norm': 34.8979377746582, 'learning_rate': 6.032750653003818e-07, 'epoch': 2.82}\n",
      "{'loss': 1.0627, 'grad_norm': 20.264604568481445, 'learning_rate': 5.982519590114527e-07, 'epoch': 2.82}\n",
      "{'loss': 1.053, 'grad_norm': 18.21559715270996, 'learning_rate': 5.932288527225236e-07, 'epoch': 2.82}\n",
      "{'loss': 1.04, 'grad_norm': 18.82845687866211, 'learning_rate': 5.882057464335946e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0667, 'grad_norm': 5.130443572998047, 'learning_rate': 5.831826401446655e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0849, 'grad_norm': 38.77342987060547, 'learning_rate': 5.781595338557364e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0019, 'grad_norm': 26.980567932128906, 'learning_rate': 5.731364275668073e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0336, 'grad_norm': 41.12948226928711, 'learning_rate': 5.681133212778782e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0822, 'grad_norm': 20.899646759033203, 'learning_rate': 5.630902149889492e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0261, 'grad_norm': 10.527600288391113, 'learning_rate': 5.580671087000201e-07, 'epoch': 2.83}\n",
      "{'loss': 1.0133, 'grad_norm': 42.66819763183594, 'learning_rate': 5.53044002411091e-07, 'epoch': 2.84}\n",
      "{'loss': 1.0011, 'grad_norm': 29.144378662109375, 'learning_rate': 5.480208961221619e-07, 'epoch': 2.84}\n",
      "{'loss': 0.975, 'grad_norm': 18.278398513793945, 'learning_rate': 5.429977898332329e-07, 'epoch': 2.84}\n",
      "{'loss': 1.075, 'grad_norm': 22.723787307739258, 'learning_rate': 5.379746835443038e-07, 'epoch': 2.84}\n",
      "{'loss': 0.9861, 'grad_norm': 19.26523780822754, 'learning_rate': 5.329515772553747e-07, 'epoch': 2.84}\n",
      "{'loss': 1.0163, 'grad_norm': 35.50229263305664, 'learning_rate': 5.279284709664456e-07, 'epoch': 2.84}\n",
      "{'loss': 1.073, 'grad_norm': 41.25919723510742, 'learning_rate': 5.229053646775166e-07, 'epoch': 2.85}\n",
      "{'loss': 1.0913, 'grad_norm': 8.285225868225098, 'learning_rate': 5.178822583885875e-07, 'epoch': 2.85}\n",
      "{'loss': 0.9728, 'grad_norm': 18.664941787719727, 'learning_rate': 5.128591520996585e-07, 'epoch': 2.85}\n",
      "{'loss': 1.0859, 'grad_norm': 20.150863647460938, 'learning_rate': 5.078360458107294e-07, 'epoch': 2.85}\n",
      "{'loss': 1.041, 'grad_norm': 33.09733581542969, 'learning_rate': 5.028129395218004e-07, 'epoch': 2.85}\n",
      "{'loss': 1.0136, 'grad_norm': 36.98727798461914, 'learning_rate': 4.977898332328713e-07, 'epoch': 2.85}\n",
      "{'loss': 1.0156, 'grad_norm': 7.440175533294678, 'learning_rate': 4.927667269439422e-07, 'epoch': 2.85}\n",
      "{'loss': 1.1108, 'grad_norm': 30.779420852661133, 'learning_rate': 4.877436206550131e-07, 'epoch': 2.86}\n",
      "{'loss': 1.0184, 'grad_norm': 38.03795623779297, 'learning_rate': 4.827205143660841e-07, 'epoch': 2.86}\n",
      "{'loss': 1.0606, 'grad_norm': 42.665611267089844, 'learning_rate': 4.77697408077155e-07, 'epoch': 2.86}\n",
      "{'loss': 0.9988, 'grad_norm': 17.253347396850586, 'learning_rate': 4.7267430178822583e-07, 'epoch': 2.86}\n",
      "{'loss': 1.091, 'grad_norm': 19.895557403564453, 'learning_rate': 4.6765119549929683e-07, 'epoch': 2.86}\n",
      "{'loss': 1.0136, 'grad_norm': 6.655305862426758, 'learning_rate': 4.6262808921036774e-07, 'epoch': 2.86}\n",
      "{'loss': 1.0483, 'grad_norm': 30.052244186401367, 'learning_rate': 4.5760498292143864e-07, 'epoch': 2.86}\n",
      "{'loss': 1.1326, 'grad_norm': 37.757171630859375, 'learning_rate': 4.5258187663250954e-07, 'epoch': 2.87}\n",
      "{'loss': 1.0414, 'grad_norm': 19.671852111816406, 'learning_rate': 4.475587703435805e-07, 'epoch': 2.87}\n",
      "{'loss': 1.0236, 'grad_norm': 18.026412963867188, 'learning_rate': 4.4253566405465145e-07, 'epoch': 2.87}\n",
      "{'loss': 1.0646, 'grad_norm': 17.788576126098633, 'learning_rate': 4.3751255776572235e-07, 'epoch': 2.87}\n",
      "{'loss': 1.0381, 'grad_norm': 31.366804122924805, 'learning_rate': 4.3248945147679326e-07, 'epoch': 2.87}\n",
      "{'loss': 1.117, 'grad_norm': 25.791595458984375, 'learning_rate': 4.274663451878642e-07, 'epoch': 2.87}\n",
      "{'loss': 1.0326, 'grad_norm': 5.771144866943359, 'learning_rate': 4.2244323889893517e-07, 'epoch': 2.88}\n",
      "{'loss': 0.9702, 'grad_norm': 41.3751106262207, 'learning_rate': 4.1742013261000607e-07, 'epoch': 2.88}\n",
      "{'loss': 1.0482, 'grad_norm': 21.279233932495117, 'learning_rate': 4.1239702632107697e-07, 'epoch': 2.88}\n",
      "{'loss': 1.0629, 'grad_norm': 25.868871688842773, 'learning_rate': 4.073739200321479e-07, 'epoch': 2.88}\n",
      "{'loss': 1.0382, 'grad_norm': 10.180243492126465, 'learning_rate': 4.023508137432188e-07, 'epoch': 2.88}\n",
      "{'loss': 1.0514, 'grad_norm': 17.728429794311523, 'learning_rate': 3.973277074542898e-07, 'epoch': 2.88}\n",
      "{'loss': 1.1689, 'grad_norm': 23.895780563354492, 'learning_rate': 3.923046011653607e-07, 'epoch': 2.88}\n",
      "{'loss': 1.0893, 'grad_norm': 19.42864227294922, 'learning_rate': 3.8728149487643164e-07, 'epoch': 2.89}\n",
      "{'loss': 1.0465, 'grad_norm': 23.391416549682617, 'learning_rate': 3.8225838858750254e-07, 'epoch': 2.89}\n",
      "{'loss': 1.0346, 'grad_norm': 12.884044647216797, 'learning_rate': 3.7723528229857344e-07, 'epoch': 2.89}\n",
      "{'loss': 1.0365, 'grad_norm': 9.193293571472168, 'learning_rate': 3.722121760096444e-07, 'epoch': 2.89}\n",
      "{'loss': 1.1099, 'grad_norm': 16.739789962768555, 'learning_rate': 3.6718906972071535e-07, 'epoch': 2.89}\n",
      "{'loss': 0.9976, 'grad_norm': 25.275907516479492, 'learning_rate': 3.6216596343178625e-07, 'epoch': 2.89}\n",
      "{'loss': 1.0767, 'grad_norm': 14.776679992675781, 'learning_rate': 3.5714285714285716e-07, 'epoch': 2.89}\n",
      "{'loss': 1.1444, 'grad_norm': 18.397520065307617, 'learning_rate': 3.5211975085392806e-07, 'epoch': 2.9}\n",
      "{'loss': 1.101, 'grad_norm': 20.13833236694336, 'learning_rate': 3.4709664456499907e-07, 'epoch': 2.9}\n",
      "{'loss': 1.0761, 'grad_norm': 21.615581512451172, 'learning_rate': 3.4207353827606997e-07, 'epoch': 2.9}\n",
      "{'loss': 0.9925, 'grad_norm': 20.009563446044922, 'learning_rate': 3.3705043198714087e-07, 'epoch': 2.9}\n",
      "{'loss': 1.0346, 'grad_norm': 27.801639556884766, 'learning_rate': 3.3202732569821177e-07, 'epoch': 2.9}\n",
      "{'loss': 1.0694, 'grad_norm': 37.359962463378906, 'learning_rate': 3.270042194092828e-07, 'epoch': 2.9}\n",
      "{'loss': 1.0355, 'grad_norm': 17.75775718688965, 'learning_rate': 3.219811131203537e-07, 'epoch': 2.91}\n",
      "{'loss': 1.0962, 'grad_norm': 36.774112701416016, 'learning_rate': 3.169580068314246e-07, 'epoch': 2.91}\n",
      "{'loss': 1.0429, 'grad_norm': 42.54439163208008, 'learning_rate': 3.119349005424955e-07, 'epoch': 2.91}\n",
      "{'loss': 1.0608, 'grad_norm': 19.456066131591797, 'learning_rate': 3.0691179425356644e-07, 'epoch': 2.91}\n",
      "{'loss': 0.9922, 'grad_norm': 7.288577556610107, 'learning_rate': 3.0188868796463734e-07, 'epoch': 2.91}\n",
      "{'loss': 1.0718, 'grad_norm': inf, 'learning_rate': 2.973678923046012e-07, 'epoch': 2.91}\n",
      "{'loss': 1.0669, 'grad_norm': 21.339839935302734, 'learning_rate': 2.9234478601567215e-07, 'epoch': 2.91}\n",
      "{'loss': 1.0918, 'grad_norm': 21.537683486938477, 'learning_rate': 2.8732167972674306e-07, 'epoch': 2.92}\n",
      "{'loss': 1.0438, 'grad_norm': 18.6979923248291, 'learning_rate': 2.8229857343781396e-07, 'epoch': 2.92}\n",
      "{'loss': 1.0439, 'grad_norm': 16.76524543762207, 'learning_rate': 2.772754671488849e-07, 'epoch': 2.92}\n",
      "{'loss': 1.1014, 'grad_norm': 8.470030784606934, 'learning_rate': 2.722523608599558e-07, 'epoch': 2.92}\n",
      "{'loss': 1.064, 'grad_norm': 13.760538101196289, 'learning_rate': 2.6722925457102677e-07, 'epoch': 2.92}\n",
      "{'loss': 1.0589, 'grad_norm': 26.757484436035156, 'learning_rate': 2.6220614828209767e-07, 'epoch': 2.92}\n",
      "{'loss': 1.1458, 'grad_norm': 23.182138442993164, 'learning_rate': 2.5718304199316863e-07, 'epoch': 2.92}\n",
      "{'loss': 1.1085, 'grad_norm': 24.889543533325195, 'learning_rate': 2.5215993570423953e-07, 'epoch': 2.93}\n",
      "{'loss': 1.0371, 'grad_norm': 34.930782318115234, 'learning_rate': 2.4713682941531043e-07, 'epoch': 2.93}\n",
      "{'loss': 1.0568, 'grad_norm': 21.622669219970703, 'learning_rate': 2.421137231263814e-07, 'epoch': 2.93}\n",
      "{'loss': 1.0427, 'grad_norm': 12.27462387084961, 'learning_rate': 2.370906168374523e-07, 'epoch': 2.93}\n",
      "{'loss': 1.0678, 'grad_norm': 54.50614929199219, 'learning_rate': 2.3206751054852324e-07, 'epoch': 2.93}\n",
      "{'loss': 1.1096, 'grad_norm': 12.383862495422363, 'learning_rate': 2.2704440425959415e-07, 'epoch': 2.93}\n",
      "{'loss': 1.1429, 'grad_norm': 39.141597747802734, 'learning_rate': 2.220212979706651e-07, 'epoch': 2.94}\n",
      "{'loss': 0.985, 'grad_norm': 35.4533576965332, 'learning_rate': 2.16998191681736e-07, 'epoch': 2.94}\n",
      "{'loss': 1.0828, 'grad_norm': 14.192649841308594, 'learning_rate': 2.119750853928069e-07, 'epoch': 2.94}\n",
      "{'loss': 1.0939, 'grad_norm': 39.37202835083008, 'learning_rate': 2.0695197910387786e-07, 'epoch': 2.94}\n",
      "{'loss': 1.0912, 'grad_norm': 17.03784942626953, 'learning_rate': 2.0192887281494876e-07, 'epoch': 2.94}\n",
      "{'loss': 1.0103, 'grad_norm': 27.717329025268555, 'learning_rate': 1.9690576652601972e-07, 'epoch': 2.94}\n",
      "{'loss': 1.0307, 'grad_norm': 5.111504077911377, 'learning_rate': 1.9188266023709062e-07, 'epoch': 2.94}\n",
      "{'loss': 0.9817, 'grad_norm': 15.608250617980957, 'learning_rate': 1.8685955394816155e-07, 'epoch': 2.95}\n",
      "{'loss': 1.0532, 'grad_norm': 4.912449836730957, 'learning_rate': 1.8183644765923248e-07, 'epoch': 2.95}\n",
      "{'loss': 0.96, 'grad_norm': 26.890472412109375, 'learning_rate': 1.768133413703034e-07, 'epoch': 2.95}\n",
      "{'loss': 1.0331, 'grad_norm': 16.752592086791992, 'learning_rate': 1.7179023508137433e-07, 'epoch': 2.95}\n",
      "{'loss': 1.0588, 'grad_norm': 16.278568267822266, 'learning_rate': 1.6676712879244526e-07, 'epoch': 2.95}\n",
      "{'loss': 1.0868, 'grad_norm': 17.731908798217773, 'learning_rate': 1.617440225035162e-07, 'epoch': 2.95}\n",
      "{'loss': 1.0122, 'grad_norm': 19.786415100097656, 'learning_rate': 1.5672091621458712e-07, 'epoch': 2.96}\n",
      "{'loss': 1.0157, 'grad_norm': 20.61925506591797, 'learning_rate': 1.5169780992565805e-07, 'epoch': 2.96}\n",
      "{'loss': 1.1185, 'grad_norm': 23.290664672851562, 'learning_rate': 1.4667470363672898e-07, 'epoch': 2.96}\n",
      "{'loss': 1.0402, 'grad_norm': 55.17924499511719, 'learning_rate': 1.416515973477999e-07, 'epoch': 2.96}\n",
      "{'loss': 1.1275, 'grad_norm': 32.955230712890625, 'learning_rate': 1.366284910588708e-07, 'epoch': 2.96}\n",
      "{'loss': 1.05, 'grad_norm': 35.93857955932617, 'learning_rate': 1.3160538476994174e-07, 'epoch': 2.96}\n",
      "{'loss': 1.1117, 'grad_norm': 7.7810211181640625, 'learning_rate': 1.2658227848101266e-07, 'epoch': 2.96}\n",
      "{'loss': 1.0748, 'grad_norm': 18.289207458496094, 'learning_rate': 1.215591721920836e-07, 'epoch': 2.97}\n",
      "{'loss': 1.0407, 'grad_norm': 18.753110885620117, 'learning_rate': 1.1653606590315452e-07, 'epoch': 2.97}\n",
      "{'loss': 1.0013, 'grad_norm': 19.045928955078125, 'learning_rate': 1.1151295961422545e-07, 'epoch': 2.97}\n",
      "{'loss': 1.0299, 'grad_norm': 19.771194458007812, 'learning_rate': 1.0648985332529636e-07, 'epoch': 2.97}\n",
      "{'loss': 1.1328, 'grad_norm': 6.832857131958008, 'learning_rate': 1.014667470363673e-07, 'epoch': 2.97}\n",
      "{'loss': 1.14, 'grad_norm': 39.485782623291016, 'learning_rate': 9.644364074743822e-08, 'epoch': 2.97}\n",
      "{'loss': 1.0807, 'grad_norm': 14.682696342468262, 'learning_rate': 9.142053445850915e-08, 'epoch': 2.97}\n",
      "{'loss': 1.1264, 'grad_norm': 18.173091888427734, 'learning_rate': 8.639742816958008e-08, 'epoch': 2.98}\n",
      "{'loss': 1.1111, 'grad_norm': 8.143553733825684, 'learning_rate': 8.137432188065101e-08, 'epoch': 2.98}\n",
      "{'loss': 1.0575, 'grad_norm': 30.26357078552246, 'learning_rate': 7.635121559172192e-08, 'epoch': 2.98}\n",
      "{'loss': 1.0517, 'grad_norm': 34.9432487487793, 'learning_rate': 7.132810930279285e-08, 'epoch': 2.98}\n",
      "{'loss': 1.0543, 'grad_norm': 17.210641860961914, 'learning_rate': 6.630500301386378e-08, 'epoch': 2.98}\n",
      "{'loss': 1.0561, 'grad_norm': 53.282352447509766, 'learning_rate': 6.128189672493471e-08, 'epoch': 2.98}\n",
      "{'loss': 1.0264, 'grad_norm': 16.038450241088867, 'learning_rate': 5.625879043600563e-08, 'epoch': 2.99}\n",
      "{'loss': 1.0289, 'grad_norm': 23.579463958740234, 'learning_rate': 5.123568414707656e-08, 'epoch': 2.99}\n",
      "{'loss': 1.0519, 'grad_norm': 19.863128662109375, 'learning_rate': 4.621257785814748e-08, 'epoch': 2.99}\n",
      "{'loss': 1.0772, 'grad_norm': 32.54600524902344, 'learning_rate': 4.118947156921841e-08, 'epoch': 2.99}\n",
      "{'loss': 1.0145, 'grad_norm': 21.698013305664062, 'learning_rate': 3.616636528028933e-08, 'epoch': 2.99}\n",
      "{'loss': 1.0336, 'grad_norm': 19.962615966796875, 'learning_rate': 3.114325899136026e-08, 'epoch': 2.99}\n",
      "{'loss': 1.015, 'grad_norm': 21.619489669799805, 'learning_rate': 2.6120152702431185e-08, 'epoch': 2.99}\n",
      "{'loss': 0.9994, 'grad_norm': 19.64628028869629, 'learning_rate': 2.109704641350211e-08, 'epoch': 3.0}\n",
      "{'loss': 1.0101, 'grad_norm': 24.19536590576172, 'learning_rate': 1.607394012457304e-08, 'epoch': 3.0}\n",
      "{'loss': 1.0435, 'grad_norm': 40.11677169799805, 'learning_rate': 1.1050833835643963e-08, 'epoch': 3.0}\n",
      "{'train_runtime': 1126.9978, 'train_samples_per_second': 70.656, 'train_steps_per_second': 17.665, 'train_loss': 1.0611081155447781, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Print evaluation results\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/trainer.py:3467\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3464\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3466\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3467\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/trainer.py:3650\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3647\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3650\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3651\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3652\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/trainer.py:3836\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3835\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3836\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3837\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   3839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/trainer.py:3161\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3160\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3163\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:822\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py:810\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/hf_mamba_classification.py:139\u001b[0m, in \u001b[0;36mMambaForSequenceClassification.forward\u001b[0;34m(self, input_ids, inputs_embeds, cache_params, use_cache, labels, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# if inputs_embeds is None:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#     inputs_embeds = self.backbone.embeddings(input_ids)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m#         self.config, inputs_embeds.size(0), device=inputs_embeds.device, dtype=inputs_embeds.dtype\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m mamba_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m mamba_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    148\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(hidden_states)\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/models/mamba/modeling_mamba.py:579\u001b[0m, in \u001b[0;36mMambaModel.forward\u001b[0;34m(self, input_ids, inputs_embeds, cache_params, use_cache, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(mixer_block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, hidden_states, cache_params)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mmixer_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    582\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/models/mamba/modeling_mamba.py:344\u001b[0m, in \u001b[0;36mMambaBlock.forward\u001b[0;34m(self, hidden_states, cache_params)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_in_fp32:\n\u001b[1;32m    342\u001b[0m     residual \u001b[38;5;241m=\u001b[39m residual\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 344\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/models/mamba/modeling_mamba.py:308\u001b[0m, in \u001b[0;36mMambaMixer.forward\u001b[0;34m(self, hidden_states, cache_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, cache_params: Optional[MambaCache] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fast_path_available \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_proj\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype:\n\u001b[0;32m--> 308\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda_kernels_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_forward(hidden_states, cache_params)\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/transformers/models/mamba/modeling_mamba.py:203\u001b[0m, in \u001b[0;36mMambaMixer.cuda_kernels_forward\u001b[0;34m(self, hidden_states, cache_params)\u001b[0m\n\u001b[1;32m    198\u001b[0m time_step, B, C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m    199\u001b[0m     ssm_parameters, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step_rank, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm_state_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm_state_size], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    201\u001b[0m discrete_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_proj\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m@\u001b[39m time_step\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA_log\u001b[49m\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# 3.c perform the recurrence y ← SSM(A, B, C)(x)\u001b[39;00m\n\u001b[1;32m    205\u001b[0m time_proj_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_proj\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_proj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/kaggle/kaggle_arena/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(dataset_set)\n",
    "\n",
    "# Print evaluation results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
